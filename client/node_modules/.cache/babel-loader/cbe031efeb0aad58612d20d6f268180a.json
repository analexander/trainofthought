{"ast":null,"code":"import { AgeGenderNet } from '../ageGenderNet/AgeGenderNet';\nimport { FaceExpressionNet } from '../faceExpressionNet/FaceExpressionNet';\nimport { FaceLandmark68Net } from '../faceLandmarkNet/FaceLandmark68Net';\nimport { FaceLandmark68TinyNet } from '../faceLandmarkNet/FaceLandmark68TinyNet';\nimport { FaceRecognitionNet } from '../faceRecognitionNet/FaceRecognitionNet';\nimport { Mtcnn } from '../mtcnn/Mtcnn';\nimport { SsdMobilenetv1 } from '../ssdMobilenetv1/SsdMobilenetv1';\nimport { TinyFaceDetector } from '../tinyFaceDetector/TinyFaceDetector';\nimport { TinyYolov2 } from '../tinyYolov2';\nexport var nets = {\n  ssdMobilenetv1: new SsdMobilenetv1(),\n  tinyFaceDetector: new TinyFaceDetector(),\n  tinyYolov2: new TinyYolov2(),\n  mtcnn: new Mtcnn(),\n  faceLandmark68Net: new FaceLandmark68Net(),\n  faceLandmark68TinyNet: new FaceLandmark68TinyNet(),\n  faceRecognitionNet: new FaceRecognitionNet(),\n  faceExpressionNet: new FaceExpressionNet(),\n  ageGenderNet: new AgeGenderNet()\n};\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var ssdMobilenetv1 = function ssdMobilenetv1(input, options) {\n  return nets.ssdMobilenetv1.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var tinyFaceDetector = function tinyFaceDetector(input, options) {\n  return nets.tinyFaceDetector.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var tinyYolov2 = function tinyYolov2(input, options) {\n  return nets.tinyYolov2.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\n\nexport var mtcnn = function mtcnn(input, options) {\n  return nets.mtcnn.forward(input, options);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\n\nexport var detectFaceLandmarks = function detectFaceLandmarks(input) {\n  return nets.faceLandmark68Net.detectLandmarks(input);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\n\nexport var detectFaceLandmarksTiny = function detectFaceLandmarksTiny(input) {\n  return nets.faceLandmark68TinyNet.detectLandmarks(input);\n};\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\n\nexport var computeFaceDescriptor = function computeFaceDescriptor(input) {\n  return nets.faceRecognitionNet.computeFaceDescriptor(input);\n};\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\n\nexport var recognizeFaceExpressions = function recognizeFaceExpressions(input) {\n  return nets.faceExpressionNet.predictExpressions(input);\n};\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\n\nexport var predictAgeAndGender = function predictAgeAndGender(input) {\n  return nets.ageGenderNet.predictAgeAndGender(input);\n};\nexport var loadSsdMobilenetv1Model = function loadSsdMobilenetv1Model(url) {\n  return nets.ssdMobilenetv1.load(url);\n};\nexport var loadTinyFaceDetectorModel = function loadTinyFaceDetectorModel(url) {\n  return nets.tinyFaceDetector.load(url);\n};\nexport var loadMtcnnModel = function loadMtcnnModel(url) {\n  return nets.mtcnn.load(url);\n};\nexport var loadTinyYolov2Model = function loadTinyYolov2Model(url) {\n  return nets.tinyYolov2.load(url);\n};\nexport var loadFaceLandmarkModel = function loadFaceLandmarkModel(url) {\n  return nets.faceLandmark68Net.load(url);\n};\nexport var loadFaceLandmarkTinyModel = function loadFaceLandmarkTinyModel(url) {\n  return nets.faceLandmark68TinyNet.load(url);\n};\nexport var loadFaceRecognitionModel = function loadFaceRecognitionModel(url) {\n  return nets.faceRecognitionNet.load(url);\n};\nexport var loadFaceExpressionModel = function loadFaceExpressionModel(url) {\n  return nets.faceExpressionNet.load(url);\n};\nexport var loadAgeGenderModel = function loadAgeGenderModel(url) {\n  return nets.ageGenderNet.load(url);\n}; // backward compatibility\n\nexport var loadFaceDetectionModel = loadSsdMobilenetv1Model;\nexport var locateFaces = ssdMobilenetv1;\nexport var detectLandmarks = detectFaceLandmarks;","map":null,"metadata":{},"sourceType":"module"}