{"ast":null,"code":"import _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _get from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Noise Layers.\n */\nimport { greaterEqual, randomUniform, serialization, tidy } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { Layer } from '../engine/topology';\nimport { getExactlyOneTensor } from '../utils/types_utils';\nexport var GaussianNoise = /*#__PURE__*/function (_Layer) {\n  _inherits(GaussianNoise, _Layer);\n\n  function GaussianNoise(args) {\n    var _this;\n\n    _classCallCheck(this, GaussianNoise);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(GaussianNoise).call(this, args));\n    _this.supportsMasking = true;\n    _this.stddev = args.stddev;\n    return _this;\n  }\n\n  _createClass(GaussianNoise, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return inputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(GaussianNoise.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        stddev: this.stddev\n      };\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n\n      return tidy(function () {\n        _this2.invokeCallHook(inputs, kwargs);\n\n        var input = getExactlyOneTensor(inputs);\n\n        var noised = function noised() {\n          return K.randomNormal(input.shape, 0, _this2.stddev).add(input);\n        };\n\n        var output = K.inTrainPhase(noised, function () {\n          return input;\n        }, kwargs['training'] || false);\n        return output;\n      });\n    }\n  }]);\n\n  return GaussianNoise;\n}(Layer);\n/** @nocollapse */\n\nGaussianNoise.className = 'GaussianNoise';\nserialization.registerClass(GaussianNoise);\nexport var GaussianDropout = /*#__PURE__*/function (_Layer2) {\n  _inherits(GaussianDropout, _Layer2);\n\n  function GaussianDropout(args) {\n    var _this3;\n\n    _classCallCheck(this, GaussianDropout);\n\n    _this3 = _possibleConstructorReturn(this, _getPrototypeOf(GaussianDropout).call(this, args));\n    _this3.supportsMasking = true;\n    _this3.rate = args.rate;\n    return _this3;\n  }\n\n  _createClass(GaussianDropout, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return inputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(GaussianDropout.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        rate: this.rate\n      };\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this4 = this;\n\n      return tidy(function () {\n        _this4.invokeCallHook(inputs, kwargs);\n\n        var input = getExactlyOneTensor(inputs);\n\n        if (_this4.rate > 0 && _this4.rate < 1) {\n          var noised = function noised() {\n            var stddev = Math.sqrt(_this4.rate / (1 - _this4.rate));\n            return input.mul(K.randomNormal(input.shape, 1, stddev));\n          };\n\n          return K.inTrainPhase(noised, function () {\n            return input;\n          }, kwargs['training'] || false);\n        }\n\n        return input;\n      });\n    }\n  }]);\n\n  return GaussianDropout;\n}(Layer);\n/** @nocollapse */\n\nGaussianDropout.className = 'GaussianDropout';\nserialization.registerClass(GaussianDropout);\n/**\n * Applies Alpha Dropout to the input.\n *\n * As it is a regularization layer, it is only active at training time.\n *\n * Alpha Dropout is a `Dropout` that keeps mean and variance of inputs\n * to their original values, in order to ensure the self-normalizing property\n * even after this dropout.\n * Alpha Dropout fits well to Scaled Exponential Linear Units\n * by randomly setting activations to the negative saturation value.\n *\n * Arguments:\n *   - `rate`: float, drop probability (as with `Dropout`).\n *     The multiplicative noise will have\n *     standard deviation `sqrt(rate / (1 - rate))`.\n *   - `noise_shape`: A 1-D `Tensor` of type `int32`, representing the\n *     shape for randomly generated keep/drop flags.\n *\n * Input shape:\n *   Arbitrary. Use the keyword argument `inputShape`\n *   (tuple of integers, does not include the samples axis)\n *   when using this layer as the first layer in a model.\n *\n * Output shape:\n *   Same shape as input.\n *\n * References:\n *   - [Self-Normalizing Neural Networks](https://arxiv.org/abs/1706.02515)\n */\n\nexport var AlphaDropout = /*#__PURE__*/function (_Layer3) {\n  _inherits(AlphaDropout, _Layer3);\n\n  function AlphaDropout(args) {\n    var _this5;\n\n    _classCallCheck(this, AlphaDropout);\n\n    _this5 = _possibleConstructorReturn(this, _getPrototypeOf(AlphaDropout).call(this, args));\n    _this5.supportsMasking = true;\n    _this5.rate = args.rate;\n    _this5.noiseShape = args.noiseShape;\n    return _this5;\n  }\n\n  _createClass(AlphaDropout, [{\n    key: \"_getNoiseShape\",\n    value: function _getNoiseShape(inputs) {\n      return this.noiseShape || getExactlyOneTensor(inputs).shape;\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      return inputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var baseConfig = _get(_getPrototypeOf(AlphaDropout.prototype), \"getConfig\", this).call(this);\n\n      var config = {\n        rate: this.rate\n      };\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this6 = this;\n\n      return tidy(function () {\n        if (_this6.rate < 1 && _this6.rate > 0) {\n          var noiseShape = _this6._getNoiseShape(inputs);\n\n          var droppedInputs = function droppedInputs() {\n            var input = getExactlyOneTensor(inputs);\n            var alpha = 1.6732632423543772848170429916717;\n            var scale = 1.0507009873554804934193349852946;\n            var alphaP = -alpha * scale;\n            var keptIdx = greaterEqual(randomUniform(noiseShape), _this6.rate);\n            keptIdx = K.cast(keptIdx, 'float32'); // get default dtype.\n            // Get affine transformation params.\n\n            var a = Math.pow((1 - _this6.rate) * (1 + _this6.rate * Math.pow(alphaP, 2)), -0.5);\n            var b = -a * alphaP * _this6.rate; // Apply mask.\n\n            var x = input.mul(keptIdx).add(keptIdx.add(-1).mul(alphaP));\n            return x.mul(a).add(b);\n          };\n\n          return K.inTrainPhase(droppedInputs, function () {\n            return getExactlyOneTensor(inputs);\n          }, kwargs['training'] || false);\n        }\n\n        return inputs;\n      });\n    }\n  }]);\n\n  return AlphaDropout;\n}(Layer);\n/** @nocollapse */\n\nAlphaDropout.className = 'AlphaDropout';\nserialization.registerClass(AlphaDropout);","map":null,"metadata":{},"sourceType":"module"}