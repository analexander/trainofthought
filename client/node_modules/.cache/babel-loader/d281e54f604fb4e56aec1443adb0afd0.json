{"ast":null,"code":"import _defineProperty from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/defineProperty\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _get from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * TensorFlow.js Layers: Convolutional Layers\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { serialization, tidy } from '@tensorflow/tfjs-core';\nimport { getActivation, serializeActivation } from '../activations';\nimport { imageDataFormat } from '../backend/common';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { getConstraint, serializeConstraint } from '../constraints';\nimport { InputSpec, Layer } from '../engine/topology';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { getInitializer, serializeInitializer } from '../initializers';\nimport { getRegularizer, serializeRegularizer } from '../regularizers';\nimport { convOutputLength, deconvLength, normalizeArray } from '../utils/conv_utils';\nimport * as generic_utils from '../utils/generic_utils';\nimport { getExactlyOneShape, getExactlyOneTensor } from '../utils/types_utils';\n/**\n * Transpose and cast the input before the conv2d.\n * @param x Input image tensor.\n * @param dataFormat\n */\n\nexport function preprocessConv2DInput(x, dataFormat) {\n  // TODO(cais): Cast type to float32 if not.\n  return tidy(function () {\n    checkDataFormat(dataFormat);\n\n    if (dataFormat === 'channelsFirst') {\n      return tfc.transpose(x, [0, 2, 3, 1]); // NCHW -> NHWC.\n    } else {\n      return x;\n    }\n  });\n}\n/**\n * Transpose and cast the input before the conv3d.\n * @param x Input image tensor.\n * @param dataFormat\n */\n\nexport function preprocessConv3DInput(x, dataFormat) {\n  return tidy(function () {\n    checkDataFormat(dataFormat);\n\n    if (dataFormat === 'channelsFirst') {\n      return tfc.transpose(x, [0, 2, 3, 4, 1]); // NCDHW -> NDHWC.\n    } else {\n      return x;\n    }\n  });\n}\n/**\n * 1D-convolution with bias added.\n *\n * Porting Note: This function does not exist in the Python Keras backend.\n *   It is exactly the same as `conv2d`, except the added `bias`.\n *\n * @param x Input tensor, rank-3, of shape `[batchSize, width, inChannels]`.\n * @param kernel Kernel, rank-3, of shape `[filterWidth, inDepth, outDepth]`.\n * @param bias Bias, rank-3, of shape `[outDepth]`.\n * @param strides\n * @param padding Padding mode.\n * @param dataFormat Data format.\n * @param dilationRate\n * @returns The result of the 1D convolution.\n * @throws ValueError, if `x`, `kernel` or `bias` is not of the correct rank.\n */\n\nexport function conv1dWithBias(x, kernel, bias) {\n  var strides = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 1;\n  var padding = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 'valid';\n  var dataFormat = arguments.length > 5 ? arguments[5] : undefined;\n  var dilationRate = arguments.length > 6 && arguments[6] !== undefined ? arguments[6] : 1;\n  return tidy(function () {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n\n    checkDataFormat(dataFormat); // Check the ranks of x, kernel and bias.\n\n    if (x.shape.length !== 3) {\n      throw new ValueError(\"The input of a conv1dWithBias operation should be 3, but is \" + \"\".concat(x.shape.length, \" instead.\"));\n    }\n\n    if (kernel.shape.length !== 3) {\n      throw new ValueError(\"The kernel for a conv1dWithBias operation should be 3, but is \" + \"\".concat(kernel.shape.length, \" instead\"));\n    }\n\n    if (bias != null && bias.shape.length !== 1) {\n      throw new ValueError(\"The bias for a conv1dWithBias operation should be 1, but is \" + \"\".concat(kernel.shape.length, \" instead\"));\n    } // TODO(cais): Support CAUSAL padding mode.\n\n\n    if (dataFormat === 'channelsFirst') {\n      x = tfc.transpose(x, [0, 2, 1]); // NCW -> NWC.\n    }\n\n    if (padding === 'causal') {\n      throw new NotImplementedError('The support for CAUSAL padding mode in conv1dWithBias is not ' + 'implemented yet.');\n    }\n\n    var y = tfc.conv1d(x, kernel, strides, padding === 'same' ? 'same' : 'valid', 'NWC', dilationRate);\n\n    if (bias != null) {\n      y = K.biasAdd(y, bias);\n    }\n\n    return y;\n  });\n}\n/**\n * 1D-convolution.\n *\n * @param x Input tensor, rank-3, of shape `[batchSize, width, inChannels]`.\n * @param kernel Kernel, rank-3, of shape `[filterWidth, inDepth, outDepth]`.s\n * @param strides\n * @param padding Padding mode.\n * @param dataFormat Data format.\n * @param dilationRate\n * @returns The result of the 1D convolution.\n * @throws ValueError, if `x`, `kernel` or `bias` is not of the correct rank.\n */\n\nexport function conv1d(x, kernel) {\n  var strides = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : 1;\n  var padding = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'valid';\n  var dataFormat = arguments.length > 4 ? arguments[4] : undefined;\n  var dilationRate = arguments.length > 5 && arguments[5] !== undefined ? arguments[5] : 1;\n  return tidy(function () {\n    checkDataFormat(dataFormat);\n    return conv1dWithBias(x, kernel, null, strides, padding, dataFormat, dilationRate);\n  });\n}\n/**\n * 2D Convolution\n * @param x\n * @param kernel kernel of the convolution.\n * @param strides strides array.\n * @param padding padding mode. Default to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param dilationRate dilation rate array.\n * @returns Result of the 2D pooling.\n */\n\nexport function conv2d(x, kernel) {\n  var strides = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [1, 1];\n  var padding = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'valid';\n  var dataFormat = arguments.length > 4 ? arguments[4] : undefined;\n  var dilationRate = arguments.length > 5 ? arguments[5] : undefined;\n  return tidy(function () {\n    checkDataFormat(dataFormat);\n    return conv2dWithBiasActivation(x, kernel, null, strides, padding, dataFormat, dilationRate);\n  });\n}\n/**\n * 2D Convolution with an added bias and optional activation.\n * Note: This function does not exist in the Python Keras Backend. This function\n * is exactly the same as `conv2d`, except the added `bias`.\n */\n\nexport function conv2dWithBiasActivation(x, kernel, bias) {\n  var strides = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1];\n  var padding = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 'valid';\n  var dataFormat = arguments.length > 5 ? arguments[5] : undefined;\n  var dilationRate = arguments.length > 6 ? arguments[6] : undefined;\n  var activation = arguments.length > 7 && arguments[7] !== undefined ? arguments[7] : null;\n  return tidy(function () {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n\n    checkDataFormat(dataFormat);\n\n    if (x.rank !== 3 && x.rank !== 4) {\n      throw new ValueError(\"conv2dWithBiasActivation expects input to be of rank 3 or 4, \" + \"but received \".concat(x.rank, \".\"));\n    }\n\n    if (kernel.rank !== 3 && kernel.rank !== 4) {\n      throw new ValueError(\"conv2dWithBiasActivation expects kernel to be of rank 3 or 4, \" + \"but received \".concat(x.rank, \".\"));\n    }\n\n    var y = preprocessConv2DInput(x, dataFormat);\n\n    if (padding === 'causal') {\n      throw new NotImplementedError('The support for CAUSAL padding mode in conv1dWithBias is not ' + 'implemented yet.');\n    }\n\n    y = tfc.fused.conv2d({\n      x: y,\n      filter: kernel,\n      strides: strides,\n      pad: padding === 'same' ? 'same' : 'valid',\n      dilations: dilationRate,\n      dataFormat: 'NHWC',\n      bias: bias,\n      activation: activation\n    });\n\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 3, 1, 2]);\n    }\n\n    return y;\n  });\n}\n/**\n * 3D Convolution.\n * @param x\n * @param kernel kernel of the convolution.\n * @param strides strides array.\n * @param padding padding mode. Default to 'valid'.\n * @param dataFormat data format. Defaults to 'channelsLast'.\n * @param dilationRate dilation rate array.\n * @returns Result of the 3D convolution.\n */\n\nexport function conv3d(x, kernel) {\n  var strides = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : [1, 1, 1];\n  var padding = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'valid';\n  var dataFormat = arguments.length > 4 ? arguments[4] : undefined;\n  var dilationRate = arguments.length > 5 ? arguments[5] : undefined;\n  return tidy(function () {\n    checkDataFormat(dataFormat);\n    return conv3dWithBias(x, kernel, null, strides, padding, dataFormat, dilationRate);\n  });\n}\n/**\n * 3D Convolution with an added bias.\n * Note: This function does not exist in the Python Keras Backend. This function\n * is exactly the same as `conv3d`, except the added `bias`.\n */\n\nexport function conv3dWithBias(x, kernel, bias) {\n  var strides = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : [1, 1, 1];\n  var padding = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : 'valid';\n  var dataFormat = arguments.length > 5 ? arguments[5] : undefined;\n  var dilationRate = arguments.length > 6 ? arguments[6] : undefined;\n  return tidy(function () {\n    if (dataFormat == null) {\n      dataFormat = imageDataFormat();\n    }\n\n    checkDataFormat(dataFormat);\n\n    if (x.rank !== 4 && x.rank !== 5) {\n      throw new ValueError(\"conv3dWithBias expects input to be of rank 4 or 5, but received \" + \"\".concat(x.rank, \".\"));\n    }\n\n    if (kernel.rank !== 4 && kernel.rank !== 5) {\n      throw new ValueError(\"conv3dWithBias expects kernel to be of rank 4 or 5, but received \" + \"\".concat(x.rank, \".\"));\n    }\n\n    var y = preprocessConv3DInput(x, dataFormat);\n\n    if (padding === 'causal') {\n      throw new NotImplementedError('The support for CAUSAL padding mode in conv3dWithBias is not ' + 'implemented yet.');\n    }\n\n    y = tfc.conv3d(y, kernel, strides, padding === 'same' ? 'same' : 'valid', 'NDHWC', dilationRate);\n\n    if (bias != null) {\n      y = K.biasAdd(y, bias);\n    }\n\n    if (dataFormat === 'channelsFirst') {\n      y = tfc.transpose(y, [0, 4, 1, 2, 3]);\n    }\n\n    return y;\n  });\n}\n/**\n * Abstract convolution layer.\n */\n\nexport var BaseConv = /*#__PURE__*/function (_Layer) {\n  _inherits(BaseConv, _Layer);\n\n  function BaseConv(rank, args) {\n    var _this;\n\n    _classCallCheck(this, BaseConv);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(BaseConv).call(this, args));\n    _this.bias = null;\n    _this.DEFAULT_KERNEL_INITIALIZER = 'glorotNormal';\n    _this.DEFAULT_BIAS_INITIALIZER = 'zeros';\n    BaseConv.verifyArgs(args);\n    _this.rank = rank;\n    generic_utils.assertPositiveInteger(_this.rank, 'rank');\n\n    if (_this.rank !== 1 && _this.rank !== 2 && _this.rank !== 3) {\n      throw new NotImplementedError(\"Convolution layer for rank other than 1, 2, or 3 (\".concat(_this.rank, \") is \") + \"not implemented yet.\");\n    }\n\n    _this.kernelSize = normalizeArray(args.kernelSize, rank, 'kernelSize');\n    _this.strides = normalizeArray(args.strides == null ? 1 : args.strides, rank, 'strides');\n    _this.padding = args.padding == null ? 'valid' : args.padding;\n    checkPaddingMode(_this.padding);\n    _this.dataFormat = args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n    checkDataFormat(_this.dataFormat);\n    _this.activation = getActivation(args.activation);\n    _this.useBias = args.useBias == null ? true : args.useBias;\n    _this.biasInitializer = getInitializer(args.biasInitializer || _this.DEFAULT_BIAS_INITIALIZER);\n    _this.biasConstraint = getConstraint(args.biasConstraint);\n    _this.biasRegularizer = getRegularizer(args.biasRegularizer);\n    _this.activityRegularizer = getRegularizer(args.activityRegularizer);\n    _this.dilationRate = normalizeArray(args.dilationRate == null ? 1 : args.dilationRate, rank, 'dilationRate');\n\n    if (_this.rank === 1 && Array.isArray(_this.dilationRate) && _this.dilationRate.length !== 1) {\n      throw new ValueError(\"dilationRate must be a number or an array of a single number \" + \"for 1D convolution, but received \" + \"\".concat(JSON.stringify(_this.dilationRate)));\n    } else if (_this.rank === 2) {\n      if (typeof _this.dilationRate === 'number') {\n        _this.dilationRate = [_this.dilationRate, _this.dilationRate];\n      } else if (_this.dilationRate.length !== 2) {\n        throw new ValueError(\"dilationRate must be a number or array of two numbers for 2D \" + \"convolution, but received \".concat(JSON.stringify(_this.dilationRate)));\n      }\n    } else if (_this.rank === 3) {\n      if (typeof _this.dilationRate === 'number') {\n        _this.dilationRate = [_this.dilationRate, _this.dilationRate, _this.dilationRate];\n      } else if (_this.dilationRate.length !== 3) {\n        throw new ValueError(\"dilationRate must be a number or array of three numbers for 3D \" + \"convolution, but received \".concat(JSON.stringify(_this.dilationRate)));\n      }\n    }\n\n    return _this;\n  }\n\n  _createClass(BaseConv, [{\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        kernelSize: this.kernelSize,\n        strides: this.strides,\n        padding: this.padding,\n        dataFormat: this.dataFormat,\n        dilationRate: this.dilationRate,\n        activation: serializeActivation(this.activation),\n        useBias: this.useBias,\n        biasInitializer: serializeInitializer(this.biasInitializer),\n        biasRegularizer: serializeRegularizer(this.biasRegularizer),\n        activityRegularizer: serializeRegularizer(this.activityRegularizer),\n        biasConstraint: serializeConstraint(this.biasConstraint)\n      };\n\n      var baseConfig = _get(_getPrototypeOf(BaseConv.prototype), \"getConfig\", this).call(this);\n\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }], [{\n    key: \"verifyArgs\",\n    value: function verifyArgs(args) {\n      // Check config.kernelSize type and shape.\n      generic_utils.assert('kernelSize' in args, \"required key 'kernelSize' not in config\");\n\n      if (typeof args.kernelSize !== 'number' && !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 3)) {\n        throw new ValueError(\"BaseConv expects config.kernelSize to be number or number[] with \" + \"length 1, 2, or 3, but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n      }\n    }\n  }]);\n\n  return BaseConv;\n}(Layer);\n/**\n * Abstract nD convolution layer.  Ancestor of convolution layers which reduce\n * across channels, i.e., Conv1D and Conv2D, but not DepthwiseConv2D.\n */\n\nexport var Conv = /*#__PURE__*/function (_BaseConv) {\n  _inherits(Conv, _BaseConv);\n\n  function Conv(rank, args) {\n    var _this2;\n\n    _classCallCheck(this, Conv);\n\n    _this2 = _possibleConstructorReturn(this, _getPrototypeOf(Conv).call(this, rank, args));\n    _this2.kernel = null;\n    Conv.verifyArgs(args);\n    _this2.filters = args.filters;\n    generic_utils.assertPositiveInteger(_this2.filters, 'filters');\n    _this2.kernelInitializer = getInitializer(args.kernelInitializer || _this2.DEFAULT_KERNEL_INITIALIZER);\n    _this2.kernelConstraint = getConstraint(args.kernelConstraint);\n    _this2.kernelRegularizer = getRegularizer(args.kernelRegularizer);\n    return _this2;\n  }\n\n  _createClass(Conv, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n      if (inputShape[channelAxis] == null) {\n        throw new ValueError(\"The channel dimension of the input should be defined. \" + \"Found \".concat(inputShape[channelAxis]));\n      }\n\n      var inputDim = inputShape[channelAxis];\n      var kernelShape = this.kernelSize.concat([inputDim, this.filters]);\n      this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.filters], null, this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n\n      this.inputSpec = [{\n        ndim: this.rank + 2,\n        axes: _defineProperty({}, channelAxis, inputDim)\n      }];\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this3 = this;\n\n      return tidy(function () {\n        inputs = getExactlyOneTensor(inputs);\n        var outputs;\n        var biasValue = _this3.bias == null ? null : _this3.bias.read();\n        var fusedActivationName = generic_utils.mapActivationToFusedKernel(_this3.activation.getClassName());\n\n        if (fusedActivationName != null && _this3.rank === 2) {\n          outputs = conv2dWithBiasActivation(inputs, _this3.kernel.read(), biasValue, _this3.strides, _this3.padding, _this3.dataFormat, _this3.dilationRate, fusedActivationName);\n        } else {\n          if (_this3.rank === 1) {\n            outputs = conv1dWithBias(inputs, _this3.kernel.read(), biasValue, _this3.strides[0], _this3.padding, _this3.dataFormat, _this3.dilationRate[0]);\n          } else if (_this3.rank === 2) {\n            // TODO(cais): Move up to constructor.\n            outputs = conv2dWithBiasActivation(inputs, _this3.kernel.read(), biasValue, _this3.strides, _this3.padding, _this3.dataFormat, _this3.dilationRate);\n          } else if (_this3.rank === 3) {\n            outputs = conv3dWithBias(inputs, _this3.kernel.read(), biasValue, _this3.strides, _this3.padding, _this3.dataFormat, _this3.dilationRate);\n          } else {\n            throw new NotImplementedError('convolutions greater than 3D are not implemented yet.');\n          }\n\n          if (_this3.activation != null) {\n            outputs = _this3.activation.apply(outputs);\n          }\n        }\n\n        return outputs;\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var newSpace = [];\n      var space = this.dataFormat === 'channelsLast' ? inputShape.slice(1, inputShape.length - 1) : inputShape.slice(2);\n\n      for (var i = 0; i < space.length; ++i) {\n        var newDim = convOutputLength(space[i], this.kernelSize[i], this.padding, this.strides[i], typeof this.dilationRate === 'number' ? this.dilationRate : this.dilationRate[i]);\n        newSpace.push(newDim);\n      }\n\n      var outputShape = [inputShape[0]];\n\n      if (this.dataFormat === 'channelsLast') {\n        outputShape = outputShape.concat(newSpace);\n        outputShape.push(this.filters);\n      } else {\n        outputShape.push(this.filters);\n        outputShape = outputShape.concat(newSpace);\n      }\n\n      return outputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        filters: this.filters,\n        kernelInitializer: serializeInitializer(this.kernelInitializer),\n        kernelRegularizer: serializeRegularizer(this.kernelRegularizer),\n        kernelConstraint: serializeConstraint(this.kernelConstraint)\n      };\n\n      var baseConfig = _get(_getPrototypeOf(Conv.prototype), \"getConfig\", this).call(this);\n\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }], [{\n    key: \"verifyArgs\",\n    value: function verifyArgs(args) {\n      // Check config.filters type, shape, and value.\n      if (!('filters' in args) || typeof args.filters !== 'number' || args.filters < 1) {\n        throw new ValueError(\"Convolution layer expected config.filters to be a 'number' > 0 \" + \"but got \".concat(JSON.stringify(args.filters)));\n      }\n    }\n  }]);\n\n  return Conv;\n}(BaseConv);\nexport var Conv2D = /*#__PURE__*/function (_Conv) {\n  _inherits(Conv2D, _Conv);\n\n  function Conv2D(args) {\n    var _this4;\n\n    _classCallCheck(this, Conv2D);\n\n    _this4 = _possibleConstructorReturn(this, _getPrototypeOf(Conv2D).call(this, 2, args));\n    Conv2D.verifyArgs(args);\n    return _this4;\n  }\n\n  _createClass(Conv2D, [{\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = _get(_getPrototypeOf(Conv2D.prototype), \"getConfig\", this).call(this);\n\n      delete config['rank'];\n      return config;\n    }\n  }], [{\n    key: \"verifyArgs\",\n    value: function verifyArgs(args) {\n      // config.kernelSize must be a number or array of numbers.\n      if (typeof args.kernelSize !== 'number' && !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 2)) {\n        throw new ValueError(\"Conv2D expects config.kernelSize to be number or number[] with \" + \"length 1 or 2, but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n      }\n    }\n  }]);\n\n  return Conv2D;\n}(Conv);\n/** @nocollapse */\n\nConv2D.className = 'Conv2D';\nserialization.registerClass(Conv2D);\nexport var Conv3D = /*#__PURE__*/function (_Conv2) {\n  _inherits(Conv3D, _Conv2);\n\n  function Conv3D(args) {\n    var _this5;\n\n    _classCallCheck(this, Conv3D);\n\n    _this5 = _possibleConstructorReturn(this, _getPrototypeOf(Conv3D).call(this, 3, args));\n    Conv3D.verifyArgs(args);\n    return _this5;\n  }\n\n  _createClass(Conv3D, [{\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = _get(_getPrototypeOf(Conv3D.prototype), \"getConfig\", this).call(this);\n\n      delete config['rank'];\n      return config;\n    }\n  }], [{\n    key: \"verifyArgs\",\n    value: function verifyArgs(args) {\n      // config.kernelSize must be a number or array of numbers.\n      if (typeof args.kernelSize !== 'number') {\n        if (!(Array.isArray(args.kernelSize) && (args.kernelSize.length === 1 || args.kernelSize.length === 3))) {\n          throw new ValueError(\"Conv3D expects config.kernelSize to be number or\" + \" [number, number, number], but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n        }\n      }\n    }\n  }]);\n\n  return Conv3D;\n}(Conv);\n/** @nocollapse */\n\nConv3D.className = 'Conv3D';\nserialization.registerClass(Conv3D);\nexport var Conv2DTranspose = /*#__PURE__*/function (_Conv2D) {\n  _inherits(Conv2DTranspose, _Conv2D);\n\n  function Conv2DTranspose(args) {\n    var _this6;\n\n    _classCallCheck(this, Conv2DTranspose);\n\n    _this6 = _possibleConstructorReturn(this, _getPrototypeOf(Conv2DTranspose).call(this, args));\n    _this6.inputSpec = [new InputSpec({\n      ndim: 4\n    })];\n\n    if (_this6.padding !== 'same' && _this6.padding !== 'valid') {\n      throw new ValueError(\"Conv2DTranspose currently supports only padding modes 'same' \" + \"and 'valid', but received padding mode \".concat(_this6.padding));\n    }\n\n    return _this6;\n  }\n\n  _createClass(Conv2DTranspose, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n\n      if (inputShape.length !== 4) {\n        throw new ValueError('Input should have rank 4; Received input shape: ' + JSON.stringify(inputShape));\n      }\n\n      var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n      if (inputShape[channelAxis] == null) {\n        throw new ValueError('The channel dimension of the inputs should be defined. ' + 'Found `None`.');\n      }\n\n      var inputDim = inputShape[channelAxis];\n      var kernelShape = this.kernelSize.concat([this.filters, inputDim]);\n      this.kernel = this.addWeight('kernel', kernelShape, 'float32', this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      } // Set input spec.\n\n\n      this.inputSpec = [new InputSpec({\n        ndim: 4,\n        axes: _defineProperty({}, channelAxis, inputDim)\n      })];\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this7 = this;\n\n      return tfc.tidy(function () {\n        var input = getExactlyOneTensor(inputs);\n\n        if (input.shape.length !== 4) {\n          throw new ValueError(\"Conv2DTranspose.call() expects input tensor to be rank-4, but \" + \"received a tensor of rank-\".concat(input.shape.length));\n        }\n\n        var inputShape = input.shape;\n        var batchSize = inputShape[0];\n        var hAxis;\n        var wAxis;\n\n        if (_this7.dataFormat === 'channelsFirst') {\n          hAxis = 2;\n          wAxis = 3;\n        } else {\n          hAxis = 1;\n          wAxis = 2;\n        }\n\n        var height = inputShape[hAxis];\n        var width = inputShape[wAxis];\n        var kernelH = _this7.kernelSize[0];\n        var kernelW = _this7.kernelSize[1];\n        var strideH = _this7.strides[0];\n        var strideW = _this7.strides[1]; // Infer the dynamic output shape.\n\n        var outHeight = deconvLength(height, strideH, kernelH, _this7.padding);\n        var outWidth = deconvLength(width, strideW, kernelW, _this7.padding); // Porting Note: We don't branch based on `this.dataFormat` here,\n        // because\n        //   the tjfs-core function `conv2dTranspose` called below always\n        //   assumes channelsLast.\n\n        var outputShape = [batchSize, outHeight, outWidth, _this7.filters];\n\n        if (_this7.dataFormat !== 'channelsLast') {\n          input = tfc.transpose(input, [0, 2, 3, 1]);\n        }\n\n        var outputs = tfc.conv2dTranspose(input, _this7.kernel.read(), outputShape, _this7.strides, _this7.padding);\n\n        if (_this7.dataFormat !== 'channelsLast') {\n          outputs = tfc.transpose(outputs, [0, 3, 1, 2]);\n        }\n\n        if (_this7.bias != null) {\n          outputs = K.biasAdd(outputs, _this7.bias.read(), _this7.dataFormat);\n        }\n\n        if (_this7.activation != null) {\n          outputs = _this7.activation.apply(outputs);\n        }\n\n        return outputs;\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n      var outputShape = inputShape.slice();\n      var channelAxis;\n      var heightAxis;\n      var widthAxis;\n\n      if (this.dataFormat === 'channelsFirst') {\n        channelAxis = 1;\n        heightAxis = 2;\n        widthAxis = 3;\n      } else {\n        channelAxis = 3;\n        heightAxis = 1;\n        widthAxis = 2;\n      }\n\n      var kernelH = this.kernelSize[0];\n      var kernelW = this.kernelSize[1];\n      var strideH = this.strides[0];\n      var strideW = this.strides[1];\n      outputShape[channelAxis] = this.filters;\n      outputShape[heightAxis] = deconvLength(outputShape[heightAxis], strideH, kernelH, this.padding);\n      outputShape[widthAxis] = deconvLength(outputShape[widthAxis], strideW, kernelW, this.padding);\n      return outputShape;\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = _get(_getPrototypeOf(Conv2DTranspose.prototype), \"getConfig\", this).call(this);\n\n      delete config['dilationRate'];\n      return config;\n    }\n  }]);\n\n  return Conv2DTranspose;\n}(Conv2D);\n/** @nocollapse */\n\nConv2DTranspose.className = 'Conv2DTranspose';\nserialization.registerClass(Conv2DTranspose);\nexport var SeparableConv = /*#__PURE__*/function (_Conv3) {\n  _inherits(SeparableConv, _Conv3);\n\n  function SeparableConv(rank, config) {\n    var _this8;\n\n    _classCallCheck(this, SeparableConv);\n\n    _this8 = _possibleConstructorReturn(this, _getPrototypeOf(SeparableConv).call(this, rank, config));\n    _this8.DEFAULT_DEPTHWISE_INITIALIZER = 'glorotUniform';\n    _this8.DEFAULT_POINTWISE_INITIALIZER = 'glorotUniform';\n    _this8.depthwiseKernel = null;\n    _this8.pointwiseKernel = null;\n\n    if (config.filters == null) {\n      throw new ValueError('The `filters` configuration field is required by SeparableConv, ' + 'but is unspecified.');\n    }\n\n    if (config.kernelInitializer != null || config.kernelRegularizer != null || config.kernelConstraint != null) {\n      throw new ValueError('Fields kernelInitializer, kernelRegularizer and kernelConstraint ' + 'are invalid for SeparableConv2D. Use depthwiseInitializer, ' + 'depthwiseRegularizer, depthwiseConstraint, pointwiseInitializer, ' + 'pointwiseRegularizer and pointwiseConstraint instead.');\n    }\n\n    if (config.padding != null && config.padding !== 'same' && config.padding !== 'valid') {\n      throw new ValueError(\"SeparableConv\".concat(_this8.rank, \"D supports only padding modes: \") + \"'same' and 'valid', but received \".concat(JSON.stringify(config.padding)));\n    }\n\n    _this8.depthMultiplier = config.depthMultiplier == null ? 1 : config.depthMultiplier;\n    _this8.depthwiseInitializer = getInitializer(config.depthwiseInitializer || _this8.DEFAULT_DEPTHWISE_INITIALIZER);\n    _this8.depthwiseRegularizer = getRegularizer(config.depthwiseRegularizer);\n    _this8.depthwiseConstraint = getConstraint(config.depthwiseConstraint);\n    _this8.pointwiseInitializer = getInitializer(config.depthwiseInitializer || _this8.DEFAULT_POINTWISE_INITIALIZER);\n    _this8.pointwiseRegularizer = getRegularizer(config.pointwiseRegularizer);\n    _this8.pointwiseConstraint = getConstraint(config.pointwiseConstraint);\n    return _this8;\n  }\n\n  _createClass(SeparableConv, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      inputShape = getExactlyOneShape(inputShape);\n\n      if (inputShape.length < this.rank + 2) {\n        throw new ValueError(\"Inputs to SeparableConv\".concat(this.rank, \"D should have rank \") + \"\".concat(this.rank + 2, \", but received input shape: \") + \"\".concat(JSON.stringify(inputShape)));\n      }\n\n      var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n      if (inputShape[channelAxis] == null || inputShape[channelAxis] < 0) {\n        throw new ValueError(\"The channel dimension of the inputs should be defined, \" + \"but found \".concat(JSON.stringify(inputShape[channelAxis])));\n      }\n\n      var inputDim = inputShape[channelAxis];\n      var depthwiseKernelShape = this.kernelSize.concat([inputDim, this.depthMultiplier]);\n      var pointwiseKernelShape = [];\n\n      for (var i = 0; i < this.rank; ++i) {\n        pointwiseKernelShape.push(1);\n      }\n\n      pointwiseKernelShape.push(inputDim * this.depthMultiplier, this.filters);\n      var trainable = true;\n      this.depthwiseKernel = this.addWeight('depthwise_kernel', depthwiseKernelShape, 'float32', this.depthwiseInitializer, this.depthwiseRegularizer, trainable, this.depthwiseConstraint);\n      this.pointwiseKernel = this.addWeight('pointwise_kernel', pointwiseKernelShape, 'float32', this.pointwiseInitializer, this.pointwiseRegularizer, trainable, this.pointwiseConstraint);\n\n      if (this.useBias) {\n        this.bias = this.addWeight('bias', [this.filters], 'float32', this.biasInitializer, this.biasRegularizer, trainable, this.biasConstraint);\n      } else {\n        this.bias = null;\n      }\n\n      this.inputSpec = [new InputSpec({\n        ndim: this.rank + 2,\n        axes: _defineProperty({}, channelAxis, inputDim)\n      })];\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this9 = this;\n\n      return tidy(function () {\n        inputs = getExactlyOneTensor(inputs);\n        var output;\n\n        if (_this9.rank === 1) {\n          throw new NotImplementedError('1D separable convolution is not implemented yet.');\n        } else if (_this9.rank === 2) {\n          if (_this9.dataFormat === 'channelsFirst') {\n            inputs = tfc.transpose(inputs, [0, 2, 3, 1]); // NCHW -> NHWC.\n          }\n\n          output = tfc.separableConv2d(inputs, _this9.depthwiseKernel.read(), _this9.pointwiseKernel.read(), _this9.strides, _this9.padding, _this9.dilationRate, 'NHWC');\n        }\n\n        if (_this9.useBias) {\n          output = K.biasAdd(output, _this9.bias.read(), _this9.dataFormat);\n        }\n\n        if (_this9.activation != null) {\n          output = _this9.activation.apply(output);\n        }\n\n        if (_this9.dataFormat === 'channelsFirst') {\n          output = tfc.transpose(output, [0, 3, 1, 2]); // NHWC -> NCHW.\n        }\n\n        return output;\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = _get(_getPrototypeOf(SeparableConv.prototype), \"getConfig\", this).call(this);\n\n      delete config['rank'];\n      delete config['kernelInitializer'];\n      delete config['kernelRegularizer'];\n      delete config['kernelConstraint'];\n      config['depthwiseInitializer'] = serializeInitializer(this.depthwiseInitializer);\n      config['pointwiseInitializer'] = serializeInitializer(this.pointwiseInitializer);\n      config['depthwiseRegularizer'] = serializeRegularizer(this.depthwiseRegularizer);\n      config['pointwiseRegularizer'] = serializeRegularizer(this.pointwiseRegularizer);\n      config['depthwiseConstraint'] = serializeConstraint(this.depthwiseConstraint);\n      config['pointwiseConstraint'] = serializeConstraint(this.pointwiseConstraint);\n      return config;\n    }\n  }]);\n\n  return SeparableConv;\n}(Conv);\n/** @nocollapse */\n\nSeparableConv.className = 'SeparableConv';\nexport var SeparableConv2D = /*#__PURE__*/function (_SeparableConv) {\n  _inherits(SeparableConv2D, _SeparableConv);\n\n  function SeparableConv2D(args) {\n    _classCallCheck(this, SeparableConv2D);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(SeparableConv2D).call(this, 2, args));\n  }\n\n  return SeparableConv2D;\n}(SeparableConv);\n/** @nocollapse */\n\nSeparableConv2D.className = 'SeparableConv2D';\nserialization.registerClass(SeparableConv2D);\nexport var Conv1D = /*#__PURE__*/function (_Conv4) {\n  _inherits(Conv1D, _Conv4);\n\n  function Conv1D(args) {\n    var _this10;\n\n    _classCallCheck(this, Conv1D);\n\n    _this10 = _possibleConstructorReturn(this, _getPrototypeOf(Conv1D).call(this, 1, args));\n    Conv1D.verifyArgs(args);\n    _this10.inputSpec = [{\n      ndim: 3\n    }];\n    return _this10;\n  }\n\n  _createClass(Conv1D, [{\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = _get(_getPrototypeOf(Conv1D.prototype), \"getConfig\", this).call(this);\n\n      delete config['rank'];\n      delete config['dataFormat'];\n      return config;\n    }\n  }], [{\n    key: \"verifyArgs\",\n    value: function verifyArgs(args) {\n      // config.kernelSize must be a number or array of numbers.\n      if (typeof args.kernelSize !== 'number' && !generic_utils.checkArrayTypeAndLength(args.kernelSize, 'number', 1, 1)) {\n        throw new ValueError(\"Conv1D expects config.kernelSize to be number or number[] with \" + \"length 1, but received \".concat(JSON.stringify(args.kernelSize), \".\"));\n      }\n    }\n  }]);\n\n  return Conv1D;\n}(Conv);\n/** @nocollapse */\n\nConv1D.className = 'Conv1D';\nserialization.registerClass(Conv1D);\nexport var Cropping2D = /*#__PURE__*/function (_Layer2) {\n  _inherits(Cropping2D, _Layer2);\n\n  function Cropping2D(args) {\n    var _this11;\n\n    _classCallCheck(this, Cropping2D);\n\n    _this11 = _possibleConstructorReturn(this, _getPrototypeOf(Cropping2D).call(this, args));\n\n    if (typeof args.cropping === 'number') {\n      _this11.cropping = [[args.cropping, args.cropping], [args.cropping, args.cropping]];\n    } else if (typeof args.cropping[0] === 'number') {\n      _this11.cropping = [[args.cropping[0], args.cropping[0]], [args.cropping[1], args.cropping[1]]];\n    } else {\n      _this11.cropping = args.cropping;\n    }\n\n    _this11.dataFormat = args.dataFormat === undefined ? 'channelsLast' : args.dataFormat;\n    _this11.inputSpec = [{\n      ndim: 4\n    }];\n    return _this11;\n  }\n\n  _createClass(Cropping2D, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      if (this.dataFormat === 'channelsFirst') {\n        return [inputShape[0], inputShape[1], inputShape[2] - this.cropping[0][0] - this.cropping[0][1], inputShape[3] - this.cropping[1][0] - this.cropping[1][1]];\n      } else {\n        return [inputShape[0], inputShape[1] - this.cropping[0][0] - this.cropping[0][1], inputShape[2] - this.cropping[1][0] - this.cropping[1][1], inputShape[3]];\n      }\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this12 = this;\n\n      return tidy(function () {\n        inputs = getExactlyOneTensor(inputs);\n\n        if (_this12.dataFormat === 'channelsLast') {\n          var hSliced = K.sliceAlongAxis(inputs, _this12.cropping[0][0], inputs.shape[1] - _this12.cropping[0][0] - _this12.cropping[0][1], 2);\n          return K.sliceAlongAxis(hSliced, _this12.cropping[1][0], inputs.shape[2] - _this12.cropping[1][1] - _this12.cropping[1][0], 3);\n        } else {\n          var _hSliced = K.sliceAlongAxis(inputs, _this12.cropping[0][0], inputs.shape[2] - _this12.cropping[0][0] - _this12.cropping[0][1], 3);\n\n          return K.sliceAlongAxis(_hSliced, _this12.cropping[1][0], inputs.shape[3] - _this12.cropping[1][1] - _this12.cropping[1][0], 4);\n        }\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        cropping: this.cropping,\n        dataFormat: this.dataFormat\n      };\n\n      var baseConfig = _get(_getPrototypeOf(Cropping2D.prototype), \"getConfig\", this).call(this);\n\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n\n  return Cropping2D;\n}(Layer);\n/** @nocollapse */\n\nCropping2D.className = 'Cropping2D';\nserialization.registerClass(Cropping2D);\nexport var UpSampling2D = /*#__PURE__*/function (_Layer3) {\n  _inherits(UpSampling2D, _Layer3);\n\n  function UpSampling2D(args) {\n    var _this13;\n\n    _classCallCheck(this, UpSampling2D);\n\n    _this13 = _possibleConstructorReturn(this, _getPrototypeOf(UpSampling2D).call(this, args));\n    _this13.DEFAULT_SIZE = [2, 2];\n    _this13.inputSpec = [{\n      ndim: 4\n    }];\n    _this13.size = args.size == null ? _this13.DEFAULT_SIZE : args.size;\n    _this13.dataFormat = args.dataFormat == null ? 'channelsLast' : args.dataFormat;\n    return _this13;\n  }\n\n  _createClass(UpSampling2D, [{\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      if (this.dataFormat === 'channelsFirst') {\n        var height = inputShape[2] == null ? null : this.size[0] * inputShape[2];\n        var width = inputShape[3] == null ? null : this.size[1] * inputShape[3];\n        return [inputShape[0], inputShape[1], height, width];\n      } else {\n        var _height = inputShape[1] == null ? null : this.size[0] * inputShape[1];\n\n        var _width = inputShape[2] == null ? null : this.size[1] * inputShape[2];\n\n        return [inputShape[0], _height, _width, inputShape[3]];\n      }\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this14 = this;\n\n      return tfc.tidy(function () {\n        var input = getExactlyOneTensor(inputs);\n        var inputShape = input.shape;\n\n        if (_this14.dataFormat === 'channelsFirst') {\n          input = tfc.transpose(input, [0, 2, 3, 1]);\n          var height = _this14.size[0] * inputShape[2];\n          var width = _this14.size[1] * inputShape[3];\n          var resized = input.resizeNearestNeighbor([height, width]);\n          return tfc.transpose(resized, [0, 3, 1, 2]);\n        } else {\n          var _height2 = _this14.size[0] * inputShape[1];\n\n          var _width2 = _this14.size[1] * inputShape[2];\n\n          return input.resizeNearestNeighbor([_height2, _width2]);\n        }\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var config = {\n        size: this.size,\n        dataFormat: this.dataFormat\n      };\n\n      var baseConfig = _get(_getPrototypeOf(UpSampling2D.prototype), \"getConfig\", this).call(this);\n\n      Object.assign(config, baseConfig);\n      return config;\n    }\n  }]);\n\n  return UpSampling2D;\n}(Layer);\n/** @nocollapse */\n\nUpSampling2D.className = 'UpSampling2D';\nserialization.registerClass(UpSampling2D);","map":null,"metadata":{},"sourceType":"module"}