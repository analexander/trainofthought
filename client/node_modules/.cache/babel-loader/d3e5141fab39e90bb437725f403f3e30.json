{"ast":null,"code":"\"use strict\";\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nvar __extends = this && this.__extends || function () {\n  var _extendStatics = function extendStatics(d, b) {\n    _extendStatics = Object.setPrototypeOf || {\n      __proto__: []\n    } instanceof Array && function (d, b) {\n      d.__proto__ = b;\n    } || function (d, b) {\n      for (var p in b) {\n        if (b.hasOwnProperty(p)) d[p] = b[p];\n      }\n    };\n\n    return _extendStatics(d, b);\n  };\n\n  return function (d, b) {\n    _extendStatics(d, b);\n\n    function __() {\n      this.constructor = d;\n    }\n\n    d.prototype = b === null ? Object.create(b) : (__.prototype = b.prototype, new __());\n  };\n}();\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [op[0] & 2, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\n\nvar path = require(\"path\");\n\nvar ProgressBar = require(\"progress\");\n\nvar tensorboard_1 = require(\"./tensorboard\"); // A helper class created for testing with the jasmine `spyOn` method, which\n// operates only on member methods of objects.\n// tslint:disable-next-line:no-any\n\n\nexports.progressBarHelper = {\n  ProgressBar: ProgressBar,\n  log: console.log\n};\n/**\n * Terminal-based progress bar callback for tf.Model.fit().\n */\n\nvar ProgbarLogger =\n/** @class */\nfunction (_super) {\n  __extends(ProgbarLogger, _super);\n  /**\n   * Construtor of LoggingCallback.\n   */\n\n\n  function ProgbarLogger() {\n    var _this = _super.call(this, {\n      onTrainBegin: function onTrainBegin(logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var samples, batchSize, steps;\n          return __generator(this, function (_a) {\n            samples = this.params.samples;\n            batchSize = this.params.batchSize;\n            steps = this.params.steps;\n\n            if (samples != null || steps != null) {\n              this.numTrainBatchesPerEpoch = samples != null ? Math.ceil(samples / batchSize) : steps;\n            } else {\n              // Undetermined number of batches per epoch, e.g., due to\n              // `fitDataset()` without `batchesPerEpoch`.\n              this.numTrainBatchesPerEpoch = 0;\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onEpochBegin: function onEpochBegin(epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            exports.progressBarHelper.log(\"Epoch \" + (epoch + 1) + \" / \" + this.params.epochs);\n            this.currentEpochBegin = tfjs_1.util.now();\n            this.epochDurationMillis = null;\n            this.usPerStep = null;\n            this.batchesInLatestEpoch = 0;\n            this.terminalWidth = process.stderr.columns;\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onBatchEnd: function onBatchEnd(batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var maxMetricsStringLength, tickTokens;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                this.batchesInLatestEpoch++;\n\n                if (batch === 0) {\n                  this.progressBar = new exports.progressBarHelper.ProgressBar('eta=:eta :bar :placeholderForLossesAndMetrics', {\n                    width: Math.floor(0.5 * this.terminalWidth),\n                    total: this.numTrainBatchesPerEpoch + 1,\n                    head: \">\",\n                    renderThrottle: this.RENDER_THROTTLE_MS\n                  });\n                }\n\n                maxMetricsStringLength = Math.floor(this.terminalWidth * 0.5 - 12);\n                tickTokens = {\n                  placeholderForLossesAndMetrics: this.formatLogsAsMetricsContent(logs, maxMetricsStringLength)\n                };\n\n                if (this.numTrainBatchesPerEpoch === 0) {\n                  // Undetermined number of batches per epoch.\n                  this.progressBar.tick(0, tickTokens);\n                } else {\n                  this.progressBar.tick(tickTokens);\n                }\n\n                return [4\n                /*yield*/\n                , tfjs_1.nextFrame()];\n\n              case 1:\n                _a.sent();\n\n                if (batch === this.numTrainBatchesPerEpoch - 1) {\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.params.samples != null ? this.epochDurationMillis / this.params.samples * 1e3 : this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n\n                return [2\n                /*return*/\n                ];\n            }\n          });\n        });\n      },\n      onEpochEnd: function onEpochEnd(epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          var lossesAndMetricsString;\n          return __generator(this, function (_a) {\n            switch (_a.label) {\n              case 0:\n                if (this.epochDurationMillis == null) {\n                  // In cases where the number of batches per epoch is not determined,\n                  // the calculation of the per-step duration is done at the end of the\n                  // epoch. N.B., this includes the time spent on validation.\n                  this.epochDurationMillis = tfjs_1.util.now() - this.currentEpochBegin;\n                  this.usPerStep = this.epochDurationMillis / this.batchesInLatestEpoch * 1e3;\n                }\n\n                this.progressBar.tick({\n                  placeholderForLossesAndMetrics: ''\n                });\n                lossesAndMetricsString = this.formatLogsAsMetricsContent(logs);\n                exports.progressBarHelper.log(this.epochDurationMillis.toFixed(0) + \"ms \" + (this.usPerStep.toFixed(0) + \"us/step - \") + (\"\" + lossesAndMetricsString));\n                return [4\n                /*yield*/\n                , tfjs_1.nextFrame()];\n\n              case 1:\n                _a.sent();\n\n                return [2\n                /*return*/\n                ];\n            }\n          });\n        });\n      }\n    }) || this;\n\n    _this.RENDER_THROTTLE_MS = 50;\n    return _this;\n  }\n\n  ProgbarLogger.prototype.formatLogsAsMetricsContent = function (logs, maxMetricsLength) {\n    var metricsContent = '';\n    var keys = Object.keys(logs).sort();\n\n    for (var _i = 0, keys_1 = keys; _i < keys_1.length; _i++) {\n      var key = keys_1[_i];\n\n      if (this.isFieldRelevant(key)) {\n        var value = logs[key];\n        metricsContent += key + \"=\" + getSuccinctNumberDisplay(value) + \" \";\n      }\n    }\n\n    if (maxMetricsLength != null && metricsContent.length > maxMetricsLength) {\n      // Cut off metrics strings that are too long to avoid new lines being\n      // constantly created.\n      metricsContent = metricsContent.slice(0, maxMetricsLength - 3) + '...';\n    }\n\n    return metricsContent;\n  };\n\n  ProgbarLogger.prototype.isFieldRelevant = function (key) {\n    return key !== 'batch' && key !== 'size';\n  };\n\n  return ProgbarLogger;\n}(tfjs_1.CustomCallback);\n\nexports.ProgbarLogger = ProgbarLogger;\nvar BASE_NUM_DIGITS = 2;\nvar MAX_NUM_DECIMAL_PLACES = 4;\n/**\n * Get a succint string representation of a number.\n *\n * Uses decimal notation if the number isn't too small.\n * Otherwise, use engineering notation.\n *\n * @param x Input number.\n * @return Succinct string representing `x`.\n */\n\nfunction getSuccinctNumberDisplay(x) {\n  var decimalPlaces = getDisplayDecimalPlaces(x);\n  return decimalPlaces > MAX_NUM_DECIMAL_PLACES ? x.toExponential(BASE_NUM_DIGITS) : x.toFixed(decimalPlaces);\n}\n\nexports.getSuccinctNumberDisplay = getSuccinctNumberDisplay;\n/**\n * Determine the number of decimal places to display.\n *\n * @param x Number to display.\n * @return Number of decimal places to display for `x`.\n */\n\nfunction getDisplayDecimalPlaces(x) {\n  if (!Number.isFinite(x) || x === 0 || x > 1 || x < -1) {\n    return BASE_NUM_DIGITS;\n  } else {\n    return BASE_NUM_DIGITS - Math.floor(Math.log10(Math.abs(x)));\n  }\n}\n\nexports.getDisplayDecimalPlaces = getDisplayDecimalPlaces;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Users are expected to access this class through the `tensorBoardCallback()`\n * factory method instead.\n */\n\nvar TensorBoardCallback =\n/** @class */\nfunction (_super) {\n  __extends(TensorBoardCallback, _super);\n\n  function TensorBoardCallback(logdir, args) {\n    if (logdir === void 0) {\n      logdir = './logs';\n    }\n\n    var _this = _super.call(this, {\n      onBatchEnd: function onBatchEnd(batch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.batchesSeen++;\n\n            if (this.args.updateFreq !== 'epoch') {\n              this.logMetrics(logs, 'batch_', this.batchesSeen);\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onEpochEnd: function onEpochEnd(epoch, logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            this.logMetrics(logs, 'epoch_', epoch + 1);\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      },\n      onTrainEnd: function onTrainEnd(logs) {\n        return __awaiter(_this, void 0, void 0, function () {\n          return __generator(this, function (_a) {\n            if (this.trainWriter != null) {\n              this.trainWriter.flush();\n            }\n\n            if (this.valWriter != null) {\n              this.valWriter.flush();\n            }\n\n            return [2\n            /*return*/\n            ];\n          });\n        });\n      }\n    }) || this;\n\n    _this.logdir = logdir;\n    _this.args = args == null ? {} : args;\n\n    if (_this.args.updateFreq == null) {\n      _this.args.updateFreq = 'epoch';\n    }\n\n    tfjs_1.util.assert(['batch', 'epoch'].indexOf(_this.args.updateFreq) !== -1, function () {\n      return \"Expected updateFreq to be 'batch' or 'epoch', but got \" + (\"\" + _this.args.updateFreq);\n    });\n    _this.batchesSeen = 0;\n    return _this;\n  }\n\n  TensorBoardCallback.prototype.logMetrics = function (logs, prefix, step) {\n    for (var key in logs) {\n      if (key === 'batch' || key === 'size' || key === 'num_steps') {\n        continue;\n      }\n\n      var VAL_PREFIX = 'val_';\n\n      if (key.startsWith(VAL_PREFIX)) {\n        this.ensureValWriterCreated();\n        var scalarName = prefix + key.slice(VAL_PREFIX.length);\n        this.valWriter.scalar(scalarName, logs[key], step);\n      } else {\n        this.ensureTrainWriterCreated();\n        this.trainWriter.scalar(\"\" + prefix + key, logs[key], step);\n      }\n    }\n  };\n\n  TensorBoardCallback.prototype.ensureTrainWriterCreated = function () {\n    this.trainWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'train'));\n  };\n\n  TensorBoardCallback.prototype.ensureValWriterCreated = function () {\n    this.valWriter = tensorboard_1.summaryFileWriter(path.join(this.logdir, 'val'));\n  };\n\n  return TensorBoardCallback;\n}(tfjs_1.CustomCallback);\n\nexports.TensorBoardCallback = TensorBoardCallback;\n/**\n * Callback for logging to TensorBoard during training.\n *\n * Writes the loss and metric values (if any) to the specified log directory\n * (`logdir`) which can be ingested and visualized by TensorBoard.\n * This callback is usually passed as a callback to `tf.Model.fit()` or\n * `tf.Model.fitDataset()` calls during model training. The frequency at which\n * the values are logged can be controlled with the `updateFreq` field of the\n * configuration object (2nd argument).\n *\n * Usage example:\n * ```js\n * // Constructor a toy multilayer-perceptron regressor for demo purpose.\n * const model = tf.sequential();\n * model.add(\n *     tf.layers.dense({units: 100, activation: 'relu', inputShape: [200]}));\n * model.add(tf.layers.dense({units: 1}));\n * model.compile({\n *   loss: 'meanSquaredError',\n *   optimizer: 'sgd',\n *   metrics: ['MAE']\n * });\n *\n * // Generate some random fake data for demo purpose.\n * const xs = tf.randomUniform([10000, 200]);\n * const ys = tf.randomUniform([10000, 1]);\n * const valXs = tf.randomUniform([1000, 200]);\n * const valYs = tf.randomUniform([1000, 1]);\n *\n * // Start model training process.\n * await model.fit(xs, ys, {\n *   epochs: 100,\n *   validationData: [valXs, valYs],\n *    // Add the tensorBoard callback here.\n *   callbacks: tf.node.tensorBoard('/tmp/fit_logs_1')\n * });\n * ```\n *\n * Then you can use the following commands to point tensorboard\n * to the logdir:\n *\n * ```sh\n * pip install tensorboard  # Unless you've already installed it.\n * tensorboard --logdir /tmp/fit_logs_1\n * ```\n *\n * @param logdir Directory to which the logs will be written.\n * @param args Optional configuration arguments.\n * @returns An instance of `TensorBoardCallback`, which is a subclass of\n *   `tf.CustomCallback`.\n *\n * @doc {heading: 'TensorBoard', namespace: 'node'}\n */\n\nfunction tensorBoard(logdir, args) {\n  if (logdir === void 0) {\n    logdir = './logs';\n  }\n\n  return new TensorBoardCallback(logdir, args);\n}\n\nexports.tensorBoard = tensorBoard;","map":null,"metadata":{},"sourceType":"script"}