{"ast":null,"code":"import _toConsumableArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _get from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it; if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = o[Symbol.iterator](); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/* Original Source: engine/training.py */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { io, Optimizer, scalar, serialization, Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { nameScope } from '../common';\nimport { NotImplementedError, RuntimeError, ValueError } from '../errors';\nimport { deserialize } from '../layers/serialization';\nimport * as losses from '../losses';\nimport * as Metrics from '../metrics';\nimport * as optimizers from '../optimizers';\nimport { checkUserDefinedMetadata } from '../user_defined_metadata';\nimport { count, pyListRepeat, singletonOrArray, toCamelCase, toSnakeCase, unique } from '../utils/generic_utils';\nimport { printSummary } from '../utils/layer_utils';\nimport { range } from '../utils/math_utils';\nimport { convertPythonicToTs } from '../utils/serialization_utils';\nimport { version } from '../version';\nimport { Container } from './container';\nimport { execute as _execute, FeedDict } from './executor';\nimport { evaluateDataset as _evaluateDataset, fitDataset as _fitDataset } from './training_dataset';\nimport { checkBatchSize, disposeNewTensors, ensureTensorsRank2OrHigher, fitTensors, makeBatches, sliceArrays, sliceArraysByIndices } from './training_tensors';\nimport { computeWeightedLoss, standardizeClassWeights, standardizeWeights } from './training_utils';\n/**\n * Helper function for polymorphic input data: 1. singleton Tensor.\n */\n\nexport function isDataTensor(x) {\n  return x instanceof Tensor;\n}\n/**\n * Helper function for polymorphic input data: 2. Array of Tensor.\n */\n\nexport function isDataArray(x) {\n  return Array.isArray(x);\n}\n/**\n * Helper function for polymorphic input data: 3. \"dict\" of Tensor.\n */\n\nexport function isDataDict(x) {\n  return !isDataTensor(x) && !isDataArray(x);\n}\n/**\n * Normalizes inputs and targets provided by users.\n * @param data User-provided input data (polymorphic).\n * @param names An Array of expected Tensor names.\n * @param shapes Optional Array of expected Tensor shapes.\n * @param checkBatchAxis Whether to check that the batch axis of the arrays\n *   match  the expected value found in `shapes`.\n * @param exceptionPrefix String prefix used for exception formatting.\n * @returns List of standardized input Tensors (one Tensor per model input).\n * @throws ValueError: in case of improperly formatted user data.\n */\n\nexport function standardizeInputData(data, names, shapes) {\n  var checkBatchAxis = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : true;\n  var exceptionPrefix = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : '';\n\n  if (names == null || names.length === 0) {\n    // Check for the case where the model expected no data, but some data got\n    // sent.\n    if (data != null) {\n      var gotUnexpectedData = false;\n\n      if (isDataArray(data) && data.length > 0) {\n        gotUnexpectedData = true;\n      } else if (isDataDict(data)) {\n        for (var key in data) {\n          if (data.hasOwnProperty(key)) {\n            gotUnexpectedData = true;\n            break;\n          }\n        }\n      } else {\n        // `data` is a singleton Tensor in this case.\n        gotUnexpectedData = true;\n      }\n\n      if (gotUnexpectedData) {\n        throw new ValueError(\"Error when checking model \".concat(exceptionPrefix, \" expected no data, \") + \"but got \".concat(data));\n      }\n    }\n\n    return [];\n  }\n\n  if (data == null) {\n    return names.map(function (name) {\n      return null;\n    });\n  }\n\n  var arrays;\n\n  if (isDataDict(data)) {\n    data = data;\n    arrays = [];\n\n    var _iterator = _createForOfIteratorHelper(names),\n        _step;\n\n    try {\n      for (_iterator.s(); !(_step = _iterator.n()).done;) {\n        var name = _step.value;\n\n        if (data[name] == null) {\n          throw new ValueError(\"No data provided for \\\"\".concat(name, \"\\\". Need data for each key in: \") + \"\".concat(names));\n        }\n\n        arrays.push(data[name]);\n      }\n    } catch (err) {\n      _iterator.e(err);\n    } finally {\n      _iterator.f();\n    }\n  } else if (isDataArray(data)) {\n    data = data;\n\n    if (data.length !== names.length) {\n      throw new ValueError(\"Error when checking model \".concat(exceptionPrefix, \": the Array of \") + \"Tensors that you are passing to your model is not the size the \" + \"model expected. Expected to see \".concat(names.length, \" Tensor(s), but \") + \"instead got the following list of Tensor(s): \".concat(data));\n    }\n\n    arrays = data;\n  } else {\n    data = data;\n\n    if (names.length > 1) {\n      throw new ValueError(\"The model \".concat(exceptionPrefix, \" expects \").concat(names.length, \" Tensor(s), \") + \"but only received one Tensor. Found: Tensor with shape \".concat(data.shape));\n    }\n\n    arrays = [data];\n  }\n\n  arrays = ensureTensorsRank2OrHigher(arrays); // Check shape compatibility.\n\n  if (shapes != null) {\n    for (var i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      var array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(\"Error when checking \".concat(exceptionPrefix, \": expected \").concat(names[i], \" \") + \"to have \".concat(shapes[i].length, \" dimension(s). but got array with \") + \"shape \".concat(array.shape));\n      }\n\n      for (var j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          // Skip the first (batch) axis.\n          continue;\n        }\n\n        var dim = array.shape[j];\n        var refDim = shapes[i][j];\n\n        if (refDim != null && refDim >= 0 && dim !== refDim) {\n          throw new ValueError(\"Error when checking \".concat(exceptionPrefix, \": expected \").concat(names[i], \" \") + \"to have shape [\".concat(shapes[i], \"], but got array with shape \") + \"[\".concat(array.shape, \"].\"));\n        }\n      }\n    }\n  }\n\n  return arrays;\n}\n/**\n * User input validation for Tensors.\n * @param inputs `Array` of `tf.Tensor`s for inputs.\n * @param targets `Array` of `tf.Tensor`s for targets.\n * @param weights Optional `Array` of `tf.Tensor`s for sample weights.\n * @throws ValueError: in case of incorrectly formatted data.\n */\n\nexport function checkArrayLengths(inputs, targets, weights) {\n  var setX = unique(inputs.map(function (input) {\n    return input.shape[0];\n  }));\n  setX.sort();\n  var setY = unique(targets.map(function (target) {\n    return target.shape[0];\n  }));\n  setY.sort(); // TODO(cais): Check `weights` as well.\n\n  if (setX.length > 1) {\n    throw new ValueError(\"All input Tensors (x) should have the same number of samples. \" + \"Got array shapes: \" + \"\".concat(JSON.stringify(inputs.map(function (input) {\n      return input.shape;\n    }))));\n  }\n\n  if (setY.length > 1) {\n    throw new ValueError(\"All target Tensors (y) should have the same number of samples. \" + \"Got array shapes: \" + \"\".concat(JSON.stringify(targets.map(function (target) {\n      return target.shape;\n    }))));\n  }\n\n  if (setX.length > 0 && setY.length > 0 && !util.arraysEqual(setX, setY)) {\n    throw new ValueError(\"Input Tensors should have the same number of samples as target \" + \"Tensors. Found \".concat(setX[0], \" input sample(s) and \").concat(setY[0], \" target \") + \"sample(s).\");\n  }\n}\n/**\n * Validation on the compatibility of targes and loss functions.\n *\n * This helps prevent users from using loss functions incorrectly.\n *\n * @param targets `Array` of `tf.Tensor`s of targets.\n * @param lossFns `Array` of loss functions.\n * @param outputShapes `Array` of shapes of model outputs.\n */\n\nfunction checkLossAndTargetCompatibility(targets, lossFns, outputShapes) {\n  // TODO(cais): Dedicated test coverage?\n  var keyLosses = [losses.meanSquaredError, losses.binaryCrossentropy, losses.categoricalCrossentropy];\n\n  for (var i = 0; i < targets.length; ++i) {\n    var y = targets[i];\n    var loss = lossFns[i];\n    var shape = outputShapes[i];\n\n    if (loss == null) {\n      continue;\n    }\n\n    if (loss === losses.categoricalCrossentropy) {\n      if (y.shape[y.shape.length - 1] === 1) {\n        throw new ValueError(\"You are passing a target array of shape \".concat(y.shape, \" while using \") + \"a loss 'categorical_crossentropy'. 'categorical_crossentropy'\" + \"expects targets to be binary matrices (1s and 0s) of shape \" + \"[samples, classes].\"); // TODO(cais): Example code in error message.\n      }\n    }\n\n    if (keyLosses.indexOf(loss) !== -1) {\n      var slicedYShape = y.shape.slice(1);\n      var slicedShape = shape.slice(1);\n\n      for (var j = 0; j < slicedYShape.length; ++j) {\n        var targetDim = slicedYShape[j];\n        var outDim = slicedShape[j];\n\n        if (outDim != null && targetDim !== outDim) {\n          throw new ValueError(\"A target Tensor with shape \".concat(y.shape, \" was passed for an \") + \"output of shape \".concat(shape, \", while using a loss function that \") + \"expects targets to have the same shape as the output.\");\n        }\n      }\n    }\n  }\n}\n/**\n * Check inputs provided by the user.\n *\n * Porting Note: This corresponds to _standardize_input_data() in Python\n *   Keras. Because of the strong typing in TF.js, we do not need to convert\n *   the data. Specifically:\n *   1) in PyKeras, `data` can be `DataFrame` instances from pandas, for\n *      example. We don't need to worry about that here because there is no\n *      widely popular javascript/typesdcript equivalent of pandas (so far).\n *      If one becomes available in the future, we can add support.\n *   2) in PyKeras, inputs can be Python dict. But here we are stipulating\n * that the data is either a single `tf.Tensor` or an Array of `tf.Tensor`s. We\n * may add support for `Object` data inputs in the future when the need\n * arises.\n *\n * Instead, we perform basic checks for number of parameters and shapes.\n *\n * @param data: The input data.\n * @param names: Name for the inputs, from the model.\n * @param shapes: Expected shapes for the input data, from the model.\n * @param checkBatchAxis: Whether the size along the batch axis (i.e., the\n *   first dimension) will be checked for matching.\n * @param exceptionPrefix: Execption prefix message, used in generating error\n *   messages.\n * @throws ValueError: on incorrect number of inputs or mismatches in shapes.\n */\n\n\nfunction checkInputData(data, names, shapes) {\n  var checkBatchAxis = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : true;\n  var exceptionPrefix = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : '';\n  var arrays;\n\n  if (Array.isArray(data)) {\n    if (data.length !== names.length) {\n      throw new ValueError(\"Error when checking model \".concat(exceptionPrefix, \": the Array of \") + \"Tensors that you are passing to your model is not the size the \" + \"the model expected. Expected to see \".concat(names.length, \" Tensor(s),\") + \" but instead got \".concat(data.length, \" Tensors(s).\"));\n    }\n\n    arrays = data;\n  } else {\n    if (names.length > 1) {\n      throw new ValueError(\"The model expects \".concat(names.length, \" \").concat(exceptionPrefix, \" Tensors, \") + \"but only received one Tensor. Found: array with shape \" + \"\".concat(JSON.stringify(data.shape), \".\"));\n    }\n\n    arrays = [data];\n  }\n\n  if (shapes != null) {\n    for (var i = 0; i < names.length; ++i) {\n      if (shapes[i] == null) {\n        continue;\n      }\n\n      var array = arrays[i];\n\n      if (array.shape.length !== shapes[i].length) {\n        throw new ValueError(\"Error when checking \".concat(exceptionPrefix, \": expected \").concat(names[i], \" \") + \"to have \".concat(shapes[i].length, \" dimension(s), but got array with \") + \"shape \".concat(JSON.stringify(array.shape)));\n      }\n\n      for (var j = 0; j < shapes[i].length; ++j) {\n        if (j === 0 && !checkBatchAxis) {\n          continue;\n        }\n\n        var dim = array.shape[j];\n        var refDim = shapes[i][j];\n\n        if (refDim != null) {\n          if (refDim !== dim) {\n            throw new ValueError(\"Error when checking \".concat(exceptionPrefix, \": expected \") + \"\".concat(names[i], \" to have shape \").concat(JSON.stringify(shapes[i]), \" but \") + \"got array with shape \".concat(JSON.stringify(array.shape), \".\"));\n          }\n        }\n      }\n    }\n  }\n}\n/**\n * Maps metric functions to model outputs.\n * @param metrics An shortcut strings name, metric function, `Array` or dict\n *   (`Object`) of metric functions.\n * @param outputNames An `Array` of the names of model outputs.\n * @returns An `Array` (one entry per model output) of `Array` of metric\n *   functions. For instance, if the model has 2 outputs, and for the first\n *   output we want to compute `binaryAccuracy` and `binaryCrossentropy`,\n *   and just `binaryAccuracy` for the second output, the `Array` would look\n *   like:\n *     `[[binaryAccuracy, binaryCrossentropy],  [binaryAccuracy]]`\n * @throws TypeError: incompatible metrics format.\n */\n\n\nexport function collectMetrics(metrics, outputNames) {\n  if (metrics == null || Array.isArray(metrics) && metrics.length === 0) {\n    return outputNames.map(function (name) {\n      return [];\n    });\n  }\n\n  var wrappedMetrics;\n\n  if (typeof metrics === 'string' || typeof metrics === 'function') {\n    wrappedMetrics = [metrics];\n  } else if (Array.isArray(metrics) || typeof metrics === 'object') {\n    wrappedMetrics = metrics;\n  } else {\n    throw new TypeError('Type of metrics argument not understood. Expected an string,' + \"function, Array, or Object, found: \".concat(metrics));\n  }\n\n  if (Array.isArray(wrappedMetrics)) {\n    // We then apply all metrics to all outputs.\n    return outputNames.map(function (name) {\n      return wrappedMetrics;\n    });\n  } else {\n    // In this case, metrics is a dict.\n    var nestedMetrics = [];\n\n    var _iterator2 = _createForOfIteratorHelper(outputNames),\n        _step2;\n\n    try {\n      for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n        var name = _step2.value;\n        var outputMetrics = wrappedMetrics.hasOwnProperty(name) ? wrappedMetrics[name] : [];\n\n        if (!Array.isArray(outputMetrics)) {\n          outputMetrics = [outputMetrics];\n        }\n\n        nestedMetrics.push(outputMetrics);\n      }\n    } catch (err) {\n      _iterator2.e(err);\n    } finally {\n      _iterator2.f();\n    }\n\n    return nestedMetrics;\n  }\n}\nvar LAYERS_MODEL_FORMAT_NAME = 'layers-model';\n/**\n * A `tf.LayersModel` is a directed, acyclic graph of `tf.Layer`s plus methods\n * for training, evaluation, prediction and saving.\n *\n * `tf.LayersModel` is the basic unit of training, inference and evaluation in\n * TensorFlow.js. To create a `tf.LayersModel`, use `tf.LayersModel`.\n *\n * See also:\n *   `tf.Sequential`, `tf.loadLayersModel`.\n *\n * @doc {heading: 'Models', subheading: 'Classes'}\n */\n\nexport var LayersModel = /*#__PURE__*/function (_Container) {\n  _inherits(LayersModel, _Container);\n\n  function LayersModel(args) {\n    var _this;\n\n    _classCallCheck(this, LayersModel);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(LayersModel).call(this, args));\n    _this.isTraining = false;\n    return _this;\n  }\n  /**\n   * Print a text summary of the model's layers.\n   *\n   * The summary includes\n   * - Name and type of all layers that comprise the model.\n   * - Output shape(s) of the layers\n   * - Number of weight parameters of each layer\n   * - If the model has non-sequential-like topology, the inputs each layer\n   *   receives\n   * - The total number of trainable and non-trainable parameters of the model.\n   *\n   * ```js\n   * const input1 = tf.input({shape: [10]});\n   * const input2 = tf.input({shape: [20]});\n   * const dense1 = tf.layers.dense({units: 4}).apply(input1);\n   * const dense2 = tf.layers.dense({units: 8}).apply(input2);\n   * const concat = tf.layers.concatenate().apply([dense1, dense2]);\n   * const output =\n   *     tf.layers.dense({units: 3, activation: 'softmax'}).apply(concat);\n   *\n   * const model = tf.model({inputs: [input1, input2], outputs: output});\n   * model.summary();\n   * ```\n   *\n   * @param lineLength Custom line length, in number of characters.\n   * @param positions Custom widths of each of the columns, as either\n   *   fractions of `lineLength` (e.g., `[0.5, 0.75, 1]`) or absolute number\n   *   of characters (e.g., `[30, 50, 65]`). Each number corresponds to\n   *   right-most (i.e., ending) position of a column.\n   * @param printFn Custom print function. Can be used to replace the default\n   *   `console.log`. For example, you can use `x => {}` to mute the printed\n   *   messages in the console.\n   *\n   * @doc {heading: 'Models', subheading: 'Classes'}\n   */\n\n\n  _createClass(LayersModel, [{\n    key: \"summary\",\n    value: function summary(lineLength, positions) {\n      var printFn = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : console.log;\n\n      if (!this.built) {\n        throw new ValueError(\"This model has never been called, thus its weights have not been \" + \"created yet. So no summary can be displayed. Build the model \" + \"first (e.g., by calling it on some test data).\");\n      }\n\n      printSummary(this, lineLength, positions, printFn);\n    }\n    /**\n     * Configures and prepares the model for training and evaluation.  Compiling\n     * outfits the model with an optimizer, loss, and/or metrics.  Calling `fit`\n     * or `evaluate` on an un-compiled model will throw an error.\n     *\n     * @param args a `ModelCompileArgs` specifying the loss, optimizer, and\n     * metrics to be used for fitting and evaluating this model.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"compile\",\n    value: function compile(args) {\n      var _this2 = this;\n\n      if (args.loss == null) {\n        args.loss = [];\n      }\n\n      this.loss = args.loss;\n\n      if (typeof args.optimizer === 'string') {\n        this.optimizer_ = optimizers.getOptimizer(args.optimizer);\n        this.isOptimizerOwned = true;\n      } else {\n        if (!(args.optimizer instanceof Optimizer)) {\n          throw new ValueError(\"User-defined optimizer must be an instance of tf.Optimizer.\");\n        }\n\n        this.optimizer_ = args.optimizer;\n        this.isOptimizerOwned = false;\n      } // TODO(cais): Add lossWeights.\n      // TODO(cais): Add sampleWeightMode.\n      // Prepare loss functions.\n\n\n      var lossFunctions = [];\n\n      if (!Array.isArray(args.loss) && typeof args.loss !== 'string' && typeof args.loss !== 'function') {\n        args.loss = args.loss;\n\n        for (var name in args.loss) {\n          if (this.outputNames.indexOf(name) === -1) {\n            throw new ValueError(\"Unknown entry in loss dictionary: \\\"\".concat(name, \"\\\". \") + \"Only expected the following keys: \".concat(this.outputNames));\n          }\n        }\n\n        var _iterator3 = _createForOfIteratorHelper(this.outputNames),\n            _step3;\n\n        try {\n          for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n            var _name = _step3.value;\n\n            if (args.loss[_name] == null) {\n              console.warn(\"Output \\\"\".concat(_name, \"\\\" is missing from loss dictionary. We assume \") + \"this was done on purpose, and we will not be expecting data \" + \"to be passed to \".concat(_name, \" during training\"));\n            }\n\n            lossFunctions.push(losses.get(args.loss[_name]));\n          }\n        } catch (err) {\n          _iterator3.e(err);\n        } finally {\n          _iterator3.f();\n        }\n      } else if (Array.isArray(args.loss)) {\n        if (args.loss.length !== this.outputs.length) {\n          throw new ValueError(\"When passing an Array as loss, it should have one entry per \" + \"model output. The model has \".concat(this.outputs.length, \" output(s), \") + \"but you passed loss=\".concat(args.loss, \".\"));\n        }\n\n        var theLosses = args.loss;\n        lossFunctions = theLosses.map(function (l) {\n          return losses.get(l);\n        });\n      } else {\n        var lossFunction = losses.get(args.loss);\n        this.outputs.forEach(function (_) {\n          lossFunctions.push(lossFunction);\n        });\n      }\n\n      this.lossFunctions = lossFunctions;\n      this.feedOutputNames = [];\n      this.feedOutputShapes = [];\n      this.feedLossFns = [];\n\n      for (var i = 0; i < this.outputs.length; ++i) {\n        // TODO(cais): Logic for skipping target(s).\n        var shape = this.internalOutputShapes[i];\n        var _name2 = this.outputNames[i];\n        this.feedOutputNames.push(_name2);\n        this.feedOutputShapes.push(shape);\n        this.feedLossFns.push(this.lossFunctions[i]);\n      } // TODO(cais): Add logic for output masks.\n      // TODO(cais): Add logic for sample weights.\n\n\n      var skipTargetIndices = []; // Prepare metrics.\n\n      this.metrics = args.metrics; // TODO(cais): Add weightedMetrics.\n\n      this.metricsNames = ['loss'];\n      this.metricsTensors = []; // Compute total loss.\n      // Porting Note: In PyKeras, metrics_tensors are symbolic tensor objects.\n      //   Here, metricsTensors are TypeScript functions. This difference is due\n      //   to the difference in symbolic/imperative property of the backends.\n\n      nameScope('loss', function () {\n        for (var _i = 0; _i < _this2.outputs.length; ++_i) {\n          if (skipTargetIndices.indexOf(_i) !== -1) {\n            continue;\n          } // TODO(cais): Add weightedLoss, sampleWeight and mask.\n          //   The following line should be weightedLoss\n\n\n          var weightedLoss = _this2.lossFunctions[_i];\n\n          if (_this2.outputs.length > 1) {\n            _this2.metricsTensors.push([weightedLoss, _i]);\n\n            _this2.metricsNames.push(_this2.outputNames[_i] + '_loss');\n          }\n        } // Porting Note: Due to the imperative nature of the backend, we calculate\n        //   the regularizer penalties in the totalLossFunction, instead of here.\n\n      });\n      var nestedMetrics = collectMetrics(args.metrics, this.outputNames); // TODO(cais): Add nestedWeightedMetrics.\n\n      /**\n       * Helper function used in loop below.\n       */\n\n      var appendMetric = function appendMetric(outputIndex, metricName, metricTensor) {\n        if (_this2.outputNames.length > 1) {\n          metricName = _this2.outputNames[outputIndex] + '_' + metricName;\n        }\n\n        _this2.metricsNames.push(metricName);\n\n        _this2.metricsTensors.push([metricTensor, outputIndex]);\n      };\n\n      nameScope('metric', function () {\n        var _loop = function _loop(_i2) {\n          if (skipTargetIndices.indexOf(_i2) !== -1) {\n            return \"continue\";\n          }\n\n          var outputMetrics = nestedMetrics[_i2]; // TODO(cais): Add weights and outputWeightedMetrics.\n          // TODO(cais): Add optional arg `weights` to the following function.\n\n          var handleMetrics = function handleMetrics(metrics) {\n            var metricNamePrefix = '';\n            var metricName;\n            var accFn;\n            var weightedMetricFn; //  TODO(cais): Use 'weights_' for weighted metrics.\n\n            var _iterator4 = _createForOfIteratorHelper(metrics),\n                _step4;\n\n            try {\n              for (_iterator4.s(); !(_step4 = _iterator4.n()).done;) {\n                var metric = _step4.value;\n\n                if (typeof metric === 'string' && ['accuracy', 'acc', 'crossentropy', 'ce'].indexOf(metric) !== -1) {\n                  var outputShape = _this2.internalOutputShapes[_i2];\n\n                  if (outputShape[outputShape.length - 1] === 1 || _this2.lossFunctions[_i2] === losses.binaryCrossentropy) {\n                    // case: binary accuracy/crossentropy.\n                    if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                      accFn = Metrics.binaryAccuracy;\n                    } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                      accFn = Metrics.binaryCrossentropy;\n                    }\n                  } else if (_this2.lossFunctions[_i2] === losses.sparseCategoricalCrossentropy) {\n                    // case: categorical accuracy / crossentropy with sparse\n                    // targets.\n                    if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                      accFn = Metrics.sparseCategoricalAccuracy;\n                    } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                      accFn = Metrics.sparseCategoricalCrossentropy;\n                    }\n                  } else {\n                    // case: categorical accuracy / crossentropy.\n                    if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                      accFn = Metrics.categoricalAccuracy;\n                    } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                      accFn = Metrics.categoricalCrossentropy;\n                    }\n                  }\n\n                  var suffix = void 0;\n\n                  if (['accuracy', 'acc'].indexOf(metric) !== -1) {\n                    suffix = 'acc';\n                  } else if (['crossentropy', 'ce'].indexOf(metric) !== -1) {\n                    suffix = 'ce';\n                  } // TODO(cais): Add weighting actually.\n\n\n                  weightedMetricFn = accFn;\n                  metricName = metricNamePrefix + suffix;\n                } else {\n                  var metricFn = Metrics.get(metric); // TODO(cais): Add weighting actually.\n\n                  weightedMetricFn = metricFn;\n                  metricName = metricNamePrefix + Metrics.getLossOrMetricName(metric);\n                } // TODO(cais): Add weighting and masking to metricResult.\n\n\n                var metricResult = void 0;\n                nameScope(metricName, function () {\n                  metricResult = weightedMetricFn;\n                });\n                appendMetric(_i2, metricName, metricResult);\n              }\n            } catch (err) {\n              _iterator4.e(err);\n            } finally {\n              _iterator4.f();\n            }\n          };\n\n          handleMetrics(outputMetrics); // TODO(cais): Call handleMetrics with weights.\n        };\n\n        for (var _i2 = 0; _i2 < _this2.outputs.length; ++_i2) {\n          var _ret = _loop(_i2);\n\n          if (_ret === \"continue\") continue;\n        }\n      }); // Porting Notes: Given the imperative backend of tfjs-core,\n      //   there is no need for constructing the symbolic graph and placeholders.\n\n      this.collectedTrainableWeights = this.trainableWeights;\n    }\n    /**\n     * Check trainable weights count consistency.\n     *\n     * This will raise a warning if `this.trainableWeights` and\n     * `this.collectedTrainableWeights` are inconsistent (i.e., have different\n     * numbers of parameters).\n     * Inconsistency will typically arise when one modifies `model.trainable`\n     * without calling `model.compile()` again.\n     */\n\n  }, {\n    key: \"checkTrainableWeightsConsistency\",\n    value: function checkTrainableWeightsConsistency() {\n      if (this.collectedTrainableWeights == null) {\n        return;\n      }\n\n      if (this.trainableWeights.length !== this.collectedTrainableWeights.length) {\n        console.warn('Discrepancy between trainableweights and collected trainable ' + 'weights. Did you set `model.trainable` without calling ' + '`model.compile()` afterwards?');\n      }\n    }\n    /**\n     * Returns the loss value & metrics values for the model in test mode.\n     *\n     * Loss and metrics are specified during `compile()`, which needs to happen\n     * before calls to `evaluate()`.\n     *\n     * Computation is done in batches.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * const result = model.evaluate(\n     *     tf.ones([8, 10]), tf.ones([8, 1]), {batchSize: 4});\n     * result.print();\n     * ```\n     *\n     * @param x `tf.Tensor` of test data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple inputs.\n     * @param y `tf.Tensor` of target data, or an `Array` of `tf.Tensor`s if the\n     * model has multiple outputs.\n     * @param args A `ModelEvaluateArgs`, containing optional fields.\n     *\n     * @return `Scalar` test loss (if the model has a single output and no\n     *   metrics) or `Array` of `Scalar`s (if the model has multiple outputs\n     *   and/or metrics). The attribute `model.metricsNames`\n     *   will give you the display labels for the scalar outputs.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"evaluate\",\n    value: function evaluate(x, y) {\n      var args = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : {};\n      var batchSize = args.batchSize == null ? 32 : args.batchSize;\n      checkBatchSize(batchSize); // TODO(cais): Standardize `config.sampleWeights` as well.\n      // Validate user data.\n\n      var checkBatchAxis = true;\n      var standardizedOuts = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize);\n\n      try {\n        // TODO(cais): If uses `useLearningPhase`, set the corresponding element\n        // of the input to 0.\n        var ins = standardizedOuts[0].concat(standardizedOuts[1]);\n        this.makeTestFunction();\n        var f = this.testFunction;\n        var testOuts = this.testLoop(f, ins, batchSize, args.verbose, args.steps);\n        return singletonOrArray(testOuts);\n      } finally {\n        disposeNewTensors(standardizedOuts[0], x);\n        disposeNewTensors(standardizedOuts[1], y);\n      }\n    } // TODO(cais): Add code snippet below once real dataset objects are\n    //   available.\n\n    /**\n     * Evaluate model using a dataset object.\n     *\n     * Note: Unlike `evaluate()`, this method is asynchronous (`async`);\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for evaluation. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs. Of the two items in the array, the\n     *   first is the input feature(s) and the second is the output target(s).\n     * @param args A configuration object for the dataset-based evaluation.\n     * @returns Loss and metric values as an Array of `Scalar` objects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"evaluateDataset\",\n    value: function () {\n      var _evaluateDataset2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(dataset, args) {\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                this.makeTestFunction();\n                return _context.abrupt(\"return\", _evaluateDataset(this, dataset, args));\n\n              case 2:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function evaluateDataset(_x, _x2) {\n        return _evaluateDataset2.apply(this, arguments);\n      }\n\n      return evaluateDataset;\n    }()\n    /**\n     * Get number of samples provided for training, evaluation or prediction.\n     *\n     * @param ins Input `tf.Tensor`.\n     * @param batchSize Integer batch size, optional.\n     * @param steps Total number of steps (batches of samples) before\n     * declaring loop finished. Optional.\n     * @param stepsName The public API's parameter name for `steps`.\n     * @returns Number of samples provided.\n     */\n\n  }, {\n    key: \"checkNumSamples\",\n    value: function checkNumSamples(ins, batchSize, steps) {\n      var stepsName = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 'steps';\n      var numSamples;\n\n      if (steps != null) {\n        numSamples = null;\n\n        if (batchSize != null) {\n          throw new ValueError(\"If \".concat(stepsName, \" is set, batchSize must be null or undefined.\") + \"Got batchSize = \".concat(batchSize));\n        }\n      } else if (ins != null) {\n        if (Array.isArray(ins)) {\n          numSamples = ins[0].shape[0];\n        } else {\n          numSamples = ins.shape[0];\n        }\n      } else {\n        throw new ValueError(\"Either the input data should have a defined shape, or \" + \"\".concat(stepsName, \" shoud be specified.\"));\n      }\n\n      return numSamples;\n    }\n    /**\n     * Execute internal tensors of the model with input data feed.\n     * @param inputs Input data feed. Must match the inputs of the model.\n     * @param outputs Names of the output tensors to be fetched. Must match\n     *   names of the SymbolicTensors that belong to the graph.\n     * @returns Fetched values for `outputs`.\n     */\n\n  }, {\n    key: \"execute\",\n    value: function execute(inputs, outputs) {\n      if (Array.isArray(outputs) && outputs.length === 0) {\n        throw new ValueError('`outputs` is an empty Array, which is not allowed.');\n      }\n\n      var outputsIsArray = Array.isArray(outputs);\n      var outputNames = outputsIsArray ? outputs : [outputs];\n      var outputSymbolicTensors = this.retrieveSymbolicTensors(outputNames); // Format the input into a FeedDict.\n\n      var feedDict = new FeedDict();\n\n      if (inputs instanceof Tensor) {\n        inputs = [inputs];\n      }\n\n      if (Array.isArray(inputs)) {\n        if (inputs.length !== this.inputs.length) {\n          throw new ValueError(\"The number of inputs provided (\".concat(inputs.length, \") \") + \"does not match the number of inputs of this model \" + \"(\".concat(this.inputs.length, \").\"));\n        }\n\n        for (var i = 0; i < this.inputs.length; ++i) {\n          feedDict.add(this.inputs[i], inputs[i]);\n        }\n      } else {\n        var _iterator5 = _createForOfIteratorHelper(this.inputs),\n            _step5;\n\n        try {\n          for (_iterator5.s(); !(_step5 = _iterator5.n()).done;) {\n            var input = _step5.value;\n            var tensorValue = inputs[input.name];\n\n            if (tensorValue == null) {\n              throw new ValueError(\"No value is provided for the model's input \".concat(input.name));\n            }\n\n            feedDict.add(input, tensorValue);\n          }\n        } catch (err) {\n          _iterator5.e(err);\n        } finally {\n          _iterator5.f();\n        }\n      } // Run execution.\n\n\n      var executeOutputs = _execute(outputSymbolicTensors, feedDict);\n\n      return outputsIsArray ? executeOutputs : executeOutputs[0];\n    }\n    /**\n     * Retrieve the model's internal symbolic tensors from symbolic-tensor names.\n     */\n\n  }, {\n    key: \"retrieveSymbolicTensors\",\n    value: function retrieveSymbolicTensors(symbolicTensorNames) {\n      var outputSymbolicTensors = pyListRepeat(null, symbolicTensorNames.length);\n      var outputsRemaining = symbolicTensorNames.length;\n\n      var _iterator6 = _createForOfIteratorHelper(this.layers),\n          _step6;\n\n      try {\n        for (_iterator6.s(); !(_step6 = _iterator6.n()).done;) {\n          var layer = _step6.value;\n          var layerOutputs = Array.isArray(layer.output) ? layer.output : [layer.output];\n          var layerOutputNames = layerOutputs.map(function (output) {\n            return output.name;\n          });\n\n          for (var i = 0; i < symbolicTensorNames.length; ++i) {\n            var index = layerOutputNames.indexOf(symbolicTensorNames[i]);\n\n            if (index !== -1) {\n              outputSymbolicTensors[i] = layerOutputs[index];\n              outputsRemaining--;\n            }\n\n            if (outputsRemaining === 0) {\n              break;\n            }\n          }\n\n          if (outputsRemaining === 0) {\n            break;\n          }\n        }\n      } catch (err) {\n        _iterator6.e(err);\n      } finally {\n        _iterator6.f();\n      }\n\n      if (outputsRemaining > 0) {\n        var remainingNames = [];\n        outputSymbolicTensors.forEach(function (tensor, i) {\n          if (tensor == null) {\n            remainingNames.push(symbolicTensorNames[i]);\n          }\n        });\n        throw new ValueError(\"Cannot find SymbolicTensors for output name(s): \" + \"\".concat(JSON.stringify(remainingNames)));\n      }\n\n      return outputSymbolicTensors;\n    }\n    /**\n     * Helper method to loop over some data in batches.\n     *\n     * Porting Note: Not using the functional approach in the Python equivalent\n     *   due to the imperative backend.\n     * Porting Note: Does not support step mode currently.\n     *\n     * @param ins: input data\n     * @param batchSize: integer batch size.\n     * @param verbose: verbosity model\n     * @returns: Predictions as `tf.Tensor` (if a single output) or an `Array` of\n     *   `tf.Tensor` (if multipe outputs).\n     */\n\n  }, {\n    key: \"predictLoop\",\n    value: function predictLoop(ins) {\n      var _this3 = this;\n\n      var batchSize = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : 32;\n      var verbose = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : false;\n      return tfc.tidy(function () {\n        var numSamples = _this3.checkNumSamples(ins);\n\n        if (verbose) {\n          throw new NotImplementedError('Verbose predictLoop() is not implemented yet.');\n        } // Sample-based predictions.\n        // Porting Note: Tensor currently does not support sliced assignments as\n        //   in numpy, e.g., x[1:3] = y. Therefore we use concatenation while\n        //   iterating over the batches.\n\n\n        var batches = makeBatches(numSamples, batchSize);\n\n        var outsBatches = _this3.outputs.map(function (output) {\n          return [];\n        }); // TODO(cais): Can the scope() be pushed down inside the for loop?\n\n\n        var _loop2 = function _loop2(batchIndex) {\n          var batchOuts = tfc.tidy(function () {\n            var batchStart = batches[batchIndex][0];\n            var batchEnd = batches[batchIndex][1]; // TODO(cais): Take care of the case of the last element is a flag for\n            //   training/test.\n\n            var insBatch = sliceArrays(ins, batchStart, batchEnd); // Construct the feeds for execute();\n\n            var feeds = [];\n\n            if (Array.isArray(insBatch)) {\n              for (var i = 0; i < insBatch.length; ++i) {\n                feeds.push({\n                  key: _this3.inputs[i],\n                  value: insBatch[i]\n                });\n              }\n            } else {\n              feeds.push({\n                key: _this3.inputs[0],\n                value: insBatch\n              });\n            }\n\n            var feedDict = new FeedDict(feeds);\n            return _execute(_this3.outputs, feedDict);\n          });\n          batchOuts.forEach(function (batchOut, i) {\n            return outsBatches[i].push(batchOut);\n          });\n        };\n\n        for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n          _loop2(batchIndex);\n        }\n\n        return singletonOrArray(outsBatches.map(function (batches) {\n          return tfc.concat(batches, 0);\n        }));\n      });\n    }\n    /**\n     * Generates output predictions for the input samples.\n     *\n     * Computation is done in batches.\n     *\n     * Note: the \"step\" mode of predict() is currently not supported.\n     *   This is because the TensorFlow.js core backend is imperative only.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predict(tf.ones([8, 10]), {batchSize: 4}).print();\n     * ```\n     *\n     * @param x The input data, as a Tensor, or an `Array` of `tf.Tensor`s if\n     *   the model has multiple inputs.\n     * @param args A `ModelPredictArgs` object containing optional fields.\n     *\n     * @return Prediction results as a `tf.Tensor`(s).\n     *\n     * @exception ValueError In case of mismatch between the provided input data\n     *   and the model's expectations, or in case a stateful model receives a\n     *   number of samples that is not a multiple of the batch size.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"predict\",\n    value: function predict(x) {\n      var args = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n      var xsRank2OrHigher = ensureTensorsRank2OrHigher(x);\n      checkInputData(xsRank2OrHigher, this.inputNames, this.feedInputShapes, false);\n\n      try {\n        // TODO(cais): Take care of stateful models.\n        //   if (this.stateful) ...\n        // TODO(cais): Take care of the learning_phase boolean flag.\n        //   if (this.useLearningPhase) ...\n        var batchSize = args.batchSize == null ? 32 : args.batchSize;\n        checkBatchSize(batchSize);\n        return this.predictLoop(xsRank2OrHigher, batchSize);\n      } finally {\n        disposeNewTensors(xsRank2OrHigher, x);\n      }\n    }\n    /**\n     * Returns predictions for a single batch of samples.\n     *\n     * ```js\n     * const model = tf.sequential({\n     *   layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.predictOnBatch(tf.ones([8, 10])).print();\n     * ```\n     * @param x: Input samples, as a Tensor (for models with exactly one\n     *   input) or an array of Tensors (for models with more than one input).\n     * @return Tensor(s) of predictions\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"predictOnBatch\",\n    value: function predictOnBatch(x) {\n      checkInputData(x, this.inputNames, this.feedInputShapes, true); // TODO(cais): Take care of the learning_phase boolean flag.\n      //   if (this.useLearningPhase) ...\n\n      var batchSize = (Array.isArray(x) ? x[0] : x).shape[0];\n      return this.predictLoop(x, batchSize);\n    }\n  }, {\n    key: \"standardizeUserDataXY\",\n    value: function standardizeUserDataXY(x, y) {\n      var checkBatchAxis = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n      var batchSize = arguments.length > 3 ? arguments[3] : undefined;\n\n      // TODO(cais): Add sampleWeight, classWeight\n      if (this.optimizer_ == null) {\n        throw new RuntimeError('You must compile a model before training/testing. Use ' + 'LayersModel.compile(modelCompileArgs).');\n      }\n\n      var outputShapes = [];\n\n      for (var i = 0; i < this.feedOutputShapes.length; ++i) {\n        var outputShape = this.feedOutputShapes[i];\n        var lossFn = this.feedLossFns[i];\n\n        if (lossFn === losses.sparseCategoricalCrossentropy) {\n          outputShapes.push(outputShape.slice(0, outputShape.length - 1).concat([1]));\n        } else {\n          // Porting Note: Because of strong typing `lossFn` must be a function.\n          outputShapes.push(outputShape);\n        }\n      }\n\n      x = standardizeInputData(x, this.feedInputNames, this.feedInputShapes, false, 'input');\n      y = standardizeInputData(y, this.feedOutputNames, outputShapes, false, 'target'); // TODO(cais): Standardize sampleWeights & classWeights.\n\n      checkArrayLengths(x, y, null); // TODO(cais): Check sampleWeights as well.\n\n      checkLossAndTargetCompatibility(y, this.feedLossFns, this.feedOutputShapes);\n\n      if (this.stateful && batchSize != null && batchSize > 0) {\n        if (x[0].shape[0] % batchSize !== 0) {\n          throw new ValueError(\"In a stateful network, you should only pass inputs with a \" + \"number of samples that is divisible by the batch size \" + \"\".concat(batchSize, \". Found: \").concat(x[0].shape[0], \" sample(s).\"));\n        }\n      }\n\n      return [x, y];\n    }\n  }, {\n    key: \"standardizeUserData\",\n    value: function () {\n      var _standardizeUserData = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(x, y, sampleWeight, classWeight) {\n        var checkBatchAxis,\n            batchSize,\n            _this$standardizeUser,\n            _this$standardizeUser2,\n            standardXs,\n            standardYs,\n            standardSampleWeights,\n            classWeights,\n            i,\n            _args2 = arguments;\n\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                checkBatchAxis = _args2.length > 4 && _args2[4] !== undefined ? _args2[4] : true;\n                batchSize = _args2.length > 5 ? _args2[5] : undefined;\n                _this$standardizeUser = this.standardizeUserDataXY(x, y, checkBatchAxis, batchSize), _this$standardizeUser2 = _slicedToArray(_this$standardizeUser, 2), standardXs = _this$standardizeUser2[0], standardYs = _this$standardizeUser2[1]; // TODO(cais): Handle sampleWeights.\n\n                if (!(sampleWeight != null)) {\n                  _context2.next = 5;\n                  break;\n                }\n\n                throw new Error('sample weight is not supported yet.');\n\n              case 5:\n                standardSampleWeights = null;\n\n                if (!(classWeight != null)) {\n                  _context2.next = 19;\n                  break;\n                }\n\n                classWeights = standardizeClassWeights(classWeight, this.outputNames);\n                standardSampleWeights = [];\n                i = 0;\n\n              case 10:\n                if (!(i < classWeights.length)) {\n                  _context2.next = 19;\n                  break;\n                }\n\n                _context2.t0 = standardSampleWeights;\n                _context2.next = 14;\n                return standardizeWeights(standardYs[i], null, classWeights[i]);\n\n              case 14:\n                _context2.t1 = _context2.sent;\n\n                _context2.t0.push.call(_context2.t0, _context2.t1);\n\n              case 16:\n                ++i;\n                _context2.next = 10;\n                break;\n\n              case 19:\n                return _context2.abrupt(\"return\", [standardXs, standardYs, standardSampleWeights]);\n\n              case 20:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function standardizeUserData(_x3, _x4, _x5, _x6) {\n        return _standardizeUserData.apply(this, arguments);\n      }\n\n      return standardizeUserData;\n    }()\n    /**\n     * Loop over some test data in batches.\n     * @param f A Function returning a list of tensors.\n     * @param ins Array of tensors to be fed to `f`.\n     * @param batchSize Integer batch size or `null` / `undefined`.\n     * @param verbose verbosity mode.\n     * @param steps Total number of steps (batches of samples) before\n     * declaring test finished. Ignored with the default value of `null` /\n     * `undefined`.\n     * @returns Array of Scalars.\n     */\n\n  }, {\n    key: \"testLoop\",\n    value: function testLoop(f, ins, batchSize) {\n      var _this4 = this;\n\n      var verbose = arguments.length > 3 && arguments[3] !== undefined ? arguments[3] : 0;\n      var steps = arguments.length > 4 ? arguments[4] : undefined;\n      return tfc.tidy(function () {\n        var numSamples = _this4.checkNumSamples(ins, batchSize, steps, 'steps');\n\n        var outs = [];\n\n        if (verbose > 0) {\n          throw new NotImplementedError('Verbose mode is not implemented yet.');\n        } // TODO(cais): Use `indicesForConversionToDense' to prevent slow down.\n\n\n        if (steps != null) {\n          throw new NotImplementedError('steps mode in testLoop() is not implemented yet');\n        } else {\n          var batches = makeBatches(numSamples, batchSize);\n          var indexArray = tensor1d(range(0, numSamples));\n\n          for (var batchIndex = 0; batchIndex < batches.length; ++batchIndex) {\n            var batchStart = batches[batchIndex][0];\n            var batchEnd = batches[batchIndex][1];\n            var batchIds = K.sliceAlongFirstAxis(indexArray, batchStart, batchEnd - batchStart); // TODO(cais): In ins, train flag can be a number, instead of an\n            //   Tensor? Do we need to handle this in tfjs-layers?\n\n            var insBatch = sliceArraysByIndices(ins, batchIds);\n            var batchOuts = f(insBatch);\n\n            if (batchIndex === 0) {\n              for (var i = 0; i < batchOuts.length; ++i) {\n                outs.push(scalar(0));\n              }\n            }\n\n            for (var _i3 = 0; _i3 < batchOuts.length; ++_i3) {\n              var batchOut = batchOuts[_i3];\n              outs[_i3] = tfc.add(outs[_i3], tfc.mul(batchEnd - batchStart, batchOut));\n            }\n          }\n\n          for (var _i4 = 0; _i4 < outs.length; ++_i4) {\n            outs[_i4] = tfc.div(outs[_i4], numSamples);\n          }\n        }\n\n        return outs;\n      });\n    }\n  }, {\n    key: \"getDedupedMetricsNames\",\n    value: function getDedupedMetricsNames() {\n      var outLabels = this.metricsNames; // Rename duplicated metrics names (can happen with an output layer\n      // shared among multiple dataflows).\n\n      var dedupedOutLabels = [];\n\n      for (var i = 0; i < outLabels.length; ++i) {\n        var label = outLabels[i];\n        var newLabel = label;\n\n        if (count(outLabels, label) > 1) {\n          var dupIndex = count(outLabels.slice(0, i), label);\n          newLabel += \"_\".concat(dupIndex);\n        }\n\n        dedupedOutLabels.push(newLabel);\n      }\n\n      return dedupedOutLabels;\n    }\n    /**\n     * Creates a function that performs the following actions:\n     *\n     * 1. computes the losses\n     * 2. sums them to get the total loss\n     * 3. call the optimizer computes the gradients of the LayersModel's\n     *    trainable weights w.r.t. the total loss and update the variables\n     * 4. calculates the metrics\n     * 5. returns the values of the losses and metrics.\n     */\n\n  }, {\n    key: \"makeTrainFunction\",\n    value: function makeTrainFunction() {\n      var _this5 = this;\n\n      return function (data) {\n        var lossValues = [];\n        var inputs = data.slice(0, _this5.inputs.length);\n        var targets = data.slice(_this5.inputs.length, _this5.inputs.length + _this5.outputs.length);\n        var sampleWeights = data.slice(_this5.inputs.length + _this5.outputs.length, _this5.inputs.length + _this5.outputs.length * 2);\n        var metricsValues = []; // Create a function that computes the total loss based on the\n        // inputs. This function is used for obtaining gradients through\n        // backprop.\n\n        var totalLossFunction = function totalLossFunction() {\n          var feeds = [];\n\n          for (var i = 0; i < _this5.inputs.length; ++i) {\n            feeds.push({\n              key: _this5.inputs[i],\n              value: inputs[i]\n            });\n          }\n\n          var feedDict = new FeedDict(feeds);\n\n          var outputs = _execute(_this5.outputs, feedDict, {\n            'training': true\n          }); // TODO(cais): Take care of the case of multiple outputs from a\n          //   single layer?\n\n\n          var totalLoss;\n\n          for (var _i5 = 0; _i5 < _this5.lossFunctions.length; ++_i5) {\n            var lossFunction = _this5.lossFunctions[_i5];\n            var loss = lossFunction(targets[_i5], outputs[_i5]);\n\n            if (sampleWeights[_i5] != null) {\n              loss = computeWeightedLoss(loss, sampleWeights[_i5]);\n            } // TODO(cais): push Scalar instead.\n\n\n            var meanLoss = tfc.mean(loss); // TODO(cais): Use a scope() instead, to avoid ownership.\n\n            lossValues.push(meanLoss);\n\n            if (_i5 === 0) {\n              totalLoss = loss;\n            } else {\n              totalLoss = tfc.add(totalLoss, loss);\n            }\n          } // Compute the metrics.\n          // TODO(cais): These should probably be calculated outside\n          //   totalLossFunction to benefit speed?\n\n\n          for (var _i6 = 0; _i6 < _this5.metricsTensors.length; ++_i6) {\n            var weightedMetric = void 0;\n\n            if (_this5.outputs.length > 1 && _i6 < _this5.outputs.length) {\n              weightedMetric = lossValues[_i6];\n            } else {\n              var metric = _this5.metricsTensors[_i6][0];\n              var outputIndex = _this5.metricsTensors[_i6][1];\n              weightedMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n            }\n\n            tfc.keep(weightedMetric); // TODO(cais): Use a scope() instead, to avoid ownership.\n\n            metricsValues.push(weightedMetric);\n          }\n\n          totalLoss = tfc.mean(totalLoss); // Add regularizer penalties.\n\n          _this5.calculateLosses().forEach(function (regularizerLoss) {\n            totalLoss = tfc.add(totalLoss, regularizerLoss);\n          });\n\n          return totalLoss;\n        };\n\n        var variables = _this5.collectedTrainableWeights.map(function (param) {\n          return param.read();\n        });\n\n        var returnCost = true;\n\n        var totalLossValue = _this5.optimizer_.minimize(totalLossFunction, returnCost, variables);\n\n        return [totalLossValue].concat(metricsValues);\n      };\n    }\n    /**\n     * Create a function which, when invoked with an array of `tf.Tensor`s as a\n     * batch of inputs, returns the prespecified loss and metrics of the model\n     * under the batch of input data.\n     */\n\n  }, {\n    key: \"makeTestFunction\",\n    value: function makeTestFunction() {\n      var _this6 = this;\n\n      this.testFunction = function (data) {\n        return tfc.tidy(function () {\n          var valOutputs = [];\n          var totalLoss;\n          var inputs = data.slice(0, _this6.inputs.length);\n          var targets = data.slice(_this6.inputs.length, _this6.inputs.length + _this6.outputs.length);\n          var feeds = [];\n\n          for (var i = 0; i < _this6.inputs.length; ++i) {\n            feeds.push({\n              key: _this6.inputs[i],\n              value: inputs[i]\n            });\n          }\n\n          var feedDict = new FeedDict(feeds);\n\n          var outputs = _execute(_this6.outputs, feedDict); // Compute total loss.\n\n\n          for (var _i7 = 0; _i7 < _this6.lossFunctions.length; ++_i7) {\n            var lossFunction = _this6.lossFunctions[_i7]; // TODO(cais): Add sample weighting and replace the simple\n            // averaging.\n\n            var loss = tfc.mean(lossFunction(targets[_i7], outputs[_i7]));\n\n            if (_i7 === 0) {\n              totalLoss = loss;\n            } else {\n              totalLoss = tfc.add(totalLoss, loss);\n            }\n\n            valOutputs.push(totalLoss);\n          } // Compute the metrics.\n\n\n          for (var _i8 = 0; _i8 < _this6.metricsTensors.length; ++_i8) {\n            var metric = _this6.metricsTensors[_i8][0];\n            var outputIndex = _this6.metricsTensors[_i8][1]; // TODO(cais): Replace K.mean() with a proper weighting function.\n\n            var meanMetric = tfc.mean(metric(targets[outputIndex], outputs[outputIndex]));\n            valOutputs.push(meanMetric);\n          }\n\n          return valOutputs;\n        });\n      };\n    }\n    /**\n     * Trains the model for a fixed number of epochs (iterations on a\n     * dataset).\n     *\n     * ```js\n     * const model = tf.sequential({\n     *     layers: [tf.layers.dense({units: 1, inputShape: [10]})]\n     * });\n     * model.compile({optimizer: 'sgd', loss: 'meanSquaredError'});\n     * for (let i = 1; i < 5 ; ++i) {\n     *   const h = await model.fit(tf.ones([8, 10]), tf.ones([8, 1]), {\n     *       batchSize: 4,\n     *       epochs: 3\n     *   });\n     *   console.log(\"Loss after Epoch \" + i + \" : \" + h.history.loss[0]);\n     * }\n     * ```\n     *\n     * @param x `tf.Tensor` of training data, or an array of `tf.Tensor`s if the\n     * model has multiple inputs. If all inputs in the model are named, you\n     * can also pass a dictionary mapping input names to `tf.Tensor`s.\n     * @param y `tf.Tensor` of target (label) data, or an array of `tf.Tensor`s if\n     * the model has multiple outputs. If all outputs in the model are named,\n     * you can also pass a dictionary mapping output names to `tf.Tensor`s.\n     * @param args A `ModelFitArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @exception ValueError In case of mismatch between the provided input\n     * data and what the model expects.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"fit\",\n    value: function () {\n      var _fit = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(x, y) {\n        var args,\n            _args3 = arguments;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                args = _args3.length > 2 && _args3[2] !== undefined ? _args3[2] : {};\n                return _context3.abrupt(\"return\", fitTensors(this, x, y, args));\n\n              case 2:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function fit(_x7, _x8) {\n        return _fit.apply(this, arguments);\n      }\n\n      return fit;\n    }() // TODO(cais): Add code snippet below when it's possible to instantiate\n    //   actual dataset objects.\n\n    /**\n     * Trains the model using a dataset object.\n     *\n     * @param dataset A dataset object. Its `iterator()` method is expected\n     *   to generate a dataset iterator object, the `next()` method of which\n     *   is expected to produce data batches for training. The return value\n     *   of the `next()` call ought to contain a boolean `done` field and a\n     *   `value` field. The `value` field is expected to be an array of two\n     *   `tf.Tensor`s or an array of two nested `tf.Tensor` structures. The former\n     *   case is for models with exactly one input and one output (e.g..\n     *   a sequential model). The latter case is for models with multiple\n     *   inputs and/or multiple outputs.\n     *   Of the two items in the array, the first is the input feature(s) and\n     *   the second is the output target(s).\n     * @param args A `ModelFitDatasetArgs`, containing optional fields.\n     *\n     * @return A `History` instance. Its `history` attribute contains all\n     *   information collected during training.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"fitDataset\",\n    value: function () {\n      var _fitDataset2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(dataset, args) {\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                return _context4.abrupt(\"return\", _fitDataset(this, dataset, args));\n\n              case 1:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function fitDataset(_x9, _x10) {\n        return _fitDataset2.apply(this, arguments);\n      }\n\n      return fitDataset;\n    }()\n    /**\n     * Runs a single gradient update on a single batch of data.\n     *\n     * This method differs from `fit()` and `fitDataset()` in the following\n     * regards:\n     *   - It operates on exactly one batch of data.\n     *   - It returns only the loss and matric values, instead of\n     *     returning the batch-by-batch loss and metric values.\n     *   - It doesn't support fine-grained options such as verbosity and\n     *     callbacks.\n     *\n     * @param x Input data. It could be one of the following:\n     *   - A `tf.Tensor`, or an Array of `tf.Tensor`s (in case the model has\n     *     multiple inputs).\n     *   - An Object mapping input names to corresponding `tf.Tensor` (if the\n     *     model has named inputs).\n     * @param y Target darta. It could be either a `tf.Tensor` a multiple\n     *   `tf.Tensor`s. It should be consistent with `x`.\n     * @returns Training loss or losses (in case the model has\n     *   multiple outputs), along with metrics (if any), as numbers.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes'}\n     */\n\n  }, {\n    key: \"trainOnBatch\",\n    value: function () {\n      var _trainOnBatch = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(x, y) {\n        var standardizeOut, inputs, targets, trainFunction, losses, lossValues, _iterator7, _step7, loss, v;\n\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                _context5.next = 2;\n                return this.standardizeUserData(x, y);\n\n              case 2:\n                standardizeOut = _context5.sent;\n                inputs = standardizeOut[0];\n                targets = standardizeOut[1];\n                trainFunction = this.makeTrainFunction();\n                losses = trainFunction(inputs.concat(targets));\n                lossValues = [];\n                _iterator7 = _createForOfIteratorHelper(losses);\n                _context5.prev = 9;\n\n                _iterator7.s();\n\n              case 11:\n                if ((_step7 = _iterator7.n()).done) {\n                  _context5.next = 19;\n                  break;\n                }\n\n                loss = _step7.value;\n                _context5.next = 15;\n                return loss.data();\n\n              case 15:\n                v = _context5.sent;\n                lossValues.push(v[0]);\n\n              case 17:\n                _context5.next = 11;\n                break;\n\n              case 19:\n                _context5.next = 24;\n                break;\n\n              case 21:\n                _context5.prev = 21;\n                _context5.t0 = _context5[\"catch\"](9);\n\n                _iterator7.e(_context5.t0);\n\n              case 24:\n                _context5.prev = 24;\n\n                _iterator7.f();\n\n                return _context5.finish(24);\n\n              case 27:\n                tfc.dispose(losses);\n                return _context5.abrupt(\"return\", singletonOrArray(lossValues));\n\n              case 29:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5, this, [[9, 21, 24, 27]]);\n      }));\n\n      function trainOnBatch(_x11, _x12) {\n        return _trainOnBatch.apply(this, arguments);\n      }\n\n      return trainOnBatch;\n    }()\n    /**\n     * Extract weight values of the model.\n     *\n     * @param config: An instance of `io.SaveConfig`, which specifies\n     * model-saving options such as whether only trainable weights are to be\n     * saved.\n     * @returns A `NamedTensorMap` mapping original weight names (i.e.,\n     *   non-uniqueified weight names) to their values.\n     */\n\n  }, {\n    key: \"getNamedWeights\",\n    value: function getNamedWeights(config) {\n      var namedWeights = [];\n      var trainableOnly = config != null && config.trainableOnly;\n      var weights = trainableOnly ? this.trainableWeights : this.weights;\n      var weightValues = this.getWeights(trainableOnly);\n\n      for (var i = 0; i < weights.length; ++i) {\n        if (trainableOnly && !weights[i].trainable) {\n          // Optionally skip non-trainable weights.\n          continue;\n        }\n\n        namedWeights.push({\n          name: weights[i].originalName,\n          tensor: weightValues[i]\n        });\n      }\n\n      return namedWeights;\n    }\n    /**\n     * Setter used for force stopping of LayersModel.fit() (i.e., training).\n     *\n     * Example:\n     *\n     * ```js\n     * const input = tf.input({shape: [10]});\n     * const output = tf.layers.dense({units: 1}).apply(input);\n     * const model = tf.model({inputs: [input], outputs: [output]});\n     * model.compile({loss: 'meanSquaredError', optimizer: 'sgd'});\n     * const xs = tf.ones([8, 10]);\n     * const ys = tf.zeros([8, 1]);\n     *\n     * const history = await model.fit(xs, ys, {\n     *   epochs: 10,\n     *   callbacks: {\n     *     onEpochEnd: async (epoch, logs) => {\n     *       if (epoch === 2) {\n     *         model.stopTraining = true;\n     *       }\n     *     }\n     *   }\n     * });\n     *\n     * // There should be only 3 values in the loss array, instead of 10\n     * values,\n     * // due to the stopping after 3 epochs.\n     * console.log(history.history.loss);\n     * ```\n     */\n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var result = _get(_getPrototypeOf(LayersModel.prototype), \"dispose\", this).call(this);\n\n      if (result.refCountAfterDispose === 0 && this.optimizer != null && this.isOptimizerOwned) {\n        var numTensorsBeforeOptmizerDisposal = tfc.memory().numTensors;\n        this.optimizer_.dispose();\n        result.numDisposedVariables += numTensorsBeforeOptmizerDisposal - tfc.memory().numTensors;\n      }\n\n      return result;\n    }\n  }, {\n    key: \"getLossIdentifiers\",\n    value: function getLossIdentifiers() {\n      var lossNames;\n\n      if (typeof this.loss === 'string') {\n        lossNames = toSnakeCase(this.loss);\n      } else if (Array.isArray(this.loss)) {\n        var _iterator8 = _createForOfIteratorHelper(this.loss),\n            _step8;\n\n        try {\n          for (_iterator8.s(); !(_step8 = _iterator8.n()).done;) {\n            var loss = _step8.value;\n\n            if (typeof loss !== 'string') {\n              throw new Error('Serialization of non-string loss is not supported.');\n            }\n          }\n        } catch (err) {\n          _iterator8.e(err);\n        } finally {\n          _iterator8.f();\n        }\n\n        lossNames = this.loss.map(function (name) {\n          return toSnakeCase(name);\n        });\n      } else {\n        var outputNames = Object.keys(this.loss);\n        lossNames = {};\n        var _losses = this.loss;\n\n        for (var _i9 = 0, _outputNames = outputNames; _i9 < _outputNames.length; _i9++) {\n          var outputName = _outputNames[_i9];\n\n          if (typeof _losses[outputName] === 'string') {\n            lossNames[outputName] = toSnakeCase(_losses[outputName]);\n          } else {\n            throw new Error('Serialization of non-string loss is not supported.');\n          }\n        }\n      }\n\n      return lossNames;\n    }\n  }, {\n    key: \"getMetricIdentifiers\",\n    value: function getMetricIdentifiers() {\n      if (typeof this.metrics === 'string' || typeof this.metrics === 'function') {\n        return [toSnakeCase(Metrics.getLossOrMetricName(this.metrics))];\n      } else if (Array.isArray(this.metrics)) {\n        return this.metrics.map(function (metric) {\n          return toSnakeCase(Metrics.getLossOrMetricName(metric));\n        });\n      } else {\n        var metricsIdentifiers = {};\n\n        for (var key in this.metrics) {\n          metricsIdentifiers[key] = toSnakeCase(Metrics.getLossOrMetricName(this.metrics[key]));\n        }\n\n        return metricsIdentifiers;\n      }\n    }\n  }, {\n    key: \"getTrainingConfig\",\n    value: function getTrainingConfig() {\n      return {\n        loss: this.getLossIdentifiers(),\n        metrics: this.getMetricIdentifiers(),\n        optimizer_config: {\n          class_name: this.optimizer.getClassName(),\n          config: this.optimizer.getConfig()\n        }\n      }; // TODO(cais): Add weight_metrics when they are supported.\n      // TODO(cais): Add sample_weight_mode when it's supported.\n      // TODO(cais): Add loss_weights when it's supported.\n    }\n  }, {\n    key: \"loadTrainingConfig\",\n    value: function loadTrainingConfig(trainingConfig) {\n      if (trainingConfig.weighted_metrics != null) {\n        throw new Error('Loading weight_metrics is not supported yet.');\n      }\n\n      if (trainingConfig.loss_weights != null) {\n        throw new Error('Loading loss_weights is not supported yet.');\n      }\n\n      if (trainingConfig.sample_weight_mode != null) {\n        throw new Error('Loading sample_weight_mode is not supported yet.');\n      }\n\n      var tsConfig = convertPythonicToTs(trainingConfig.optimizer_config);\n      var optimizer = deserialize(tsConfig);\n      var loss;\n\n      if (typeof trainingConfig.loss === 'string') {\n        loss = toCamelCase(trainingConfig.loss);\n      } else if (Array.isArray(trainingConfig.loss)) {\n        loss = trainingConfig.loss.map(function (lossEntry) {\n          return toCamelCase(lossEntry);\n        });\n      } else if (trainingConfig.loss != null) {\n        loss = {};\n\n        for (var key in trainingConfig.loss) {\n          loss[key] = toCamelCase(trainingConfig.loss[key]);\n        }\n      }\n\n      var metrics;\n\n      if (Array.isArray(trainingConfig.metrics)) {\n        metrics = trainingConfig.metrics.map(function (metric) {\n          return toCamelCase(metric);\n        });\n      } else if (trainingConfig.metrics != null) {\n        metrics = {};\n\n        for (var _key in trainingConfig.metrics) {\n          metrics[_key] = toCamelCase(trainingConfig.metrics[_key]);\n        }\n      }\n\n      this.compile({\n        loss: loss,\n        metrics: metrics,\n        optimizer: optimizer\n      });\n    }\n    /**\n     * Save the configuration and/or weights of the LayersModel.\n     *\n     * An `IOHandler` is an object that has a `save` method of the proper\n     * signature defined. The `save` method manages the storing or\n     * transmission of serialized data (\"artifacts\") that represent the\n     * model's topology and weights onto or via a specific medium, such as\n     * file downloads, local storage, IndexedDB in the web browser and HTTP\n     * requests to a server. TensorFlow.js provides `IOHandler`\n     * implementations for a number of frequently used saving mediums, such as\n     * `tf.io.browserDownloads` and `tf.io.browserLocalStorage`. See `tf.io`\n     * for more details.\n     *\n     * This method also allows you to refer to certain types of `IOHandler`s\n     * as URL-like string shortcuts, such as 'localstorage://' and\n     * 'indexeddb://'.\n     *\n     * Example 1: Save `model`'s topology and weights to browser [local\n     * storage](https://developer.mozilla.org/en-US/docs/Web/API/Window/localStorage);\n     * then load it back.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * console.log('Prediction from original model:');\n     * model.predict(tf.ones([1, 3])).print();\n     *\n     * const saveResults = await model.save('localstorage://my-model-1');\n     *\n     * const loadedModel = await tf.loadLayersModel('localstorage://my-model-1');\n     * console.log('Prediction from loaded model:');\n     * loadedModel.predict(tf.ones([1, 3])).print();\n     * ```\n     *\n     * Example 2. Saving `model`'s topology and weights to browser\n     * [IndexedDB](https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API);\n     * then load it back.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * console.log('Prediction from original model:');\n     * model.predict(tf.ones([1, 3])).print();\n     *\n     * const saveResults = await model.save('indexeddb://my-model-1');\n     *\n     * const loadedModel = await tf.loadLayersModel('indexeddb://my-model-1');\n     * console.log('Prediction from loaded model:');\n     * loadedModel.predict(tf.ones([1, 3])).print();\n     * ```\n     *\n     * Example 3. Saving `model`'s topology and weights as two files\n     * (`my-model-1.json` and `my-model-1.weights.bin`) downloaded from\n     * browser.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * const saveResults = await model.save('downloads://my-model-1');\n     * ```\n     *\n     * Example 4. Send  `model`'s topology and weights to an HTTP server.\n     * See the documentation of `tf.io.http` for more details\n     * including specifying request parameters and implementation of the\n     * server.\n     *\n     * ```js\n     * const model = tf.sequential(\n     *     {layers: [tf.layers.dense({units: 1, inputShape: [3]})]});\n     * const saveResults = await model.save('http://my-server/model/upload');\n     * ```\n     *\n     * @param handlerOrURL An instance of `IOHandler` or a URL-like,\n     * scheme-based string shortcut for `IOHandler`.\n     * @param config Options for saving the model.\n     * @returns A `Promise` of `SaveResult`, which summarizes the result of\n     * the saving, such as byte sizes of the saved artifacts for the model's\n     *   topology and weight values.\n     *\n     * @doc {heading: 'Models', subheading: 'Classes', ignoreCI: true}\n     */\n\n  }, {\n    key: \"save\",\n    value: function () {\n      var _save = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee6(handlerOrURL, config) {\n        var handlers, weightDataAndSpecs, returnString, unusedArg, modelConfig, modelArtifacts, includeOptimizer, _weightDataAndSpecs$s, weightType, _yield$io$encodeWeigh, optimizerWeightData, optimizerWeightSpecs, checkSize;\n\n        return _regeneratorRuntime.wrap(function _callee6$(_context6) {\n          while (1) {\n            switch (_context6.prev = _context6.next) {\n              case 0:\n                if (!(typeof handlerOrURL === 'string')) {\n                  _context6.next = 9;\n                  break;\n                }\n\n                handlers = io.getSaveHandlers(handlerOrURL);\n\n                if (!(handlers.length === 0)) {\n                  _context6.next = 6;\n                  break;\n                }\n\n                throw new ValueError(\"Cannot find any save handlers for URL '\".concat(handlerOrURL, \"'\"));\n\n              case 6:\n                if (!(handlers.length > 1)) {\n                  _context6.next = 8;\n                  break;\n                }\n\n                throw new ValueError(\"Found more than one (\".concat(handlers.length, \") save handlers for \") + \"URL '\".concat(handlerOrURL, \"'\"));\n\n              case 8:\n                handlerOrURL = handlers[0];\n\n              case 9:\n                if (!(handlerOrURL.save == null)) {\n                  _context6.next = 11;\n                  break;\n                }\n\n                throw new ValueError('LayersModel.save() cannot proceed because the IOHandler ' + 'provided does not have the `save` attribute defined.');\n\n              case 11:\n                _context6.next = 13;\n                return io.encodeWeights(this.getNamedWeights(config));\n\n              case 13:\n                weightDataAndSpecs = _context6.sent;\n                returnString = false;\n                unusedArg = null;\n                modelConfig = this.toJSON(unusedArg, returnString);\n                modelArtifacts = {\n                  modelTopology: modelConfig,\n                  format: LAYERS_MODEL_FORMAT_NAME,\n                  generatedBy: \"TensorFlow.js tfjs-layers v\".concat(version),\n                  convertedBy: null\n                };\n                includeOptimizer = config == null ? false : config.includeOptimizer;\n\n                if (!(includeOptimizer && this.optimizer != null)) {\n                  _context6.next = 34;\n                  break;\n                }\n\n                modelArtifacts.trainingConfig = this.getTrainingConfig();\n                weightType = 'optimizer';\n                _context6.t0 = io;\n                _context6.next = 25;\n                return this.optimizer.getWeights();\n\n              case 25:\n                _context6.t1 = _context6.sent;\n                _context6.t2 = weightType;\n                _context6.next = 29;\n                return _context6.t0.encodeWeights.call(_context6.t0, _context6.t1, _context6.t2);\n\n              case 29:\n                _yield$io$encodeWeigh = _context6.sent;\n                optimizerWeightData = _yield$io$encodeWeigh.data;\n                optimizerWeightSpecs = _yield$io$encodeWeigh.specs;\n\n                (_weightDataAndSpecs$s = weightDataAndSpecs.specs).push.apply(_weightDataAndSpecs$s, _toConsumableArray(optimizerWeightSpecs));\n\n                weightDataAndSpecs.data = io.concatenateArrayBuffers([weightDataAndSpecs.data, optimizerWeightData]);\n\n              case 34:\n                if (this.userDefinedMetadata != null) {\n                  // Check serialized size of user-defined metadata.\n                  checkSize = true;\n                  checkUserDefinedMetadata(this.userDefinedMetadata, this.name, checkSize);\n                  modelArtifacts.userDefinedMetadata = this.userDefinedMetadata;\n                }\n\n                modelArtifacts.weightData = weightDataAndSpecs.data;\n                modelArtifacts.weightSpecs = weightDataAndSpecs.specs;\n                return _context6.abrupt(\"return\", handlerOrURL.save(modelArtifacts));\n\n              case 38:\n              case \"end\":\n                return _context6.stop();\n            }\n          }\n        }, _callee6, this);\n      }));\n\n      function save(_x13, _x14) {\n        return _save.apply(this, arguments);\n      }\n\n      return save;\n    }()\n    /**\n     * Set user-defined metadata.\n     *\n     * The set metadata will be serialized together with the topology\n     * and weights of the model during `save()` calls.\n     *\n     * @param setUserDefinedMetadata\n     */\n\n  }, {\n    key: \"setUserDefinedMetadata\",\n    value: function setUserDefinedMetadata(userDefinedMetadata) {\n      checkUserDefinedMetadata(userDefinedMetadata, this.name);\n      this.userDefinedMetadata = userDefinedMetadata;\n    }\n    /**\n     * Get user-defined metadata.\n     *\n     * The metadata is supplied via one of the two routes:\n     *   1. By calling `setUserDefinedMetadata()`.\n     *   2. Loaded during model loading (if the model is constructed\n     *      via `tf.loadLayersModel()`.)\n     *\n     * If no user-defined metadata is available from either of the\n     * two routes, this function will return `undefined`.\n     */\n\n  }, {\n    key: \"getUserDefinedMetadata\",\n    value: function getUserDefinedMetadata() {\n      return this.userDefinedMetadata;\n    }\n  }, {\n    key: \"stopTraining\",\n    set: function set(stop) {\n      this.stopTraining_ = stop;\n    },\n    get: function get() {\n      return this.stopTraining_;\n    }\n  }, {\n    key: \"optimizer\",\n    get: function get() {\n      return this.optimizer_;\n    },\n    set: function set(optimizer) {\n      if (this.optimizer_ !== optimizer) {\n        this.optimizer_ = optimizer;\n        this.isOptimizerOwned = false;\n      }\n    }\n  }]);\n\n  return LayersModel;\n}(Container); // The class name is 'Model' rather than 'LayersModel' for backwards\n// compatibility since this class name shows up in the serialization format.\n\n/** @nocollapse */\n\nLayersModel.className = 'Model';\nserialization.registerClass(LayersModel);\n/**\n * A `tf.Functional` is an alias to `tf.LayersModel`.\n *\n * See also:\n *   `tf.LayersModel`, `tf.Sequential`, `tf.loadLayersModel`.\n */\n\n/** @doc {heading: 'Models', subheading: 'Classes'} */\n\nexport var Functional = /*#__PURE__*/function (_LayersModel) {\n  _inherits(Functional, _LayersModel);\n\n  function Functional() {\n    _classCallCheck(this, Functional);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(Functional).apply(this, arguments));\n  }\n\n  return Functional;\n}(LayersModel);\nFunctional.className = 'Functional';\nserialization.registerClass(Functional);","map":null,"metadata":{},"sourceType":"module"}