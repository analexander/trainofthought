{"ast":null,"code":"'use strict';\n\nvar Buffer = require('./buffer.js'); // tar -r\n\n\nvar hlo = require('./high-level-opt.js');\n\nvar Pack = require('./pack.js');\n\nvar Parse = require('./parse.js');\n\nvar fs = require('fs');\n\nvar fsm = require('fs-minipass');\n\nvar t = require('./list.js');\n\nvar path = require('path'); // starting at the head of the file, read a Header\n// If the checksum is invalid, that's our position to start writing\n// If it is, jump forward by the specified size (round up to 512)\n// and try again.\n// Write the new Pack stream starting there.\n\n\nvar Header = require('./header.js');\n\nvar r = module.exports = function (opt_, files, cb) {\n  var opt = hlo(opt_);\n  if (!opt.file) throw new TypeError('file is required');\n  if (opt.gzip) throw new TypeError('cannot append to compressed archives');\n  if (!files || !Array.isArray(files) || !files.length) throw new TypeError('no files or directories specified');\n  files = Array.from(files);\n  return opt.sync ? replaceSync(opt, files) : replace(opt, files, cb);\n};\n\nvar replaceSync = function replaceSync(opt, files) {\n  var p = new Pack.Sync(opt);\n  var threw = true;\n  var fd;\n  var position;\n\n  try {\n    try {\n      fd = fs.openSync(opt.file, 'r+');\n    } catch (er) {\n      if (er.code === 'ENOENT') fd = fs.openSync(opt.file, 'w+');else throw er;\n    }\n\n    var st = fs.fstatSync(fd);\n    var headBuf = Buffer.alloc(512);\n\n    POSITION: for (position = 0; position < st.size; position += 512) {\n      for (var bufPos = 0, bytes = 0; bufPos < 512; bufPos += bytes) {\n        bytes = fs.readSync(fd, headBuf, bufPos, headBuf.length - bufPos, position + bufPos);\n        if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b) throw new Error('cannot append to compressed archives');\n        if (!bytes) break POSITION;\n      }\n\n      var h = new Header(headBuf);\n      if (!h.cksumValid) break;\n      var entryBlockSize = 512 * Math.ceil(h.size / 512);\n      if (position + entryBlockSize + 512 > st.size) break; // the 512 for the header we just parsed will be added as well\n      // also jump ahead all the blocks for the body\n\n      position += entryBlockSize;\n      if (opt.mtimeCache) opt.mtimeCache.set(h.path, h.mtime);\n    }\n\n    threw = false;\n    streamSync(opt, p, position, fd, files);\n  } finally {\n    if (threw) try {\n      fs.closeSync(fd);\n    } catch (er) {}\n  }\n};\n\nvar streamSync = function streamSync(opt, p, position, fd, files) {\n  var stream = new fsm.WriteStreamSync(opt.file, {\n    fd: fd,\n    start: position\n  });\n  p.pipe(stream);\n  addFilesSync(p, files);\n};\n\nvar replace = function replace(opt, files, cb) {\n  files = Array.from(files);\n  var p = new Pack(opt);\n\n  var getPos = function getPos(fd, size, cb_) {\n    var cb = function cb(er, pos) {\n      if (er) fs.close(fd, function (_) {\n        return cb_(er);\n      });else cb_(null, pos);\n    };\n\n    var position = 0;\n    if (size === 0) return cb(null, 0);\n    var bufPos = 0;\n    var headBuf = Buffer.alloc(512);\n\n    var onread = function onread(er, bytes) {\n      if (er) return cb(er);\n      bufPos += bytes;\n      if (bufPos < 512 && bytes) return fs.read(fd, headBuf, bufPos, headBuf.length - bufPos, position + bufPos, onread);\n      if (position === 0 && headBuf[0] === 0x1f && headBuf[1] === 0x8b) return cb(new Error('cannot append to compressed archives')); // truncated header\n\n      if (bufPos < 512) return cb(null, position);\n      var h = new Header(headBuf);\n      if (!h.cksumValid) return cb(null, position);\n      var entryBlockSize = 512 * Math.ceil(h.size / 512);\n      if (position + entryBlockSize + 512 > size) return cb(null, position);\n      position += entryBlockSize + 512;\n      if (position >= size) return cb(null, position);\n      if (opt.mtimeCache) opt.mtimeCache.set(h.path, h.mtime);\n      bufPos = 0;\n      fs.read(fd, headBuf, 0, 512, position, onread);\n    };\n\n    fs.read(fd, headBuf, 0, 512, position, onread);\n  };\n\n  var promise = new Promise(function (resolve, reject) {\n    p.on('error', reject);\n    var flag = 'r+';\n\n    var onopen = function onopen(er, fd) {\n      if (er && er.code === 'ENOENT' && flag === 'r+') {\n        flag = 'w+';\n        return fs.open(opt.file, flag, onopen);\n      }\n\n      if (er) return reject(er);\n      fs.fstat(fd, function (er, st) {\n        if (er) return reject(er);\n        getPos(fd, st.size, function (er, position) {\n          if (er) return reject(er);\n          var stream = new fsm.WriteStream(opt.file, {\n            fd: fd,\n            start: position\n          });\n          p.pipe(stream);\n          stream.on('error', reject);\n          stream.on('close', resolve);\n          addFilesAsync(p, files);\n        });\n      });\n    };\n\n    fs.open(opt.file, flag, onopen);\n  });\n  return cb ? promise.then(cb, cb) : promise;\n};\n\nvar addFilesSync = function addFilesSync(p, files) {\n  files.forEach(function (file) {\n    if (file.charAt(0) === '@') t({\n      file: path.resolve(p.cwd, file.substr(1)),\n      sync: true,\n      noResume: true,\n      onentry: function onentry(entry) {\n        return p.add(entry);\n      }\n    });else p.add(file);\n  });\n  p.end();\n};\n\nvar addFilesAsync = function addFilesAsync(p, files) {\n  while (files.length) {\n    var file = files.shift();\n    if (file.charAt(0) === '@') return t({\n      file: path.resolve(p.cwd, file.substr(1)),\n      noResume: true,\n      onentry: function onentry(entry) {\n        return p.add(entry);\n      }\n    }).then(function (_) {\n      return addFilesAsync(p, files);\n    });else p.add(file);\n  }\n\n  p.end();\n};","map":null,"metadata":{},"sourceType":"script"}