{"ast":null,"code":"import * as tf from '@tensorflow/tfjs-core';\nimport { env } from '../env';\nimport { padToSquare } from '../ops/padToSquare';\nimport { computeReshapedDimensions, isTensor3D, isTensor4D, range } from '../utils';\nimport { createCanvasFromMedia } from './createCanvas';\nimport { imageToSquare } from './imageToSquare';\n\nvar NetInput =\n/** @class */\nfunction () {\n  function NetInput(inputs, treatAsBatchInput) {\n    var _this = this;\n\n    if (treatAsBatchInput === void 0) {\n      treatAsBatchInput = false;\n    }\n\n    this._imageTensors = [];\n    this._canvases = [];\n    this._treatAsBatchInput = false;\n    this._inputDimensions = [];\n\n    if (!Array.isArray(inputs)) {\n      throw new Error(\"NetInput.constructor - expected inputs to be an Array of TResolvedNetInput or to be instanceof tf.Tensor4D, instead have \" + inputs);\n    }\n\n    this._treatAsBatchInput = treatAsBatchInput;\n    this._batchSize = inputs.length;\n    inputs.forEach(function (input, idx) {\n      if (isTensor3D(input)) {\n        _this._imageTensors[idx] = input;\n        _this._inputDimensions[idx] = input.shape;\n        return;\n      }\n\n      if (isTensor4D(input)) {\n        var batchSize = input.shape[0];\n\n        if (batchSize !== 1) {\n          throw new Error(\"NetInput - tf.Tensor4D with batchSize \" + batchSize + \" passed, but not supported in input array\");\n        }\n\n        _this._imageTensors[idx] = input;\n        _this._inputDimensions[idx] = input.shape.slice(1);\n        return;\n      }\n\n      var canvas = input instanceof env.getEnv().Canvas ? input : createCanvasFromMedia(input);\n      _this._canvases[idx] = canvas;\n      _this._inputDimensions[idx] = [canvas.height, canvas.width, 3];\n    });\n  }\n\n  Object.defineProperty(NetInput.prototype, \"imageTensors\", {\n    get: function get() {\n      return this._imageTensors;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(NetInput.prototype, \"canvases\", {\n    get: function get() {\n      return this._canvases;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(NetInput.prototype, \"isBatchInput\", {\n    get: function get() {\n      return this.batchSize > 1 || this._treatAsBatchInput;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(NetInput.prototype, \"batchSize\", {\n    get: function get() {\n      return this._batchSize;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(NetInput.prototype, \"inputDimensions\", {\n    get: function get() {\n      return this._inputDimensions;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(NetInput.prototype, \"inputSize\", {\n    get: function get() {\n      return this._inputSize;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(NetInput.prototype, \"reshapedInputDimensions\", {\n    get: function get() {\n      var _this = this;\n\n      return range(this.batchSize, 0, 1).map(function (_, batchIdx) {\n        return _this.getReshapedInputDimensions(batchIdx);\n      });\n    },\n    enumerable: true,\n    configurable: true\n  });\n\n  NetInput.prototype.getInput = function (batchIdx) {\n    return this.canvases[batchIdx] || this.imageTensors[batchIdx];\n  };\n\n  NetInput.prototype.getInputDimensions = function (batchIdx) {\n    return this._inputDimensions[batchIdx];\n  };\n\n  NetInput.prototype.getInputHeight = function (batchIdx) {\n    return this._inputDimensions[batchIdx][0];\n  };\n\n  NetInput.prototype.getInputWidth = function (batchIdx) {\n    return this._inputDimensions[batchIdx][1];\n  };\n\n  NetInput.prototype.getReshapedInputDimensions = function (batchIdx) {\n    if (typeof this.inputSize !== 'number') {\n      throw new Error('getReshapedInputDimensions - inputSize not set, toBatchTensor has not been called yet');\n    }\n\n    var width = this.getInputWidth(batchIdx);\n    var height = this.getInputHeight(batchIdx);\n    return computeReshapedDimensions({\n      width: width,\n      height: height\n    }, this.inputSize);\n  };\n  /**\r\n   * Create a batch tensor from all input canvases and tensors\r\n   * with size [batchSize, inputSize, inputSize, 3].\r\n   *\r\n   * @param inputSize Height and width of the tensor.\r\n   * @param isCenterImage (optional, default: false) If true, add an equal amount of padding on\r\n   * both sides of the minor dimension oof the image.\r\n   * @returns The batch tensor.\r\n   */\n\n\n  NetInput.prototype.toBatchTensor = function (inputSize, isCenterInputs) {\n    var _this = this;\n\n    if (isCenterInputs === void 0) {\n      isCenterInputs = true;\n    }\n\n    this._inputSize = inputSize;\n    return tf.tidy(function () {\n      var inputTensors = range(_this.batchSize, 0, 1).map(function (batchIdx) {\n        var input = _this.getInput(batchIdx);\n\n        if (input instanceof tf.Tensor) {\n          var imgTensor = isTensor4D(input) ? input : input.expandDims();\n          imgTensor = padToSquare(imgTensor, isCenterInputs);\n\n          if (imgTensor.shape[1] !== inputSize || imgTensor.shape[2] !== inputSize) {\n            imgTensor = tf.image.resizeBilinear(imgTensor, [inputSize, inputSize]);\n          }\n\n          return imgTensor.as3D(inputSize, inputSize, 3);\n        }\n\n        if (input instanceof env.getEnv().Canvas) {\n          return tf.browser.fromPixels(imageToSquare(input, inputSize, isCenterInputs));\n        }\n\n        throw new Error(\"toBatchTensor - at batchIdx \" + batchIdx + \", expected input to be instanceof tf.Tensor or instanceof HTMLCanvasElement, instead have \" + input);\n      });\n      var batchTensor = tf.stack(inputTensors.map(function (t) {\n        return t.toFloat();\n      })).as4D(_this.batchSize, inputSize, inputSize, 3);\n      return batchTensor;\n    });\n  };\n\n  return NetInput;\n}();\n\nexport { NetInput };","map":null,"metadata":{},"sourceType":"module"}