{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\n// inspired by https://github.com/maxogden/filereader-stream\nimport { env, util } from '@tensorflow/tfjs-core';\nimport { ByteChunkIterator } from './byte_chunk_iterator';\n/**\n * Provide a stream of chunks from a File, Blob, or Uint8Array.\n * @param file The source File, Blob or Uint8Array.\n * @param options Optional settings controlling file reading.\n * @returns a lazy Iterator of Uint8Arrays containing sequential chunks of the\n *   input File, Blob or Uint8Array.\n */\n\nexport var FileChunkIterator = /*#__PURE__*/function (_ByteChunkIterator) {\n  _inherits(FileChunkIterator, _ByteChunkIterator);\n\n  function FileChunkIterator(file) {\n    var _this;\n\n    var options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n\n    _classCallCheck(this, FileChunkIterator);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(FileChunkIterator).call(this));\n    _this.file = file;\n    _this.options = options;\n    util.assert(file instanceof Uint8Array || (env().get('IS_BROWSER') ? file instanceof File || file instanceof Blob : false), function () {\n      return 'FileChunkIterator only supports File, Blob and Uint8Array ' + 'right now.';\n    });\n    _this.offset = options.offset || 0; // default 1MB chunk has tolerable perf on large files\n\n    _this.chunkSize = options.chunkSize || 1024 * 1024;\n    return _this;\n  }\n\n  _createClass(FileChunkIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"FileChunks \".concat(this.file);\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var _this2 = this;\n\n        var chunk;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!(this.offset >= (this.file instanceof Uint8Array ? this.file.byteLength : this.file.size))) {\n                  _context.next = 2;\n                  break;\n                }\n\n                return _context.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 2:\n                chunk = new Promise(function (resolve, reject) {\n                  var end = _this2.offset + _this2.chunkSize;\n\n                  if (_this2.file instanceof Uint8Array) {\n                    // Note if end > this.uint8Array.byteLength, we just get a small last\n                    // chunk.\n                    resolve(new Uint8Array(_this2.file.slice(_this2.offset, end)));\n                  } else {\n                    // This branch assumes that this.file type is File or Blob, which\n                    // means it is in the browser environment.\n                    // TODO(soergel): is this a performance issue?\n                    var fileReader = new FileReader();\n\n                    fileReader.onload = function (event) {\n                      var data = fileReader.result; // Not sure we can trust the return type of\n                      // FileReader.readAsArrayBuffer See e.g.\n                      // https://github.com/node-file-api/FileReader/issues/2\n\n                      if (data instanceof ArrayBuffer) {\n                        data = new Uint8Array(data);\n                      }\n\n                      if (!(data instanceof Uint8Array)) {\n                        return reject(new TypeError('FileReader returned unknown type.'));\n                      }\n\n                      resolve(data);\n                    };\n\n                    fileReader.onabort = function (event) {\n                      return reject(new Error('Aborted'));\n                    };\n\n                    fileReader.onerror = function (event) {\n                      return reject(new Error(event.type));\n                    }; // TODO(soergel): better handle onabort, onerror\n                    // Note if end > this.file.size, we just get a small last chunk.\n\n\n                    var slice = _this2.file.slice(_this2.offset, end); // We can't use readAsText here (even if we know the file is text)\n                    // because the slice boundary may fall within a multi-byte character.\n\n\n                    fileReader.readAsArrayBuffer(slice);\n                  }\n\n                  _this2.offset = end;\n                });\n                _context.next = 5;\n                return chunk;\n\n              case 5:\n                _context.t0 = _context.sent;\n                return _context.abrupt(\"return\", {\n                  value: _context.t0,\n                  done: false\n                });\n\n              case 7:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function next() {\n        return _next.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return FileChunkIterator;\n}(ByteChunkIterator);","map":null,"metadata":{},"sourceType":"module"}