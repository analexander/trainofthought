{"ast":null,"code":"import _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _toConsumableArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _assertThisInitialized from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/assertThisInitialized\";\n\n/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n// Import webgl flags.\nimport './flags_webgl';\nimport * as tf from '@tensorflow/tfjs-core';\nimport { div, engine, env, max, range, reshape, scalar, softmax, tensor, tidy, transpose } from '@tensorflow/tfjs-core';\nimport { backend_util, buffer, kernel_impls, slice_util, util } from '@tensorflow/tfjs-core';\nimport { DataStorage, KernelBackend, upcastType } from '@tensorflow/tfjs-core';\nimport { ceilImplCPU, expImplCPU, expm1ImplCPU, floorImplCPU, logImplCPU, rsqrtImplCPU, simpleAbsImplCPU, sliceImplCPU } from './kernel_utils/shared';\nvar segment_util = backend_util.segment_util;\nvar _split = kernel_impls.split;\nvar _tile = kernel_impls.tile;\nvar topkImpl = kernel_impls.topkImpl;\nvar whereImpl = kernel_impls.whereImpl;\nimport { AddNProgram } from './addn_gpu';\nimport { AddNPackedProgram } from './addn_packed_gpu';\nimport { ArgMinMaxProgram } from './argminmax_gpu';\nimport { ArgMinMaxPackedProgram } from './argminmax_packed_gpu';\nimport { AvgPool3DBackpropProgram } from './avg_pool_backprop_gpu';\nimport * as binaryop_gpu from './binaryop_gpu';\nimport { BinaryOpProgram } from './binaryop_gpu';\nimport * as binaryop_packed_gpu from './binaryop_packed_gpu';\nimport { BinaryOpPackedProgram } from './binaryop_packed_gpu';\nimport { getWebGLContext } from './canvas_util';\nimport { ClipProgram } from './clip_gpu';\nimport { ClipPackedProgram } from './clip_packed_gpu';\nimport { ComplexAbsProgram } from './complex_abs_gpu';\nimport { Conv2DDerFilterProgram, Conv2DDerInputProgram, Conv3DDerFilterProgram, Conv3DDerInputProgram } from './conv_backprop_gpu';\nimport { DepthwiseConv2DDerFilterProgram, DepthwiseConv2DDerInputProgram } from './conv_backprop_gpu_depthwise';\nimport { Conv2DProgram, Conv3DProgram } from './conv_gpu';\nimport { DepthwiseConv2DProgram } from './conv_gpu_depthwise';\nimport { DepthwiseConvPacked2DProgram } from './conv_packed_gpu_depthwise';\nimport { CropAndResizeProgram } from './crop_and_resize_gpu';\nimport { CumSumProgram } from './cumsum_gpu';\nimport { DecodeMatrixProgram } from './decode_matrix_gpu';\nimport { DecodeMatrixPackedProgram } from './decode_matrix_packed_gpu';\nimport { DepthToSpaceProgram } from './depth_to_space_gpu';\nimport { DiagProgram } from './diag_gpu';\nimport { EncodeFloatProgram } from './encode_float_gpu';\nimport { EncodeFloatPackedProgram } from './encode_float_packed_gpu';\nimport { EncodeMatrixProgram } from './encode_matrix_gpu';\nimport { EncodeMatrixPackedProgram } from './encode_matrix_packed_gpu';\nimport { FillProgram } from './fill_gpu';\nimport { GatherProgram } from './gather_gpu';\nimport { GatherNDProgram } from './gather_nd_gpu';\nimport { GPGPUContext } from './gpgpu_context';\nimport * as gpgpu_math from './gpgpu_math';\nimport { Im2ColPackedProgram } from './im2col_packed_gpu';\nimport { LRNProgram } from './lrn_gpu';\nimport { LRNGradProgram } from './lrn_grad_gpu';\nimport { LRNPackedProgram } from './lrn_packed_gpu';\nimport { MaxPool3DBackpropProgram } from './max_pool_backprop_gpu';\nimport { MatMulPackedProgram } from './mulmat_packed_gpu';\nimport { MultinomialProgram } from './multinomial_gpu';\nimport { OneHotProgram } from './onehot_gpu';\nimport { PackProgram } from './pack_gpu';\nimport { PadProgram } from './pad_gpu';\nimport { PadPackedProgram } from './pad_packed_gpu';\nimport { Pool3DProgram } from './pool_gpu';\nimport { ReduceProgram } from './reduce_gpu';\nimport { ReshapePackedProgram } from './reshape_packed_gpu';\nimport { ResizeBilinearBackpropProgram } from './resize_bilinear_backprop_gpu';\nimport { ResizeBilinearProgram } from './resize_bilinear_gpu';\nimport { ResizeBilinearPackedProgram } from './resize_bilinear_packed_gpu';\nimport { ResizeNearestNeigborBackpropProgram } from './resize_nearest_neighbor_backprop_gpu';\nimport { ResizeNearestNeighborProgram } from './resize_nearest_neighbor_gpu';\nimport { ReverseProgram } from './reverse_gpu';\nimport { ReversePackedProgram } from './reverse_packed_gpu';\nimport { ScatterProgram } from './scatter_gpu';\nimport { SegmentOpProgram } from './segment_gpu';\nimport { SelectProgram } from './select_gpu';\nimport { SliceProgram } from './slice_gpu';\nimport { SlicePackedProgram } from './slice_packed_gpu';\nimport { StridedSliceProgram } from './strided_slice_gpu';\nimport * as tex_util from './tex_util';\nimport { TextureUsage } from './tex_util';\nimport { TextureManager } from './texture_manager';\nimport { TileProgram } from './tile_gpu';\nimport * as unary_op from './unaryop_gpu';\nimport { UnaryOpProgram } from './unaryop_gpu';\nimport * as unary_packed_op from './unaryop_packed_gpu';\nimport { UnaryOpPackedProgram } from './unaryop_packed_gpu';\nimport { UnpackProgram } from './unpack_gpu';\nimport * as webgl_util from './webgl_util';\nexport var EPSILON_FLOAT32 = 1e-7;\nexport var EPSILON_FLOAT16 = 1e-4;\nvar binaryCaches = {};\nexport function getBinaryCache(webGLVersion) {\n  if (webGLVersion in binaryCaches) {\n    return binaryCaches[webGLVersion];\n  }\n\n  binaryCaches[webGLVersion] = {};\n  return binaryCaches[webGLVersion];\n}\n\nfunction mapActivationToShaderProgram(activation) {\n  var packed = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n\n  if (activation === 'linear') {\n    if (packed) {\n      return unary_packed_op.LINEAR;\n    }\n\n    return unary_op.LINEAR;\n  } else if (activation === 'relu') {\n    if (packed) {\n      return unary_packed_op.RELU;\n    }\n\n    return unary_op.RELU;\n  } else if (activation === 'elu') {\n    if (packed) {\n      return unary_packed_op.ELU;\n    }\n\n    return unary_op.ELU;\n  } else if (activation === 'relu6') {\n    if (packed) {\n      return unary_packed_op.RELU6;\n    }\n\n    return unary_op.RELU6;\n  } else if (activation === 'prelu') {\n    if (packed) {\n      return binaryop_packed_gpu.PRELU;\n    }\n\n    return binaryop_gpu.PRELU;\n  }\n\n  throw new Error(\"Activation \".concat(activation, \" has not been implemented for the WebGL backend.\"));\n} // Empirically determined constant used to determine size threshold for handing\n// off execution to the CPU.\n\n\nvar CPU_HANDOFF_SIZE_THRESHOLD = 128; // Empirically determined constant used to decide the number of MB on GPU\n// before we warn about high memory use. The MB are this constant * screen area\n// * dpi / 1024 / 1024.\n\nvar BEFORE_PAGING_CONSTANT = 600;\n\nfunction numMBBeforeWarning() {\n  if (env().global.screen == null) {\n    return 1024; // 1 GB.\n  }\n\n  return env().global.screen.height * env().global.screen.width * window.devicePixelRatio * BEFORE_PAGING_CONSTANT / 1024 / 1024;\n} // Empirically determined minimal shared dimension in matmul before we forward\n// to a.mul(b).sum() in order to take advantage of GPU parallelism. See\n// https://github.com/tensorflow/tfjs-core/pull/1379 for benchmarks.\n\n\nexport var MATMUL_SHARED_DIM_THRESHOLD = 1000;\nexport var MathBackendWebGL = /*#__PURE__*/function (_KernelBackend) {\n  _inherits(MathBackendWebGL, _KernelBackend);\n\n  function MathBackendWebGL(gpgpu) {\n    var _this;\n\n    _classCallCheck(this, MathBackendWebGL);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(MathBackendWebGL).call(this)); // Maps data ids that have a pending read operation, to list of subscribers.\n\n    _this.pendingRead = new WeakMap(); // List of data ids that are scheduled for disposal, but are waiting on a\n    // pending read operation.\n\n    _this.pendingDisposal = new WeakSet(); // Used to count the number of 'shallow' sliced tensors that point to the\n    // same data id.\n\n    _this.dataRefCount = new WeakMap();\n    _this.numBytesInGPU = 0; // Accumulated time spent (including blocking) in uploading data to webgl.\n\n    _this.uploadWaitMs = 0; // Accumulated time spent (including blocking in downloading data from webgl.\n\n    _this.downloadWaitMs = 0;\n    _this.warnedAboutMemory = false;\n    _this.warnedAboutCPUBackend = false;\n    _this.pendingDeletes = 0;\n    _this.disposed = false;\n\n    if (!env().getBool('HAS_WEBGL')) {\n      throw new Error('WebGL is not supported on this device');\n    }\n\n    if (gpgpu == null) {\n      var gl = getWebGLContext(env().getNumber('WEBGL_VERSION'));\n      _this.binaryCache = getBinaryCache(env().getNumber('WEBGL_VERSION'));\n      _this.gpgpu = new GPGPUContext(gl);\n      _this.canvas = gl.canvas;\n      _this.gpgpuCreatedLocally = true;\n    } else {\n      _this.gpgpu = gpgpu;\n      _this.binaryCache = {};\n      _this.gpgpuCreatedLocally = false;\n      _this.canvas = gpgpu.gl.canvas;\n    }\n\n    _this.textureManager = new TextureManager(_this.gpgpu);\n    _this.numMBBeforeWarning = numMBBeforeWarning();\n    _this.texData = new DataStorage(_assertThisInitialized(_assertThisInitialized(_this)), engine());\n    return _this;\n  }\n\n  _createClass(MathBackendWebGL, [{\n    key: \"numDataIds\",\n    value: function numDataIds() {\n      return this.texData.numDataIds() + (this.cpuBackend ? this.cpuBackend.numDataIds() : 0) - this.pendingDeletes;\n    }\n  }, {\n    key: \"write\",\n    value: function write(values, shape, dtype) {\n      if (env().getBool('WEBGL_CHECK_NUMERICAL_PROBLEMS') || env().getBool('DEBUG')) {\n        this.checkNumericalProblems(values);\n      }\n\n      if (dtype === 'complex64' && values != null) {\n        throw new Error(\"Cannot write to a complex64 dtype. \" + \"Please use tf.complex(real, imag).\");\n      }\n\n      var dataId = {};\n      this.texData.set(dataId, {\n        shape: shape,\n        dtype: dtype,\n        values: values,\n        usage: TextureUsage.UPLOAD,\n        refCount: 1,\n        complexParentRefCount: 0\n      });\n      return dataId;\n    }\n    /** Increase refCount of a `TextureData`. */\n\n  }, {\n    key: \"incRef\",\n    value: function incRef(dataId) {\n      var texData = this.texData.get(dataId);\n      texData.refCount++;\n    }\n    /** Decrease refCount of a `TextureData`. */\n\n  }, {\n    key: \"decRef\",\n    value: function decRef(dataId) {\n      if (this.texData.has(dataId)) {\n        var texData = this.texData.get(dataId);\n        texData.refCount--;\n      }\n    }\n  }, {\n    key: \"move\",\n    value: function move(dataId, values, shape, dtype) {\n      if (env().getBool('DEBUG')) {\n        this.checkNumericalProblems(values);\n      }\n\n      if (dtype === 'complex64') {\n        throw new Error(\"Cannot write to a complex64 dtype. \" + \"Please use tf.complex(real, imag).\");\n      }\n\n      this.texData.set(dataId, {\n        shape: shape,\n        dtype: dtype,\n        values: values,\n        usage: TextureUsage.UPLOAD,\n        refCount: 1,\n        complexParentRefCount: 0\n      });\n    }\n  }, {\n    key: \"disposeIntermediateTensorInfo\",\n    value: function disposeIntermediateTensorInfo(tensorInfo) {\n      var dataId = tensorInfo.dataId;\n\n      if (this.texData.has(dataId)) {\n        var textureData = this.texData.get(dataId);\n        textureData.refCount--;\n\n        if (textureData.refCount < 1) {\n          this.disposeData(dataId);\n        }\n      }\n    }\n  }, {\n    key: \"readSync\",\n    value: function readSync(dataId) {\n      var texData = this.texData.get(dataId);\n      var values = texData.values,\n          dtype = texData.dtype,\n          complexTensorInfos = texData.complexTensorInfos,\n          slice = texData.slice,\n          shape = texData.shape,\n          isPacked = texData.isPacked; // The presence of `slice` indicates this tensor is a shallow slice of a\n      // different tensor, and is using that original tensor's texture. Run\n      // `clone` in order to copy that texture and read from it.\n\n      if (slice != null) {\n        var program;\n\n        if (isPacked) {\n          program = new UnaryOpPackedProgram(shape, unary_op.CLONE);\n        } else {\n          program = new UnaryOpProgram(shape, unary_op.CLONE);\n        }\n\n        var res = this.runWebGLProgram(program, [{\n          dataId: dataId,\n          shape: shape,\n          dtype: dtype\n        }], dtype);\n        var data = this.readSync(res.dataId);\n        this.disposeIntermediateTensorInfo(res);\n        return data;\n      }\n\n      if (values != null) {\n        return this.convertAndCacheOnCPU(dataId);\n      }\n\n      if (dtype === 'string') {\n        return values;\n      }\n\n      var shouldTimeProgram = this.activeTimers != null;\n      var start;\n\n      if (shouldTimeProgram) {\n        start = util.now();\n      }\n\n      var result;\n\n      if (dtype === 'complex64') {\n        var realValues = this.readSync(complexTensorInfos.real.dataId);\n        var imagValues = this.readSync(complexTensorInfos.imag.dataId);\n        result = backend_util.mergeRealAndImagArrays(realValues, imagValues);\n      } else {\n        result = this.getValuesFromTexture(dataId);\n      }\n\n      if (shouldTimeProgram) {\n        this.downloadWaitMs += util.now() - start;\n      }\n\n      return this.convertAndCacheOnCPU(dataId, result);\n    }\n  }, {\n    key: \"read\",\n    value: function () {\n      var _read = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(dataId) {\n        var _subscribers, texData, values, shape, slice, dtype, complexTensorInfos, isPacked, program, res, data, buffer, tmpDownloadTarget, _this$gpgpu, tmpData, vals, ps, realValues, imagValues, size, dTypeVals, subscribers;\n\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                if (!this.pendingRead.has(dataId)) {\n                  _context.next = 3;\n                  break;\n                }\n\n                _subscribers = this.pendingRead.get(dataId);\n                return _context.abrupt(\"return\", new Promise(function (resolve) {\n                  return _subscribers.push(resolve);\n                }));\n\n              case 3:\n                texData = this.texData.get(dataId);\n                values = texData.values, shape = texData.shape, slice = texData.slice, dtype = texData.dtype, complexTensorInfos = texData.complexTensorInfos, isPacked = texData.isPacked; // The presence of `slice` indicates this tensor is a shallow slice of a\n                // different tensor, and is using that original tensor's texture. Run\n                // `clone` in order to copy that texture and read from it.\n\n                if (!(slice != null)) {\n                  _context.next = 11;\n                  break;\n                }\n\n                if (isPacked) {\n                  program = new UnaryOpPackedProgram(shape, unary_op.CLONE);\n                } else {\n                  program = new UnaryOpProgram(shape, unary_op.CLONE);\n                }\n\n                res = this.runWebGLProgram(program, [{\n                  dataId: dataId,\n                  shape: shape,\n                  dtype: dtype\n                }], dtype);\n                data = this.read(res.dataId);\n                this.disposeIntermediateTensorInfo(res);\n                return _context.abrupt(\"return\", data);\n\n              case 11:\n                if (!(values != null)) {\n                  _context.next = 13;\n                  break;\n                }\n\n                return _context.abrupt(\"return\", this.convertAndCacheOnCPU(dataId));\n\n              case 13:\n                if (!(!env().getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED') && env().getNumber('WEBGL_VERSION') === 2)) {\n                  _context.next = 15;\n                  break;\n                }\n\n                throw new Error(\"tensor.data() with WEBGL_DOWNLOAD_FLOAT_ENABLED=false and \" + \"WEBGL_VERSION=2 not yet supported.\");\n\n              case 15:\n                buffer = null;\n\n                if (dtype !== 'complex64' && env().get('WEBGL_BUFFER_SUPPORTED')) {\n                  // Possibly copy the texture into a buffer before inserting a fence.\n                  tmpDownloadTarget = this.decode(dataId);\n                  tmpData = this.texData.get(tmpDownloadTarget.dataId);\n                  buffer = (_this$gpgpu = this.gpgpu).createBufferFromTexture.apply(_this$gpgpu, [tmpData.texture].concat(_toConsumableArray(tex_util.getDenseTexShape(shape))));\n                }\n\n                this.pendingRead.set(dataId, []);\n\n                if (!(dtype !== 'complex64')) {\n                  _context.next = 21;\n                  break;\n                }\n\n                _context.next = 21;\n                return this.gpgpu.createAndWaitForFence();\n\n              case 21:\n                if (!(dtype === 'complex64')) {\n                  _context.next = 30;\n                  break;\n                }\n\n                _context.next = 24;\n                return Promise.all([this.read(complexTensorInfos.real.dataId), this.read(complexTensorInfos.imag.dataId)]);\n\n              case 24:\n                ps = _context.sent;\n                realValues = ps[0];\n                imagValues = ps[1];\n                vals = backend_util.mergeRealAndImagArrays(realValues, imagValues);\n                _context.next = 31;\n                break;\n\n              case 30:\n                if (buffer == null) {\n                  vals = this.getValuesFromTexture(dataId);\n                } else {\n                  size = util.sizeFromShape(shape);\n                  vals = this.gpgpu.downloadFloat32MatrixFromBuffer(buffer, size);\n                }\n\n              case 31:\n                if (tmpDownloadTarget != null) {\n                  this.disposeIntermediateTensorInfo(tmpDownloadTarget);\n                }\n\n                dTypeVals = this.convertAndCacheOnCPU(dataId, vals);\n                subscribers = this.pendingRead.get(dataId);\n                this.pendingRead.delete(dataId); // Notify all pending reads.\n\n                subscribers.forEach(function (resolve) {\n                  return resolve(dTypeVals);\n                });\n\n                if (this.pendingDisposal.has(dataId)) {\n                  this.pendingDisposal.delete(dataId);\n                  this.disposeData(dataId);\n                  this.pendingDeletes--;\n                }\n\n                return _context.abrupt(\"return\", dTypeVals);\n\n              case 38:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function read(_x) {\n        return _read.apply(this, arguments);\n      }\n\n      return read;\n    }()\n  }, {\n    key: \"checkNumericalProblems\",\n    value: function checkNumericalProblems(values) {\n      if (values == null) {\n        return;\n      }\n\n      for (var i = 0; i < values.length; i++) {\n        var num = values[i];\n\n        if (!webgl_util.canBeRepresented(num)) {\n          if (env().getBool('WEBGL_RENDER_FLOAT32_CAPABLE')) {\n            throw Error(\"The value \".concat(num, \" cannot be represented with your \") + \"current settings. Consider enabling float32 rendering: \" + \"'tf.env().set('WEBGL_RENDER_FLOAT32_ENABLED', true);'\");\n          }\n\n          throw Error(\"The value \".concat(num, \" cannot be represented on this device.\"));\n        }\n      }\n    }\n  }, {\n    key: \"getValuesFromTexture\",\n    value: function getValuesFromTexture(dataId) {\n      var _this$texData$get = this.texData.get(dataId),\n          shape = _this$texData$get.shape,\n          dtype = _this$texData$get.dtype,\n          isPacked = _this$texData$get.isPacked;\n\n      var size = util.sizeFromShape(shape);\n\n      if (env().getBool('WEBGL_DOWNLOAD_FLOAT_ENABLED')) {\n        var _this$gpgpu2;\n\n        var tmpTarget = this.decode(dataId);\n\n        var _tmpData = this.texData.get(tmpTarget.dataId);\n\n        var _vals = (_this$gpgpu2 = this.gpgpu).downloadMatrixFromPackedTexture.apply(_this$gpgpu2, [_tmpData.texture].concat(_toConsumableArray(tex_util.getDenseTexShape(shape)))).subarray(0, size);\n\n        this.disposeIntermediateTensorInfo(tmpTarget);\n        return _vals;\n      }\n\n      var shouldUsePackedProgram = env().getBool('WEBGL_PACK') && isPacked === true;\n      var outputShape = shouldUsePackedProgram ? webgl_util.getShapeAs3D(shape) : shape;\n      var program = shouldUsePackedProgram ? new EncodeFloatPackedProgram(outputShape) : new EncodeFloatProgram(outputShape);\n      var output = this.runWebGLProgram(program, [{\n        shape: outputShape,\n        dtype: dtype,\n        dataId: dataId\n      }], 'float32');\n      var tmpData = this.texData.get(output.dataId);\n      var vals = this.gpgpu.downloadByteEncodedFloatMatrixFromOutputTexture(tmpData.texture, tmpData.texShape[0], tmpData.texShape[1]).subarray(0, size);\n      this.disposeIntermediateTensorInfo(output);\n      return vals;\n    }\n  }, {\n    key: \"time\",\n    value: function () {\n      var _time = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(f) {\n        var oldActiveTimers, newActiveTimers, outerMostTime, flattenedActiveTimerQueries, flattenedActiveTimerNames, res, kernelMs;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                oldActiveTimers = this.activeTimers;\n                newActiveTimers = [];\n                outerMostTime = false;\n\n                if (this.programTimersStack == null) {\n                  this.programTimersStack = newActiveTimers;\n                  outerMostTime = true;\n                } else {\n                  this.activeTimers.push(newActiveTimers);\n                }\n\n                this.activeTimers = newActiveTimers;\n                f(); // needing to split these up because util.flatten only accepts certain types\n\n                flattenedActiveTimerQueries = util.flatten(this.activeTimers.map(function (d) {\n                  return d.query;\n                })).filter(function (d) {\n                  return d != null;\n                });\n                flattenedActiveTimerNames = util.flatten(this.activeTimers.map(function (d) {\n                  return d.name;\n                })).filter(function (d) {\n                  return d != null;\n                });\n                this.activeTimers = oldActiveTimers;\n\n                if (outerMostTime) {\n                  this.programTimersStack = null;\n                }\n\n                res = {\n                  uploadWaitMs: this.uploadWaitMs,\n                  downloadWaitMs: this.downloadWaitMs,\n                  kernelMs: null,\n                  wallMs: null // will be filled by the engine\n\n                };\n\n                if (!(env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0)) {\n                  _context2.next = 19;\n                  break;\n                }\n\n                _context2.next = 14;\n                return Promise.all(flattenedActiveTimerQueries);\n\n              case 14:\n                kernelMs = _context2.sent;\n                res['kernelMs'] = util.sum(kernelMs);\n\n                res['getExtraProfileInfo'] = function () {\n                  return kernelMs.map(function (d, i) {\n                    return {\n                      name: flattenedActiveTimerNames[i],\n                      ms: d\n                    };\n                  }).map(function (d) {\n                    return \"\".concat(d.name, \": \").concat(d.ms);\n                  }).join(', ');\n                };\n\n                _context2.next = 20;\n                break;\n\n              case 19:\n                res['kernelMs'] = {\n                  error: 'WebGL query timers are not supported in this environment.'\n                };\n\n              case 20:\n                this.uploadWaitMs = 0;\n                this.downloadWaitMs = 0;\n                return _context2.abrupt(\"return\", res);\n\n              case 23:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function time(_x2) {\n        return _time.apply(this, arguments);\n      }\n\n      return time;\n    }()\n  }, {\n    key: \"memory\",\n    value: function memory() {\n      return {\n        unreliable: false,\n        numBytesInGPU: this.numBytesInGPU,\n        numBytesInGPUAllocated: this.textureManager.numBytesAllocated,\n        numBytesInGPUFree: this.textureManager.numBytesFree\n      };\n    }\n  }, {\n    key: \"startTimer\",\n    value: function startTimer() {\n      if (env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n        return this.gpgpu.beginQuery();\n      }\n\n      return {\n        startMs: util.now(),\n        endMs: null\n      };\n    }\n  }, {\n    key: \"endTimer\",\n    value: function endTimer(query) {\n      if (env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0) {\n        this.gpgpu.endQuery();\n        return query;\n      }\n\n      query.endMs = util.now();\n      return query;\n    }\n  }, {\n    key: \"getQueryTime\",\n    value: function () {\n      var _getQueryTime = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(query) {\n        var timerQuery;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                if (!(env().getNumber('WEBGL_DISJOINT_QUERY_TIMER_EXTENSION_RELIABLE') > 0)) {\n                  _context3.next = 2;\n                  break;\n                }\n\n                return _context3.abrupt(\"return\", this.gpgpu.waitForQueryAndGetTime(query));\n\n              case 2:\n                timerQuery = query;\n                return _context3.abrupt(\"return\", timerQuery.endMs - timerQuery.startMs);\n\n              case 4:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function getQueryTime(_x3) {\n        return _getQueryTime.apply(this, arguments);\n      }\n\n      return getQueryTime;\n    }()\n  }, {\n    key: \"disposeData\",\n    value: function disposeData(dataId) {\n      if (this.pendingDisposal.has(dataId)) {\n        return;\n      }\n\n      if (this.pendingRead.has(dataId)) {\n        this.pendingDisposal.add(dataId);\n        this.pendingDeletes++;\n        return;\n      } // No-op if already disposed.\n\n\n      if (!this.texData.has(dataId)) {\n        return;\n      } // Trying to dispose a textureData that has a 'kept' refCount, e.g. trying\n      // to dispose a tensor whose data bucket is shared with a complex tensor. In\n      // this case we are removing a reference to the textureData, but we\n      // shouldn't actually dispose the texture.\n\n\n      if (this.texData.get(dataId).complexParentRefCount > 0) {\n        this.texData.get(dataId).refCount--;\n        return;\n      }\n\n      this.releaseGPUData(dataId);\n\n      var _this$texData$get2 = this.texData.get(dataId),\n          complexTensorInfos = _this$texData$get2.complexTensorInfos;\n\n      if (complexTensorInfos != null) {\n        this.texData.get(complexTensorInfos.real.dataId).complexParentRefCount--;\n        this.disposeIntermediateTensorInfo(complexTensorInfos.real);\n        this.texData.get(complexTensorInfos.imag.dataId).complexParentRefCount--;\n        this.disposeIntermediateTensorInfo(complexTensorInfos.imag);\n      }\n\n      this.texData.delete(dataId);\n    }\n  }, {\n    key: \"releaseGPUData\",\n    value: function releaseGPUData(dataId) {\n      var _this$texData$get3 = this.texData.get(dataId),\n          texture = _this$texData$get3.texture,\n          dtype = _this$texData$get3.dtype,\n          texShape = _this$texData$get3.texShape,\n          usage = _this$texData$get3.usage,\n          isPacked = _this$texData$get3.isPacked,\n          slice = _this$texData$get3.slice;\n\n      var key = slice && slice.origDataId || dataId;\n      var refCount = this.dataRefCount.get(key);\n\n      if (refCount > 1) {\n        this.dataRefCount.set(key, refCount - 1);\n      } else {\n        this.dataRefCount.delete(key);\n\n        if (texture != null) {\n          this.numBytesInGPU -= this.computeBytes(texShape, dtype);\n          this.textureManager.releaseTexture(texture, texShape, usage, isPacked);\n        }\n      }\n\n      var texData = this.texData.get(dataId);\n      texData.texture = null;\n      texData.texShape = null;\n      texData.isPacked = false;\n      texData.slice = null;\n    }\n  }, {\n    key: \"getTexture\",\n    value: function getTexture(dataId) {\n      this.uploadToGPU(dataId);\n      return this.texData.get(dataId).texture;\n    }\n    /**\n     * Returns internal information for the specific data bucket. Used in unit\n     * tests.\n     */\n\n  }, {\n    key: \"getDataInfo\",\n    value: function getDataInfo(dataId) {\n      return this.texData.get(dataId);\n    }\n  }, {\n    key: \"getCPUBackend\",\n    value: function getCPUBackend() {\n      if (!env().getBool('WEBGL_CPU_FORWARD')) {\n        return null;\n      }\n\n      if (this.cpuBackend == null) {\n        this.cpuBackend = engine().findBackend('cpu');\n      }\n\n      return this.cpuBackend;\n    }\n    /*\n    Tests whether all the inputs to an op are small and on the CPU. This heuristic\n    determines when it would be faster to execute a kernel on the CPU. WebGL\n    kernels opt into running this check and forwarding when appropriate.\n    TODO(https://github.com/tensorflow/tfjs/issues/872): Develop a more\n    sustainable strategy for optimizing backend execution of ops.\n     */\n\n  }, {\n    key: \"shouldExecuteOnCPU\",\n    value: function shouldExecuteOnCPU(inputs) {\n      var _this2 = this;\n\n      var sizeThreshold = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : CPU_HANDOFF_SIZE_THRESHOLD;\n      var cpuBackend = this.getCPUBackend();\n\n      if (!this.warnedAboutCPUBackend && cpuBackend == null) {\n        console.warn('Your application contains ops that are small enough to be ' + 'executed on the CPU backend, however the CPU backend cannot ' + 'be found. Consider importing the CPU backend ' + '(@tensorflow/tfjs-backend-cpu) for better performance.');\n        this.warnedAboutCPUBackend = true;\n      }\n\n      return cpuBackend != null && inputs.every(function (input) {\n        return _this2.texData.get(input.dataId).texture == null && util.sizeFromShape(input.shape) < sizeThreshold;\n      });\n    }\n  }, {\n    key: \"getGPGPUContext\",\n    value: function getGPGPUContext() {\n      return this.gpgpu;\n    }\n  }, {\n    key: \"slice\",\n    value: function slice(x, begin, size) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = sliceImplCPU(this.texData.get(x.dataId).values, begin, size, x.shape, x.dtype);\n        return this.makeOutput(size, x.dtype, outValues);\n      } // Short-circuit computation if the slice is zero-sized.\n\n\n      if (util.sizeFromShape(size) === 0) {\n        return tensor([], size, x.dtype);\n      }\n\n      var _this$texData$get4 = this.texData.get(x.dataId),\n          isPacked = _this$texData$get4.isPacked;\n\n      var isContinous = slice_util.isSliceContinous(x.shape, begin, size);\n\n      if (isPacked || !isContinous) {\n        var program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new SlicePackedProgram(size) : new SliceProgram(size);\n        var customSetup = program.getCustomSetupFunc(begin);\n        return this.compileAndRun(program, [x], null, customSetup);\n      }\n\n      this.uploadToGPU(x.dataId);\n      return this.shallowSlice(x, begin, size);\n    }\n  }, {\n    key: \"shallowSlice\",\n    value: function shallowSlice(x, begin, size) {\n      var xTexData = this.texData.get(x.dataId);\n      var t = this.makeOutput(size, x.dtype);\n      var newTexData = this.texData.get(t.dataId); // Copy texture data from the original tensor.\n\n      Object.assign(newTexData, xTexData);\n      newTexData.shape = size;\n      newTexData.dtype = x.dtype;\n      var flatOffset = slice_util.computeFlatOffset(begin, x.strides);\n\n      if (xTexData.slice) {\n        // We are slicing an already sliced tensor, so we have to accumulate\n        // the offset.\n        flatOffset += xTexData.slice.flatOffset;\n      }\n\n      newTexData.slice = {\n        flatOffset: flatOffset,\n        // Point to the original dataId, which is used to do ref counting.\n        origDataId: xTexData.slice && xTexData.slice.origDataId || x.dataId\n      }; // Increase the ref count for that data bucket.\n\n      var refCount = this.dataRefCount.get(newTexData.slice.origDataId) || 1;\n      this.dataRefCount.set(newTexData.slice.origDataId, refCount + 1);\n      return t;\n    }\n  }, {\n    key: \"stridedSlice\",\n    value: function stridedSlice(x, begin, end, strides) {\n      var _this3 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([x], function () {\n        return _this3.cpuBackend.stridedSlice(x, begin, end, strides);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      var outShape = slice_util.computeOutShape(begin, end, strides);\n\n      if (outShape.some(function (axis) {\n        return axis === 0;\n      })) {\n        return tensor([], outShape);\n      }\n\n      var program = new StridedSliceProgram(begin, strides, outShape);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"reverse\",\n    value: function reverse(x, axis) {\n      var program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new ReversePackedProgram(x.shape, axis) : new ReverseProgram(x.shape, axis);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"neg\",\n    value: function neg(x) {\n      var _this4 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([x], function () {\n        return _this4.cpuBackend.neg(x);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_op.NEG, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.NEG);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"batchMatMul\",\n    value: function batchMatMul(a, b, transposeA, transposeB) {\n      var outerShapeA = transposeA ? a.shape[2] : a.shape[1];\n      var outerShapeB = transposeB ? b.shape[1] : b.shape[2];\n      var sharedDim = transposeA ? a.shape[1] : a.shape[2];\n      var batch = Math.max(a.shape[0], b.shape[0]); // Since the matrices are vectors, it is faster to call mul().sum()\n      // because sum() is O(sqrt(N)) due to divide-and-conquer.\n\n      if ((outerShapeA === 1 || outerShapeB === 1) && sharedDim > MATMUL_SHARED_DIM_THRESHOLD) {\n        if (transposeA) {\n          a = transpose(a, [0, 2, 1]);\n        }\n\n        if (transposeB) {\n          b = transpose(b, [0, 2, 1]);\n        }\n\n        var a3D = outerShapeB === 1 ? a : a.as3D(batch, sharedDim, 1);\n        var axis = outerShapeB === 1 ? 2 : 1;\n        var b3D = outerShapeB === 1 ? b.as3D(batch, 1, sharedDim) : b; // TODO(annxingyuan): Call multiply directly as part of batchMatMul\n        // modularization.\n\n        var product = tf.mul(a3D, b3D);\n        return product.sum(axis, true\n        /* keepDims */\n        );\n      }\n\n      var dtype = upcastType(a.dtype, b.dtype);\n      var program = new MatMulPackedProgram(a.shape, b.shape, [batch, outerShapeA, outerShapeB], transposeA, transposeB);\n      return this.compileAndRun(program, [a, b], dtype);\n    }\n  }, {\n    key: \"fusedBatchMatMul\",\n    value: function fusedBatchMatMul(_ref) {\n      var a = _ref.a,\n          b = _ref.b,\n          transposeA = _ref.transposeA,\n          transposeB = _ref.transposeB,\n          bias = _ref.bias,\n          activation = _ref.activation,\n          preluActivationWeights = _ref.preluActivationWeights;\n      var outerShapeA = transposeA ? a.shape[2] : a.shape[1];\n      var outerShapeB = transposeB ? b.shape[1] : b.shape[2];\n      var batch = Math.max(a.shape[0], b.shape[0]);\n      var dtype = upcastType(a.dtype, b.dtype);\n      var hasBias = bias != null;\n      var hasPreluActivationWeights = preluActivationWeights != null;\n      var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n      var program = new MatMulPackedProgram(a.shape, b.shape, [batch, outerShapeA, outerShapeB], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights);\n      var inputs = [a, b];\n\n      if (bias) {\n        inputs.push(bias);\n      }\n\n      if (preluActivationWeights) {\n        inputs.push(preluActivationWeights);\n      }\n\n      return this.compileAndRun(program, inputs, dtype);\n    }\n  }, {\n    key: \"localResponseNormalization4D\",\n    value: function localResponseNormalization4D(x, radius, bias, alpha, beta) {\n      var program = env().getBool('WEBGL_PACK_NORMALIZATION') ? new LRNPackedProgram(x.shape, radius, bias, alpha, beta) : new LRNProgram(x.shape, radius, bias, alpha, beta);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"LRNGrad\",\n    value: function LRNGrad(dy, inputImage, outputImage, depthRadius, bias, alpha, beta) {\n      var program = new LRNGradProgram(inputImage.shape, depthRadius, bias, alpha, beta);\n      return this.compileAndRun(program, [inputImage, outputImage, dy]);\n    }\n  }, {\n    key: \"tile\",\n    value: function tile(x, reps) {\n      if (x.dtype === 'string') {\n        var data = this.readSync(x.dataId);\n        var decodedData = data.map(function (d) {\n          return util.decodeString(d);\n        });\n        var buf = buffer(x.shape, x.dtype, decodedData);\n        return _tile(buf, reps);\n      }\n\n      var program = new TileProgram(x.shape, reps);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"pad\",\n    value: function pad(x, paddings, constantValue) {\n      var program = env().getBool('WEBGL_PACK_ARRAY_OPERATIONS') ? new PadPackedProgram(x.shape, paddings, constantValue) : new PadProgram(x.shape, paddings, constantValue);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"gather\",\n    value: function gather(x, indices, axis) {\n      var _this5 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([x, indices], function () {\n        return _this5.cpuBackend.gather(x, indices, axis);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      var program = new GatherProgram(x.shape, indices.size, axis);\n      return this.compileAndRun(program, [x, indices]);\n    }\n  }, {\n    key: \"batchToSpaceND\",\n    value: function batchToSpaceND(x, blockShape, crops) {\n      util.assert(x.rank <= 4, function () {\n        return 'batchToSpaceND for rank > 4 with a WebGL backend not ' + 'implemented yet';\n      });\n      var prod = blockShape.reduce(function (a, b) {\n        return a * b;\n      });\n      var reshaped = backend_util.getReshaped(x.shape, blockShape, prod);\n      var permuted = backend_util.getPermuted(reshaped.length, blockShape.length);\n      var reshapedPermuted = backend_util.getReshapedPermuted(x.shape, blockShape, prod);\n      var sliceBeginCoords = backend_util.getSliceBeginCoords(crops, blockShape.length);\n      var sliceSize = backend_util.getSliceSize(reshapedPermuted, crops, blockShape.length);\n      return transpose(x.reshape(reshaped), permuted).reshape(reshapedPermuted).slice(sliceBeginCoords, sliceSize);\n    }\n  }, {\n    key: \"spaceToBatchND\",\n    value: function spaceToBatchND(x, blockShape, paddings) {\n      util.assert(x.rank <= 4, function () {\n        return 'spaceToBatchND for rank > 4 with a WebGL backend not ' + 'implemented yet';\n      });\n      var prod = blockShape.reduce(function (a, b) {\n        return a * b;\n      });\n      var completePaddings = [[0, 0]];\n      completePaddings.push.apply(completePaddings, _toConsumableArray(paddings));\n\n      for (var i = 1 + blockShape.length; i < x.shape.length; ++i) {\n        completePaddings.push([0, 0]);\n      }\n\n      var paddedX = x.pad(completePaddings);\n      var reshapedPaddedShape = backend_util.getReshaped(paddedX.shape, blockShape, prod, false);\n      var permutedReshapedPaddedPermutation = backend_util.getPermuted(reshapedPaddedShape.length, blockShape.length, false);\n      var flattenShape = backend_util.getReshapedPermuted(paddedX.shape, blockShape, prod, false);\n      var paddedXT = transpose(paddedX.reshape(reshapedPaddedShape), permutedReshapedPaddedPermutation);\n      return reshape(paddedXT, flattenShape);\n    }\n  }, {\n    key: \"reduce\",\n    value: function reduce(x, reduceType, dtype) {\n      var batchSize = x.shape[0];\n      var inSize = x.shape[1];\n      var windowSize = backend_util.computeOptimalWindowSize(inSize);\n      var outSize = Math.ceil(inSize / windowSize);\n      var reduceInfo = {\n        windowSize: windowSize,\n        inSize: inSize,\n        batchSize: batchSize,\n        outSize: outSize\n      };\n      var program = new ReduceProgram(reduceInfo, reduceType);\n      var output = this.compileAndRun(program, [x], dtype); // No need to run another GPGPU program.\n\n      if (output.shape[1] === 1) {\n        return output;\n      }\n\n      return this.reduce(output, reduceType, dtype);\n    }\n  }, {\n    key: \"argReduce\",\n    value: function argReduce(x, reduceType) {\n      var bestIndicesA = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n      var batchSize = x.shape[0];\n      var inSize = x.shape[1];\n\n      if (bestIndicesA != null) {\n        batchSize = bestIndicesA.shape[0];\n        inSize = bestIndicesA.shape[1];\n      }\n\n      var windowSize = backend_util.computeOptimalWindowSize(inSize);\n      var reduceInfo = {\n        windowSize: windowSize,\n        inSize: inSize,\n        batchSize: batchSize,\n        outSize: Math.ceil(inSize / windowSize)\n      };\n      var program = new ArgMinMaxProgram(reduceInfo, reduceType, bestIndicesA == null);\n      var inputs = [x];\n\n      if (bestIndicesA != null) {\n        inputs.push(bestIndicesA);\n      }\n\n      var output = this.compileAndRun(program, inputs, 'int32'); // No need to run another GPGPU program.\n\n      if (output.shape[1] === 1) {\n        return output;\n      }\n\n      return this.argReduce(x, reduceType, output);\n    }\n  }, {\n    key: \"argReducePacked\",\n    value: function argReducePacked(x, reduceType) {\n      var bestIndicesA = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : null;\n      var inShape = bestIndicesA != null ? bestIndicesA.shape : x.shape;\n      var inSize = inShape[inShape.length - 1];\n      var windowSize = backend_util.computeOptimalWindowSize(inSize);\n      var program = new ArgMinMaxPackedProgram(inShape, windowSize, reduceType, bestIndicesA == null);\n      var inputs = bestIndicesA == null ? [x] : [x, bestIndicesA];\n      var output = this.compileAndRun(program, inputs, 'int32');\n\n      if (output.rank === x.rank) {\n        return this.argReducePacked(x, reduceType, output);\n      }\n\n      return output;\n    }\n  }, {\n    key: \"sum\",\n    value: function sum(x, axes) {\n      backend_util.assertAxesAreInnerMostDims('sum', axes, x.rank);\n\n      var _backend_util$compute = backend_util.computeOutAndReduceShapes(x.shape, axes),\n          _backend_util$compute2 = _slicedToArray(_backend_util$compute, 2),\n          outShape = _backend_util$compute2[0],\n          reduceShape = _backend_util$compute2[1];\n\n      var inSize = util.sizeFromShape(reduceShape);\n      var a2D = x.as2D(-1, inSize);\n      var outputDType = tf.sumOutType(x.dtype);\n      return this.reduce(a2D, 'sum', outputDType).reshape(outShape);\n    }\n  }, {\n    key: \"prod\",\n    value: function prod(x, axes) {\n      var _this6 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([x], function () {\n        return _this6.cpuBackend.prod(x, axes);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      var _backend_util$compute3 = backend_util.computeOutAndReduceShapes(x.shape, axes),\n          _backend_util$compute4 = _slicedToArray(_backend_util$compute3, 2),\n          outShape = _backend_util$compute4[0],\n          reduceShape = _backend_util$compute4[1];\n\n      var inSize = util.sizeFromShape(reduceShape);\n      var a2D = x.as2D(-1, inSize);\n      var outputDType = tf.sumOutType(x.dtype);\n      return this.reduce(a2D, 'prod', outputDType).reshape(outShape);\n    }\n  }, {\n    key: \"unsortedSegmentSum\",\n    value: function unsortedSegmentSum(x, segmentIds, numSegments) {\n      var axis = 0;\n      var permutation = backend_util.getAxesPermutation([axis], x.rank);\n      var permutedX = x;\n\n      if (permutation != null) {\n        permutedX = transpose(x, permutation);\n        axis = backend_util.getInnerMostAxes(1, x.rank)[0];\n      }\n\n      var outShape = segment_util.computeOutShape(permutedX.shape, axis, numSegments);\n      var inSize = util.sizeFromShape([permutedX.shape[axis]]);\n      var a2D = permutedX.as2D(-1, inSize);\n      var outputDType = tf.sumOutType(x.dtype);\n      var result = this.segOpCompute(a2D, 'unsortedSegmentSum', segmentIds, outputDType, numSegments).reshape(outShape);\n\n      if (permutation != null) {\n        result = transpose(result, backend_util.getUndoAxesPermutation(permutation));\n      }\n\n      return result;\n    }\n  }, {\n    key: \"segOpCompute\",\n    value: function segOpCompute(x, segOpType, segmentIds, dtype, numSegments) {\n      var batchSize = x.shape[0];\n      var inSize = x.shape[1];\n      var windowSize = segment_util.segOpComputeOptimalWindowSize(inSize, numSegments);\n      var segOpInfo = {\n        windowSize: windowSize,\n        inSize: inSize,\n        batchSize: batchSize,\n        numSegments: numSegments\n      };\n      var program = new SegmentOpProgram(segOpInfo, segOpType);\n      var output = this.compileAndRun(program, [x, segmentIds], dtype); // No need to run another GPGPU program.\n\n      if (output.shape[1] === numSegments) {\n        return output;\n      }\n\n      segmentIds = range(0, numSegments).tile([inSize / windowSize]);\n      return this.segOpCompute(output, segOpType, segmentIds, dtype, numSegments);\n    }\n  }, {\n    key: \"argMinMaxReduce\",\n    value: function argMinMaxReduce(x, axis, reduceType) {\n      var axes = [axis];\n      backend_util.assertAxesAreInnerMostDims('arg' + reduceType.charAt(0).toUpperCase() + reduceType.slice(1), axes, x.rank);\n\n      if (!env().getBool('WEBGL_PACK_REDUCE') || x.rank <= 2) {\n        var _backend_util$compute5 = backend_util.computeOutAndReduceShapes(x.shape, axes),\n            _backend_util$compute6 = _slicedToArray(_backend_util$compute5, 2),\n            outShape = _backend_util$compute6[0],\n            reduceShape = _backend_util$compute6[1];\n\n        var inSize = util.sizeFromShape(reduceShape);\n        var a2D = x.as2D(-1, inSize);\n        return this.argReduce(a2D, reduceType).reshape(outShape);\n      }\n\n      return this.argReducePacked(x, reduceType);\n    }\n  }, {\n    key: \"argMin\",\n    value: function argMin(x, axis) {\n      return this.argMinMaxReduce(x, axis, 'min');\n    }\n  }, {\n    key: \"argMax\",\n    value: function argMax(x, axis) {\n      return this.argMinMaxReduce(x, axis, 'max');\n    }\n  }, {\n    key: \"cumsum\",\n    value: function cumsum(x, axis, exclusive, reverse) {\n      if (axis !== x.rank - 1) {\n        throw new Error(\"WebGL cumsum shader expects an inner-most axis=\".concat(x.rank - 1, \" \") + \"but got axis=\".concat(axis));\n      }\n\n      var size = x.shape[axis];\n      var result = x; // Use cumsum parallel algorithm, ref:\n      // https://developer.nvidia.com/gpugems/gpugems3/part-vi-gpu-computing/chapter-39-parallel-prefix-sum-scan-cuda\n\n      for (var i = 0; i <= Math.ceil(Math.log2(size)) - 1; i++) {\n        var program = new CumSumProgram(x.shape, false, reverse);\n        var customSetup = program.getCustomSetupFunc(i);\n        var prevResult = result;\n        result = this.compileAndRun(program, [result], result.dtype, customSetup);\n        prevResult.dispose();\n      } // For exclusive cumsum, shift the end result in the direction of sum and\n      // add 0 to the front index.\n\n\n      if (exclusive) {\n        var _program = new CumSumProgram(x.shape, exclusive, reverse);\n\n        var _prevResult = result;\n        result = this.compileAndRun(_program, [result]);\n\n        _prevResult.dispose();\n      }\n\n      return result;\n    }\n  }, {\n    key: \"equal\",\n    value: function equal(a, b) {\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.EQUAL, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.EQUAL, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"less\",\n    value: function less(a, b) {\n      var _this7 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([a, b], function () {\n        return _this7.cpuBackend.less(a, b);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.LESS, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.LESS, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"lessEqual\",\n    value: function lessEqual(a, b) {\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.LESS_EQUAL, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.LESS_EQUAL, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"greater\",\n    value: function greater(a, b) {\n      var _this8 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([a, b], function () {\n        return _this8.cpuBackend.greater(a, b);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.GREATER, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.GREATER, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"greaterEqual\",\n    value: function greaterEqual(a, b) {\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.GREATER_EQUAL, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.GREATER_EQUAL, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"logicalNot\",\n    value: function logicalNot(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.LOGICAL_NOT);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"logicalAnd\",\n    value: function logicalAnd(a, b) {\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.LOGICAL_AND, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.LOGICAL_AND, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"logicalOr\",\n    value: function logicalOr(a, b) {\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.LOGICAL_OR, 'bool');\n      }\n\n      var program = new BinaryOpProgram(binaryop_gpu.LOGICAL_OR, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], 'bool');\n    }\n  }, {\n    key: \"select\",\n    value: function select(condition, a, b) {\n      var program = new SelectProgram(condition.rank, a.shape, a.rank);\n      return this.compileAndRun(program, [condition, a, b], upcastType(a.dtype, b.dtype));\n    }\n  }, {\n    key: \"where\",\n    value: function where(condition) {\n      backend_util.warn('tf.where() in webgl locks the UI thread. ' + 'Call tf.whereAsync() instead');\n      var condVals = condition.dataSync();\n      return whereImpl(condition.shape, condVals);\n    }\n  }, {\n    key: \"topk\",\n    value: function topk(x, k, sorted) {\n      var xVals = x.dataSync();\n      return topkImpl(xVals, x.shape, x.dtype, k, sorted);\n    }\n  }, {\n    key: \"min\",\n    value: function min(x, axes) {\n      backend_util.assertAxesAreInnerMostDims('min', axes, x.rank);\n\n      var _backend_util$compute7 = backend_util.computeOutAndReduceShapes(x.shape, axes),\n          _backend_util$compute8 = _slicedToArray(_backend_util$compute7, 2),\n          outShape = _backend_util$compute8[0],\n          reduceShape = _backend_util$compute8[1];\n\n      var inSize = util.sizeFromShape(reduceShape);\n      var a2D = x.as2D(-1, inSize);\n      return this.reduce(a2D, 'min', a2D.dtype).reshape(outShape);\n    }\n  }, {\n    key: \"minimum\",\n    value: function minimum(a, b) {\n      var _this9 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([a, b], function () {\n        return _this9.cpuBackend.minimum(a, b);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      var program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ? new BinaryOpPackedProgram(binaryop_packed_gpu.MIN, a.shape, b.shape) : new BinaryOpProgram(binaryop_gpu.MIN, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b]);\n    }\n  }, {\n    key: \"mod\",\n    value: function mod(a, b) {\n      var program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ? new BinaryOpPackedProgram(binaryop_packed_gpu.MOD, a.shape, b.shape) : new BinaryOpProgram(binaryop_gpu.MOD, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b]);\n    }\n  }, {\n    key: \"maximum\",\n    value: function maximum(a, b) {\n      var _this10 = this;\n\n      var cpuRes = this.tryRunOnCpuOrThrow([a, b], function () {\n        return _this10.cpuBackend.maximum(a, b);\n      });\n\n      if (cpuRes) {\n        return cpuRes;\n      }\n\n      var program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ? new BinaryOpPackedProgram(binaryop_packed_gpu.MAX, a.shape, b.shape) : new BinaryOpProgram(binaryop_gpu.MAX, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b]);\n    }\n  }, {\n    key: \"all\",\n    value: function all(x, axes) {\n      backend_util.assertAxesAreInnerMostDims('all', axes, x.rank);\n\n      var _backend_util$compute9 = backend_util.computeOutAndReduceShapes(x.shape, axes),\n          _backend_util$compute10 = _slicedToArray(_backend_util$compute9, 2),\n          outShape = _backend_util$compute10[0],\n          reduceShape = _backend_util$compute10[1];\n\n      var inSize = util.sizeFromShape(reduceShape);\n      var a2D = x.as2D(-1, inSize);\n      return this.reduce(a2D, 'all', a2D.dtype).reshape(outShape);\n    }\n  }, {\n    key: \"any\",\n    value: function any(x, axes) {\n      backend_util.assertAxesAreInnerMostDims('any', axes, x.rank);\n\n      var _backend_util$compute11 = backend_util.computeOutAndReduceShapes(x.shape, axes),\n          _backend_util$compute12 = _slicedToArray(_backend_util$compute11, 2),\n          outShape = _backend_util$compute12[0],\n          reduceShape = _backend_util$compute12[1];\n\n      var inSize = util.sizeFromShape(reduceShape);\n      var a2D = x.as2D(-1, inSize);\n      return this.reduce(a2D, 'any', a2D.dtype).reshape(outShape);\n    }\n  }, {\n    key: \"floorDiv\",\n    value: function floorDiv(a, b) {\n      var op = binaryop_gpu.INT_DIV;\n      var outputDtype = 'int32';\n\n      if (env().getBool('WEBGL_PACK_BINARY_OPERATIONS')) {\n        return this.packedBinaryOp(a, b, binaryop_packed_gpu.INT_DIV, outputDtype);\n      }\n\n      var program = new BinaryOpProgram(op, a.shape, b.shape);\n      return this.compileAndRun(program, [a, b], outputDtype);\n    }\n  }, {\n    key: \"packedUnaryOp\",\n    value: function packedUnaryOp(x, op, dtype) {\n      var program = new UnaryOpPackedProgram(x.shape, op);\n      return this.compileAndRun(program, [x], dtype);\n    }\n  }, {\n    key: \"packedBinaryOp\",\n    value: function packedBinaryOp(a, b, op, dtype) {\n      var checkOutOfBounds = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n      var program = new BinaryOpPackedProgram(op, a.shape, b.shape, checkOutOfBounds);\n      return this.compileAndRun(program, [a, b], dtype);\n    } // Returns a TensorInfo with the complex shape and the dataId of the\n    // underlying part. We need to do this because a reshaped complex tensor is\n    // not reflected in its parts.\n\n  }, {\n    key: \"makeComplexComponentTensorInfo\",\n    value: function makeComplexComponentTensorInfo(complexTensor, complexPart) {\n      return {\n        dataId: complexPart.dataId,\n        dtype: complexPart.dtype,\n        shape: complexTensor.shape\n      };\n    }\n  }, {\n    key: \"addN\",\n    value: function addN(tensors) {\n      if (tensors.length === 1) {\n        return tensors[0];\n      } // Limit the number of uploaded textures for optimization.\n\n\n      if (tensors.length > env().get('WEBGL_MAX_TEXTURES_IN_SHADER')) {\n        var midIndex = Math.floor(tensors.length / 2);\n        var leftSide = this.addN(tensors.slice(0, midIndex));\n        var rightSide = this.addN(tensors.slice(midIndex));\n        return this.addN([leftSide, rightSide]);\n      }\n\n      var dtype = tensors.map(function (t) {\n        return t.dtype;\n      }).reduce(function (d1, d2) {\n        return upcastType(d1, d2);\n      });\n      var shapes = tensors.map(function (t) {\n        return t.shape;\n      }); // We can make sure shapes are identical in op level.\n\n      var usePackedOp = env().getBool('WEBGL_PACK');\n      var program = usePackedOp ? new AddNPackedProgram(tensors[0].shape, shapes) : new AddNProgram(tensors[0].shape, shapes);\n      return this.compileAndRun(program, tensors, dtype);\n    }\n  }, {\n    key: \"pow\",\n    value: function pow(a, b) {\n      var usePackedOp = env().getBool('WEBGL_PACK_BINARY_OPERATIONS');\n      var program = usePackedOp ? new BinaryOpPackedProgram(binaryop_packed_gpu.POW, a.shape, b.shape) : new BinaryOpProgram(binaryop_gpu.POW, a.shape, b.shape);\n      var dtype = upcastType(a.dtype, b.dtype);\n      return this.compileAndRun(program, [a, b], dtype);\n    }\n  }, {\n    key: \"ceil\",\n    value: function ceil(x) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = ceilImplCPU(this.texData.get(x.dataId).values, x.dtype);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_op.CEIL, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.CEIL);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"floor\",\n    value: function floor(x) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = floorImplCPU(this.texData.get(x.dataId).values, x.dtype);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_op.FLOOR, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.FLOOR);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"sign\",\n    value: function sign(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.SIGN);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"isNaN\",\n    value: function isNaN(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.IS_NAN);\n      return this.compileAndRun(program, [x], 'bool');\n    }\n  }, {\n    key: \"isInf\",\n    value: function isInf(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.IS_INF);\n      return this.compileAndRun(program, [x], 'bool');\n    }\n  }, {\n    key: \"isFinite\",\n    value: function isFinite(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.IS_FINITE);\n      return this.compileAndRun(program, [x], 'bool');\n    }\n  }, {\n    key: \"round\",\n    value: function round(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ROUND);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"exp\",\n    value: function exp(x) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = expImplCPU(this.texData.get(x.dataId).values, x.dtype);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_op.EXP, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.EXP);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"expm1\",\n    value: function expm1(x) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = expm1ImplCPU(this.texData.get(x.dataId).values, x.dtype);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_op.EXPM1, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.EXPM1);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"softmax\",\n    value: function softmax(logits, dim) {\n      var axes = util.parseAxisParam([dim], logits.shape); // TODO(annxingyuan): Call maxImpl rather than op as part of softmax kernel\n      // modularization.\n\n      var maxLogit = max(logits, axes);\n      var expandedShape = backend_util.expandShapeToKeepDim(maxLogit.shape, axes); // TODO(annxingyuan): Call sub directly as part of softmax kernel\n      // modularization.\n\n      var a = tf.sub(logits, maxLogit.reshape(expandedShape));\n      var b = this.exp(a);\n      var sumExp = this.sum(b, axes).reshape(expandedShape); // TODO(annxingyuan): Call divImpl rather than op as part of softmax kernel\n      // modularization.\n\n      return div(b, sumExp);\n    }\n  }, {\n    key: \"log\",\n    value: function log(x) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = logImplCPU(this.texData.get(x.dataId).values, x.dtype);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_packed_op.LOG, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.LOG);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"log1p\",\n    value: function log1p(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.LOG1P);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"sqrt\",\n    value: function sqrt(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.SQRT);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"rsqrt\",\n    value: function rsqrt(x) {\n      if (this.shouldExecuteOnCPU([x])) {\n        var outValues = rsqrtImplCPU(this.texData.get(x.dataId).values, x.dtype);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.RSQRT);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"reciprocal\",\n    value: function reciprocal(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.RECIPROCAL);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"relu\",\n    value: function relu(x) {\n      var program;\n\n      if (env().getBool('WEBGL_PACK')) {\n        program = new UnaryOpPackedProgram(x.shape, unary_packed_op.RELU);\n      } else {\n        program = new UnaryOpProgram(x.shape, unary_op.RELU);\n      }\n\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"relu6\",\n    value: function relu6(x) {\n      var program;\n\n      if (env().getBool('WEBGL_PACK')) {\n        program = new UnaryOpPackedProgram(x.shape, unary_packed_op.RELU6);\n      } else {\n        program = new UnaryOpProgram(x.shape, unary_op.RELU6);\n      }\n\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"prelu\",\n    value: function prelu(x, alpha) {\n      var program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ? new BinaryOpPackedProgram(binaryop_packed_gpu.PRELU, x.shape, alpha.shape) : new BinaryOpProgram(binaryop_gpu.PRELU, x.shape, alpha.shape);\n      return this.compileAndRun(program, [x, alpha]);\n    }\n  }, {\n    key: \"elu\",\n    value: function elu(x) {\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_packed_op.ELU, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.ELU);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"eluDer\",\n    value: function eluDer(dy, y) {\n      var program = env().getBool('WEBGL_PACK_BINARY_OPERATIONS') ? new BinaryOpPackedProgram(binaryop_packed_gpu.ELU_DER, dy.shape, y.shape) : new BinaryOpProgram(binaryop_gpu.ELU_DER, dy.shape, y.shape);\n      return this.compileAndRun(program, [dy, y]);\n    }\n  }, {\n    key: \"selu\",\n    value: function selu(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.SELU);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"clip\",\n    value: function clip(x, min, max) {\n      var program;\n\n      if (env().getBool('WEBGL_PACK_CLIP')) {\n        program = new ClipPackedProgram(x.shape);\n      } else {\n        program = new ClipProgram(x.shape);\n      }\n\n      var customSetup = program.getCustomSetupFunc(min, max);\n      return this.compileAndRun(program, [x], null, customSetup);\n    }\n  }, {\n    key: \"abs\",\n    value: function abs(x) {\n      // TODO: handle cases when x is complex.\n      if (this.shouldExecuteOnCPU([x]) && x.dtype !== 'complex64') {\n        var outValues = simpleAbsImplCPU(this.texData.get(x.dataId).values);\n        return this.makeOutput(x.shape, x.dtype, outValues);\n      }\n\n      if (env().getBool('WEBGL_PACK_UNARY_OPERATIONS')) {\n        return this.packedUnaryOp(x, unary_op.ABS, x.dtype);\n      }\n\n      var program = new UnaryOpProgram(x.shape, unary_op.ABS);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"complexAbs\",\n    value: function complexAbs(x) {\n      var xData = this.texData.get(x.dataId);\n      var program = new ComplexAbsProgram(x.shape);\n      var inputs = [this.makeComplexComponentTensorInfo(x, xData.complexTensorInfos.real), this.makeComplexComponentTensorInfo(x, xData.complexTensorInfos.imag)];\n      return this.compileAndRun(program, inputs);\n    }\n  }, {\n    key: \"sigmoid\",\n    value: function sigmoid(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.SIGMOID);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"softplus\",\n    value: function softplus(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.SOFTPLUS);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"asin\",\n    value: function asin(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ASIN);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"acos\",\n    value: function acos(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ACOS);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"atan\",\n    value: function atan(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ATAN);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"sinh\",\n    value: function sinh(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.SINH);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"cosh\",\n    value: function cosh(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.COSH);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"tanh\",\n    value: function tanh(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.TANH);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"asinh\",\n    value: function asinh(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ASINH);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"acosh\",\n    value: function acosh(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ACOSH);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"atanh\",\n    value: function atanh(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ATANH);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"erf\",\n    value: function erf(x) {\n      var program = new UnaryOpProgram(x.shape, unary_op.ERF);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"step\",\n    value: function step(x, alpha) {\n      var program = new UnaryOpProgram(x.shape, unary_op.STEP(alpha));\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"conv2dByMatMul\",\n    value: function conv2dByMatMul(x, filter, convInfo, bias, activation, preluActivationWeights) {\n      // Reshapes conv2D input to 2D tensors, uses matMul and then reshape the\n      // result from 2D to 4D.\n      var xShape = x.shape;\n      var xTexData = this.texData.get(x.dataId);\n      var sharedMatMulDim = convInfo.inChannels;\n      var outerShapeX = xShape[0] * xShape[1] * xShape[2];\n      var outerShapeFilter = convInfo.outChannels;\n      var isChannelsLast = convInfo.dataFormat === 'channelsLast';\n      var transposeA = false;\n      var transposeB = false; // TODO: Once reduction ops are packed, batchMatMul will always be packed\n      // and we can remove this condition.\n\n      var batchMatMulWillBeUnpacked = (outerShapeX === 1 || outerShapeFilter === 1) && sharedMatMulDim > MATMUL_SHARED_DIM_THRESHOLD;\n      var reshapeWillBeExpensive = xShape[2] % 2 !== 0 && !!xTexData.isPacked;\n\n      if (batchMatMulWillBeUnpacked || !env().getBool('WEBGL_LAZILY_UNPACK') || !env().getBool('WEBGL_PACK_BINARY_OPERATIONS') || !reshapeWillBeExpensive) {\n        var _targetShape = isChannelsLast ? xShape[0] * xShape[1] * xShape[2] : xShape[0] * xShape[2] * xShape[3];\n\n        var _xReshaped = reshape(x, [1, _targetShape, convInfo.inChannels]);\n\n        var _filterReshaped = reshape(filter, [1, convInfo.inChannels, convInfo.outChannels]);\n\n        var result = this.fusedBatchMatMul({\n          a: _xReshaped,\n          b: _filterReshaped,\n          transposeA: transposeA,\n          transposeB: transposeB,\n          bias: bias,\n          activation: activation,\n          preluActivationWeights: preluActivationWeights\n        });\n        return reshape(result, convInfo.outShape);\n      } // Following optimization is specific to packed |x| with odd row count\n      // (For example, in channelLast mode, 'row count' refers to x.shape[2]):\n      // we avoid expensive packed 2x2 reshape by padding row count to next,\n      // even number. When x.shape[2] is odd, the result of packed batchMatMul is\n      // the same (has the same texture layout and and values in the texture) as\n      // it is for even x.shape[2] + 1. We make the odd-rows tensor to look like\n      // even-rows tensor before the operation and, after the batchMatMul,\n      // fix the even-rows result to have odd number of rows.\n\n\n      var targetShape = isChannelsLast ? xShape[0] * xShape[1] * (xShape[2] + 1) : xShape[0] * xShape[2] * (xShape[3] + 1);\n      var xReshaped = {\n        dataId: x.dataId,\n        shape: [1, targetShape, convInfo.inChannels],\n        dtype: x.dtype\n      }; // xTexData.shape gets referenced from GPGPUBinary.inShapeInfos.\n      // Decrementing row count, after batchMatMul->...->compileProgram leads to\n      // invalid row count within the reference in GPGPUBinary.inShapeInfos.\n      // Alternative fix would be to provide a copy to GPGPUBinary.inShapeInfos\n      // in compileProgram method, but that would affect compilation of all\n      // programs - instead, provide a copy here, with even row count, before\n      // calling batchMatMul->...->compileProgram and after that, the original\n      // xTexData.shape is restored.\n\n      var originalXTexDataShape = xTexData.shape;\n      xTexData.shape = xTexData.shape.slice();\n      xTexData.shape[xTexData.shape.length - 2]++;\n      util.assert(webgl_util.isReshapeFree(xTexData.shape, xReshaped.shape), function () {\n        return \"packed reshape \".concat(xTexData.shape, \" to \").concat(xReshaped.shape, \" isn't free\");\n      });\n      var filterReshaped = reshape(filter, [1, convInfo.inChannels, convInfo.outChannels]);\n      var pointwiseConv = this.fusedBatchMatMul({\n        a: xReshaped,\n        b: filterReshaped,\n        transposeA: transposeA,\n        transposeB: transposeB,\n        bias: bias,\n        activation: activation,\n        preluActivationWeights: preluActivationWeights\n      });\n      var pointwiseConvTexData = this.texData.get(pointwiseConv.dataId);\n      util.assert(pointwiseConvTexData.isPacked, function () {\n        return 'batchMatMul result is expected to be packed';\n      }); // Restore the input shape to original.\n\n      xTexData.shape = originalXTexDataShape; // Set the output shape - there is no need for expensive reshape as data\n      // layout is already correct.\n\n      pointwiseConvTexData.shape = convInfo.outShape;\n      return engine().makeTensorFromDataId(pointwiseConv.dataId, convInfo.outShape, pointwiseConv.dtype);\n    }\n  }, {\n    key: \"conv2dWithIm2Row\",\n    value: function conv2dWithIm2Row(x, filter, convInfo, bias, activation, preluActivationWeights) {\n      // Rearranges conv2d input so each block to be convolved over forms the\n      // column of a new matrix with shape [filterWidth * filterHeight *\n      // inChannels, outHeight * outWidth]. The filter is also rearranged so each\n      // output channel forms a row of a new matrix with shape [outChannels,\n      // filterWidth * filterHeight * inChannels]. The convolution is then\n      // computed by multiplying these matrices and reshaping the result.\n      var filterWidth = convInfo.filterWidth,\n          filterHeight = convInfo.filterHeight,\n          inChannels = convInfo.inChannels,\n          outWidth = convInfo.outWidth,\n          outHeight = convInfo.outHeight,\n          dataFormat = convInfo.dataFormat;\n      var isChannelsLast = dataFormat === 'channelsLast';\n      var sharedDim = filterWidth * filterHeight * inChannels;\n      var numCols = outHeight * outWidth;\n      var x2ColShape = [sharedDim, numCols];\n      var transposeA = true;\n      var transposeB = false;\n      var xSqueezed = x.squeeze([0]);\n      var w2Row = filter.reshape([1, sharedDim, -1]);\n      var im2ColProgram = new Im2ColPackedProgram(x2ColShape, xSqueezed.shape, convInfo);\n      var im2Col = this.compileAndRun(im2ColProgram, [xSqueezed]).reshape([1, x2ColShape[0], x2ColShape[1]]);\n      var hasBias = bias != null;\n      var hasPreluActivationWeights = preluActivationWeights != null;\n      var fusedActivation = activation ? mapActivationToShaderProgram(activation, true) : null;\n      var matmulProgram = new MatMulPackedProgram(im2Col.shape, w2Row.shape, [1, numCols, convInfo.outChannels], transposeA, transposeB, hasBias, fusedActivation, hasPreluActivationWeights);\n      var inputs = [im2Col, w2Row];\n\n      if (bias) {\n        inputs.push(bias);\n      }\n\n      if (hasPreluActivationWeights) {\n        inputs.push(preluActivationWeights);\n      }\n\n      var product = this.compileAndRun(matmulProgram, inputs);\n\n      if (isChannelsLast) {\n        return product.reshape([1, outHeight, outWidth, convInfo.outChannels]);\n      } else {\n        return product.reshape([1, convInfo.outChannels, outHeight, outWidth]);\n      }\n    }\n  }, {\n    key: \"fusedConv2d\",\n    value: function fusedConv2d(_ref2) {\n      var input = _ref2.input,\n          filter = _ref2.filter,\n          convInfo = _ref2.convInfo,\n          bias = _ref2.bias,\n          activation = _ref2.activation,\n          preluActivationWeights = _ref2.preluActivationWeights;\n\n      if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n        return this.conv2dByMatMul(input, filter, convInfo, bias, activation, preluActivationWeights);\n      }\n\n      if (env().getBool('WEBGL_CONV_IM2COL') && input.shape[0] === 1) {\n        return this.conv2dWithIm2Row(input, filter, convInfo, bias, activation, preluActivationWeights);\n      }\n\n      var hasBias = bias != null;\n      var hasPreluActivationWeights = preluActivationWeights != null;\n      var fusedActivation = activation ? mapActivationToShaderProgram(activation, false) : null;\n      var program = new Conv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights);\n      var inputs = [input, filter];\n\n      if (bias) {\n        inputs.push(bias);\n      }\n\n      if (preluActivationWeights) {\n        inputs.push(preluActivationWeights);\n      }\n\n      return this.compileAndRun(program, inputs);\n    }\n  }, {\n    key: \"conv2d\",\n    value: function conv2d(x, filter, convInfo) {\n      if (convInfo.filterHeight === 1 && convInfo.filterWidth === 1 && convInfo.dilationHeight === 1 && convInfo.dilationWidth === 1 && convInfo.strideHeight === 1 && convInfo.strideWidth === 1 && (convInfo.padInfo.type === 'SAME' || convInfo.padInfo.type === 'VALID')) {\n        return this.conv2dByMatMul(x, filter, convInfo);\n      }\n\n      if (env().getBool('WEBGL_CONV_IM2COL') && x.shape[0] === 1) {\n        return this.conv2dWithIm2Row(x, filter, convInfo);\n      }\n\n      var program = new Conv2DProgram(convInfo);\n      return this.compileAndRun(program, [x, filter]);\n    }\n  }, {\n    key: \"conv2dDerInput\",\n    value: function conv2dDerInput(dy, filter, convInfo) {\n      var program = new Conv2DDerInputProgram(convInfo);\n      return this.compileAndRun(program, [dy, filter]);\n    }\n  }, {\n    key: \"conv2dDerFilter\",\n    value: function conv2dDerFilter(x, dy, convInfo) {\n      var program = new Conv2DDerFilterProgram(convInfo);\n      return this.compileAndRun(program, [x, dy]);\n    }\n  }, {\n    key: \"fusedDepthwiseConv2D\",\n    value: function fusedDepthwiseConv2D(_ref3) {\n      var input = _ref3.input,\n          filter = _ref3.filter,\n          convInfo = _ref3.convInfo,\n          bias = _ref3.bias,\n          activation = _ref3.activation,\n          preluActivationWeights = _ref3.preluActivationWeights;\n      var shouldPackDepthwiseConv = env().getBool('WEBGL_PACK_DEPTHWISECONV') && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1;\n      var fusedActivation = activation ? mapActivationToShaderProgram(activation, shouldPackDepthwiseConv) : null;\n      var inputs = [input, filter];\n      var hasBias = bias != null;\n      var hasPreluActivationWeights = preluActivationWeights != null;\n\n      if (hasBias) {\n        inputs.push(bias);\n      }\n\n      if (hasPreluActivationWeights) {\n        inputs.push(preluActivationWeights);\n      }\n\n      var program;\n\n      if (shouldPackDepthwiseConv) {\n        program = new DepthwiseConvPacked2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights);\n        return this.compileAndRun(program, inputs);\n      }\n\n      program = new DepthwiseConv2DProgram(convInfo, hasBias, fusedActivation, hasPreluActivationWeights);\n      return this.compileAndRun(program, inputs);\n    }\n  }, {\n    key: \"depthwiseConv2D\",\n    value: function depthwiseConv2D(x, filter, convInfo) {\n      var program;\n\n      if (env().getBool('WEBGL_PACK_DEPTHWISECONV') && convInfo.strideWidth <= 2 && convInfo.outChannels / convInfo.inChannels === 1) {\n        program = new DepthwiseConvPacked2DProgram(convInfo);\n        return this.compileAndRun(program, [x, filter]);\n      }\n\n      program = new DepthwiseConv2DProgram(convInfo);\n      return this.compileAndRun(program, [x, filter]);\n    }\n  }, {\n    key: \"depthwiseConv2DDerInput\",\n    value: function depthwiseConv2DDerInput(dy, filter, convInfo) {\n      var program = new DepthwiseConv2DDerInputProgram(convInfo);\n      return this.compileAndRun(program, [dy, filter]);\n    }\n  }, {\n    key: \"depthwiseConv2DDerFilter\",\n    value: function depthwiseConv2DDerFilter(x, dy, convInfo) {\n      var program = new DepthwiseConv2DDerFilterProgram(convInfo);\n      return this.compileAndRun(program, [x, dy]);\n    }\n  }, {\n    key: \"conv3d\",\n    value: function conv3d(x, filter, convInfo) {\n      var program = new Conv3DProgram(convInfo);\n      return this.compileAndRun(program, [x, filter]);\n    }\n  }, {\n    key: \"conv3dDerInput\",\n    value: function conv3dDerInput(dy, filter, convInfo) {\n      var program = new Conv3DDerInputProgram(convInfo);\n      return this.compileAndRun(program, [dy, filter]);\n    }\n  }, {\n    key: \"conv3dDerFilter\",\n    value: function conv3dDerFilter(x, dy, convInfo) {\n      var program = new Conv3DDerFilterProgram(convInfo);\n      return this.compileAndRun(program, [x, dy]);\n    }\n  }, {\n    key: \"unstack\",\n    value: function unstack(x, axis) {\n      var num = x.shape[axis];\n      var outShape = new Array(x.rank - 1);\n      var outIndex = 0;\n\n      for (var i = 0; i < x.rank; i++) {\n        if (i !== axis) {\n          outShape[outIndex++] = x.shape[i];\n        }\n      }\n\n      var begin = new Array(x.rank).fill(0);\n      var size = x.shape.slice();\n      size[axis] = 1;\n      var res = new Array(num);\n\n      for (var _i = 0; _i < res.length; _i++) {\n        begin[axis] = _i;\n        res[_i] = this.slice(x, begin, size).reshape(outShape);\n      }\n\n      return res;\n    }\n  }, {\n    key: \"avgPool3d\",\n    value: function avgPool3d(x, convInfo) {\n      var program = new Pool3DProgram(convInfo, 'avg', false);\n      return this.compileAndRun(program, [x], 'float32');\n    }\n  }, {\n    key: \"avgPool3dBackprop\",\n    value: function avgPool3dBackprop(dy, x, convInfo) {\n      var avgPool3dBackpropProgram = new AvgPool3DBackpropProgram(convInfo);\n      return this.compileAndRun(avgPool3dBackpropProgram, [dy], x.dtype);\n    }\n  }, {\n    key: \"maxPool3d\",\n    value: function maxPool3d(x, convInfo) {\n      var program = new Pool3DProgram(convInfo, 'max', false);\n      return this.compileAndRun(program, [x], 'float32');\n    }\n  }, {\n    key: \"maxPool3dBackprop\",\n    value: function maxPool3dBackprop(dy, x, y, convInfo) {\n      var getPositions = true;\n      var maxPool3dPositionsProgram = new Pool3DProgram(convInfo, 'max', getPositions);\n      var maxPool3dPositions = this.compileAndRun(maxPool3dPositionsProgram, [x]);\n      var maxPool3dBackPropProgram = new MaxPool3DBackpropProgram(convInfo);\n      var result = this.compileAndRun(maxPool3dBackPropProgram, [dy, maxPool3dPositions], x.dtype);\n      maxPool3dPositions.dispose();\n      return result;\n    }\n  }, {\n    key: \"resizeBilinear\",\n    value: function resizeBilinear(x, newHeight, newWidth, alignCorners) {\n      var program = env().getBool('WEBGL_PACK_IMAGE_OPERATIONS') ? new ResizeBilinearPackedProgram(x.shape, newHeight, newWidth, alignCorners) : new ResizeBilinearProgram(x.shape, newHeight, newWidth, alignCorners);\n      return this.compileAndRun(program, [x], 'float32');\n    }\n  }, {\n    key: \"resizeBilinearBackprop\",\n    value: function resizeBilinearBackprop(dy, x, alignCorners) {\n      var program = new ResizeBilinearBackpropProgram(dy, x, alignCorners);\n      return this.compileAndRun(program, [dy]);\n    }\n  }, {\n    key: \"resizeNearestNeighbor\",\n    value: function resizeNearestNeighbor(x, newHeight, newWidth, alignCorners) {\n      var program = new ResizeNearestNeighborProgram(x.shape, newHeight, newWidth, alignCorners);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"resizeNearestNeighborBackprop\",\n    value: function resizeNearestNeighborBackprop(dy, x, alignCorners) {\n      var program = new ResizeNearestNeigborBackpropProgram(dy, x, alignCorners);\n      return this.compileAndRun(program, [dy]);\n    }\n  }, {\n    key: \"multinomial\",\n    value: function multinomial(logits, normalized, numSamples, seed) {\n      var probs = normalized ? logits : softmax(logits);\n      var batchSize = probs.shape[0];\n      var numOutcomes = probs.shape[1];\n      var program = new MultinomialProgram(batchSize, numOutcomes, numSamples);\n      var customSetup = program.getCustomSetupFunc(seed);\n      return this.compileAndRun(program, [probs], 'int32', customSetup);\n    }\n  }, {\n    key: \"oneHot\",\n    value: function oneHot(indices, depth, onValue, offValue) {\n      var program = new OneHotProgram(indices.size, depth, onValue, offValue);\n      return this.compileAndRun(program, [indices]);\n    }\n  }, {\n    key: \"diag\",\n    value: function diag(x) {\n      var program = new DiagProgram(x.size);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"cropAndResize\",\n    value: function cropAndResize(image, boxes, boxIndex, cropSize, method, extrapolationValue) {\n      var program = new CropAndResizeProgram(image.shape, boxes.shape, cropSize, method, extrapolationValue);\n      return this.compileAndRun(program, [image, boxes, boxIndex], 'float32');\n    }\n  }, {\n    key: \"depthToSpace\",\n    value: function depthToSpace(x, blockSize, dataFormat) {\n      util.assert(blockSize > 1, function () {\n        return \"blockSize should be > 1 for depthToSpace, but was: \".concat(blockSize);\n      });\n      var batchSize = x.shape[0];\n      var inputHeight = dataFormat === 'NHWC' ? x.shape[1] : x.shape[2];\n      var inputWidth = dataFormat === 'NHWC' ? x.shape[2] : x.shape[3];\n      var inputDepth = dataFormat === 'NHWC' ? x.shape[3] : x.shape[1];\n      var outputHeight = inputHeight * blockSize;\n      var outputWidth = inputWidth * blockSize;\n      var outputDepth = inputDepth / (blockSize * blockSize);\n      var outputShape = dataFormat === 'NHWC' ? [batchSize, outputHeight, outputWidth, outputDepth] : [batchSize, outputDepth, outputHeight, outputWidth];\n      var program = new DepthToSpaceProgram(outputShape, blockSize, dataFormat);\n      return this.compileAndRun(program, [x]);\n    }\n  }, {\n    key: \"split\",\n    value: function split(x, sizeSplits, axis) {\n      return _split(x, sizeSplits, axis);\n    }\n  }, {\n    key: \"scatterND\",\n    value: function scatterND(indices, updates, shape) {\n      var _backend_util$calcula = backend_util.calculateShapes(updates, indices, shape),\n          sliceRank = _backend_util$calcula.sliceRank,\n          numUpdates = _backend_util$calcula.numUpdates,\n          sliceSize = _backend_util$calcula.sliceSize,\n          strides = _backend_util$calcula.strides,\n          outputSize = _backend_util$calcula.outputSize;\n\n      var flattenShape = [outputSize / sliceSize, sliceSize];\n      var flattenIndices = indices.reshape([numUpdates, sliceRank]);\n      var flattenX = updates.reshape([numUpdates, sliceSize]);\n\n      if (outputSize === 0) {\n        return backend_util.reshapeTensor(tensor([]), shape);\n      }\n\n      var defaultValue = scalar(0);\n      var program = new ScatterProgram(numUpdates, sliceRank, flattenIndices.rank, flattenX.rank, strides, flattenShape);\n      var res = this.compileAndRun(program, [flattenX, flattenIndices, defaultValue]);\n      return res.reshape(shape);\n    }\n  }, {\n    key: \"sparseToDense\",\n    value: function sparseToDense(sparseIndices, sparseValues, outputShape, defaultValue) {\n      var _backend_util$calcula2 = backend_util.calculateShapes(sparseValues, sparseIndices, outputShape),\n          sliceRank = _backend_util$calcula2.sliceRank,\n          numUpdates = _backend_util$calcula2.numUpdates,\n          strides = _backend_util$calcula2.strides,\n          outputSize = _backend_util$calcula2.outputSize;\n\n      var sumDupeIndices = false;\n      var program = new ScatterProgram(numUpdates, sliceRank, sparseIndices.rank, sparseValues.rank, strides, [outputSize, 1], sumDupeIndices);\n      var res = this.compileAndRun(program, [sparseValues, sparseIndices, defaultValue]);\n      return res.reshape(outputShape);\n    }\n  }, {\n    key: \"gatherND\",\n    value: function gatherND(x, indices) {\n      var indicesShape = indices.shape;\n      var sliceRank = indicesShape[indicesShape.length - 1];\n\n      var _backend_util$prepare = backend_util.prepareAndValidate(x, indices),\n          _backend_util$prepare2 = _slicedToArray(_backend_util$prepare, 4),\n          resultShape = _backend_util$prepare2[0],\n          numSlices = _backend_util$prepare2[1],\n          sliceSize = _backend_util$prepare2[2],\n          strides = _backend_util$prepare2[3];\n\n      var flattenIndices = indices.reshape([numSlices, sliceRank]);\n      var flattenX = x.reshape([x.size / sliceSize, sliceSize]);\n      var program = new GatherNDProgram(sliceRank, strides, [numSlices, sliceSize]);\n      var res = this.compileAndRun(program, [flattenX, flattenIndices]);\n      return res.reshape(resultShape);\n    }\n  }, {\n    key: \"fill\",\n    value: function fill(shape, value, dtype) {\n      dtype = dtype || util.inferDtype(value);\n\n      if (dtype === 'string') {\n        // String type should be handled in CPU memory.\n        var values = util.getArrayFromDType(dtype, util.sizeFromShape(shape));\n        values.fill(value);\n        return engine().makeTensor(values, shape, dtype, this);\n      } else {\n        var program = new FillProgram(shape, value);\n        var customSetup = program.getCustomSetupFunc(value);\n        return this.compileAndRun(program, [], dtype, customSetup);\n      }\n    }\n  }, {\n    key: \"onesLike\",\n    value: function onesLike(x) {\n      if (x.dtype === 'string') {\n        throw new Error('onesLike is not supported under string dtype');\n      } else {\n        // TODO(cais, smilkov): Add WebGL shader for onesLike:\n        //   https://github.com/tensorflow/tfjs/issues/1293\n        return this.fill(x.shape, 1, x.dtype);\n      }\n    }\n  }, {\n    key: \"zerosLike\",\n    value: function zerosLike(x) {\n      return this.fill(x.shape, x.dtype === 'string' ? '' : 0, x.dtype);\n    }\n  }, {\n    key: \"linspace\",\n    value: function linspace(start, stop, num) {\n      // TODO: Use CPU implementation due to the precision problem in Safari.\n      return backend_util.linspaceImpl(start, stop, num);\n    }\n  }, {\n    key: \"makeTensorInfo\",\n    value: function makeTensorInfo(shape, dtype, values) {\n      var dataId = this.write(values, shape, dtype);\n      this.texData.get(dataId).usage = null;\n      return {\n        dataId: dataId,\n        shape: shape,\n        dtype: dtype\n      };\n    }\n  }, {\n    key: \"makeOutput\",\n    value: function makeOutput(shape, dtype, values) {\n      var _this$makeTensorInfo = this.makeTensorInfo(shape, dtype, values),\n          dataId = _this$makeTensorInfo.dataId;\n\n      return engine().makeTensorFromDataId(dataId, shape, dtype, this);\n    }\n  }, {\n    key: \"unpackTensor\",\n    value: function unpackTensor(input) {\n      var program = new UnpackProgram(input.shape);\n      return this.runWebGLProgram(program, [input], input.dtype);\n    }\n  }, {\n    key: \"packTensor\",\n    value: function packTensor(input) {\n      var program = new PackProgram(input.shape);\n      var preventEagerUnpackingOutput = true;\n      return this.runWebGLProgram(program, [input], input.dtype, null\n      /* customSetup */\n      , preventEagerUnpackingOutput);\n    }\n  }, {\n    key: \"packedReshape\",\n    value: function packedReshape(input, afterShape) {\n      var input3DShape = [webgl_util.getBatchDim(input.shape)].concat(_toConsumableArray(webgl_util.getRowsCols(input.shape)));\n      var input3D = {\n        dtype: input.dtype,\n        shape: input3DShape,\n        dataId: input.dataId\n      };\n      var afterShapeAs3D = [webgl_util.getBatchDim(afterShape)].concat(_toConsumableArray(webgl_util.getRowsCols(afterShape)));\n      var program = new ReshapePackedProgram(afterShapeAs3D, input3DShape);\n      var preventEagerUnpackingOfOutput = true;\n      var output = this.runWebGLProgram(program, [input3D], input.dtype, null\n      /* customSetup */\n      , preventEagerUnpackingOfOutput);\n      return {\n        dataId: output.dataId,\n        shape: afterShape,\n        dtype: output.dtype\n      };\n    }\n  }, {\n    key: \"decode\",\n    value: function decode(dataId) {\n      var texData = this.texData.get(dataId);\n      var isPacked = texData.isPacked,\n          shape = texData.shape,\n          dtype = texData.dtype;\n      var shapeAs3D = webgl_util.getShapeAs3D(shape);\n      var program;\n\n      if (isPacked) {\n        program = new DecodeMatrixPackedProgram(shapeAs3D);\n      } else {\n        program = new DecodeMatrixProgram(shapeAs3D);\n      }\n\n      var preventEagerUnpackingOfOutput = true;\n      var out = this.runWebGLProgram(program, [{\n        shape: shapeAs3D,\n        dtype: dtype,\n        dataId: dataId\n      }], dtype, null\n      /* customSetup */\n      , preventEagerUnpackingOfOutput);\n      return {\n        dtype: dtype,\n        shape: shape,\n        dataId: out.dataId\n      };\n    }\n  }, {\n    key: \"runWebGLProgram\",\n    value: function runWebGLProgram(program, inputs, outputDtype, customSetup) {\n      var _this11 = this;\n\n      var preventEagerUnpackingOfOutput = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n      var output = this.makeTensorInfo(program.outputShape, outputDtype);\n      var outData = this.texData.get(output.dataId);\n\n      if (program.packedOutput) {\n        outData.isPacked = true;\n      }\n\n      if (program.outPackingScheme === tex_util.PackingScheme.DENSE) {\n        var texelShape = tex_util.getDenseTexShape(program.outputShape); // For a densely packed output, we explicitly set texShape\n        // so it doesn't get assigned later according to our typical packing\n        // scheme wherein a single texel can only contain values from adjacent\n        // rows/cols.\n\n        outData.texShape = texelShape.map(function (d) {\n          return d * 2;\n        });\n      }\n\n      if (program.outTexUsage != null) {\n        outData.usage = program.outTexUsage;\n      }\n\n      if (util.sizeFromShape(output.shape) === 0) {\n        // Short-circuit the computation since the result is empty (has 0 in its\n        // shape).\n        outData.values = util.getTypedArrayFromDType(output.dtype, 0);\n        return output;\n      }\n\n      var dataToDispose = [];\n      var inputsData = inputs.map(function (input) {\n        if (input.dtype === 'complex64') {\n          throw new Error(\"GPGPUProgram does not support complex64 input. For complex64 \" + \"dtypes, please separate the program into real and imaginary \" + \"parts.\");\n        }\n\n        var texData = _this11.texData.get(input.dataId);\n\n        if (texData.texture == null) {\n          if (!program.packedInputs && util.sizeFromShape(input.shape) <= env().getNumber('WEBGL_SIZE_UPLOAD_UNIFORM')) {\n            // Upload small tensors that live on the CPU as uniforms, not as\n            // textures. Do this only when the environment supports 32bit floats\n            // due to problems when comparing 16bit floats with 32bit floats.\n            // TODO(https://github.com/tensorflow/tfjs/issues/821): Make it\n            // possible for packed shaders to sample from uniforms.\n            return {\n              shape: input.shape,\n              texData: null,\n              isUniform: true,\n              uniformValues: texData.values\n            };\n          } // This ensures that if a packed program's inputs have not yet been\n          // uploaded to the GPU, they get uploaded as packed right off the bat.\n\n\n          if (program.packedInputs) {\n            texData.isPacked = true;\n            texData.shape = input.shape;\n          }\n        } else if (!!texData.isPacked !== !!program.packedInputs) {\n          input = texData.isPacked ? _this11.unpackTensor(input) : _this11.packTensor(input);\n          dataToDispose.push(input);\n          texData = _this11.texData.get(input.dataId);\n        } else if (texData.isPacked && !webgl_util.isReshapeFree(texData.shape, input.shape)) {\n          // This is a special case where a texture exists for a tensor\n          // but the shapes are incompatible (due to packing constraints) because\n          // the tensor did not have a chance to go through the packed reshape\n          // shader. This only happens when we reshape the *same* tensor to form\n          // *distinct* inputs to an op, e.g. dotting a vector with itself. This\n          // case will disappear once packed uploading is the default.\n          var savedInput = input;\n          var targetShape = input.shape;\n          input.shape = texData.shape;\n          input = _this11.packedReshape(input, targetShape);\n          dataToDispose.push(input);\n          texData = _this11.texData.get(input.dataId);\n          savedInput.shape = targetShape;\n        }\n\n        _this11.uploadToGPU(input.dataId);\n\n        return {\n          shape: input.shape,\n          texData: texData,\n          isUniform: false\n        };\n      });\n      this.uploadToGPU(output.dataId);\n      var outputData = {\n        shape: output.shape,\n        texData: outData,\n        isUniform: false\n      };\n      var key = gpgpu_math.makeShaderKey(program, inputsData, outputData);\n      var binary = this.getAndSaveBinary(key, function () {\n        return gpgpu_math.compileProgram(_this11.gpgpu, program, inputsData, outputData);\n      });\n      var shouldTimeProgram = this.activeTimers != null;\n      var query;\n\n      if (shouldTimeProgram) {\n        query = this.startTimer();\n      }\n\n      gpgpu_math.runProgram(this.gpgpu, binary, inputsData, outputData, customSetup);\n      dataToDispose.forEach(function (info) {\n        return _this11.disposeIntermediateTensorInfo(info);\n      });\n\n      if (shouldTimeProgram) {\n        query = this.endTimer(query);\n        this.activeTimers.push({\n          name: program.constructor.name,\n          query: this.getQueryTime(query)\n        });\n      }\n\n      if (!env().getBool('WEBGL_LAZILY_UNPACK') && outData.isPacked && preventEagerUnpackingOfOutput === false) {\n        var unpacked = this.unpackTensor(output);\n        this.disposeIntermediateTensorInfo(output);\n        return unpacked;\n      }\n\n      return output;\n    }\n  }, {\n    key: \"compileAndRun\",\n    value: function compileAndRun(program, inputs, outputDtype, customSetup) {\n      var preventEagerUnpackingOfOutput = arguments.length > 4 && arguments[4] !== undefined ? arguments[4] : false;\n      outputDtype = outputDtype || inputs[0].dtype;\n      var outInfo = this.runWebGLProgram(program, inputs, outputDtype, customSetup, preventEagerUnpackingOfOutput);\n      return engine().makeTensorFromDataId(outInfo.dataId, outInfo.shape, outInfo.dtype);\n    }\n  }, {\n    key: \"getAndSaveBinary\",\n    value: function getAndSaveBinary(key, getBinary) {\n      if (!(key in this.binaryCache)) {\n        this.binaryCache[key] = getBinary();\n      }\n\n      return this.binaryCache[key];\n    }\n  }, {\n    key: \"getTextureManager\",\n    value: function getTextureManager() {\n      return this.textureManager;\n    }\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var _this12 = this;\n\n      if (this.disposed) {\n        return;\n      } // Avoid disposing the compiled webgl programs during unit testing because\n      // it slows down test execution.\n\n\n      if (!env().getBool('IS_TEST')) {\n        var allKeys = Object.keys(this.binaryCache);\n        allKeys.forEach(function (key) {\n          _this12.gpgpu.deleteProgram(_this12.binaryCache[key].webGLProgram);\n\n          delete _this12.binaryCache[key];\n        });\n      }\n\n      this.textureManager.dispose();\n\n      if (this.canvas != null && typeof HTMLCanvasElement !== 'undefined' && this.canvas instanceof HTMLCanvasElement) {\n        this.canvas.remove();\n      } else {\n        this.canvas = null;\n      }\n\n      if (this.gpgpuCreatedLocally) {\n        this.gpgpu.program = null;\n        this.gpgpu.dispose();\n      }\n\n      this.disposed = true;\n    }\n  }, {\n    key: \"floatPrecision\",\n    value: function floatPrecision() {\n      var _this13 = this;\n\n      if (this.floatPrecisionValue == null) {\n        this.floatPrecisionValue = tidy(function () {\n          if (!env().get('WEBGL_RENDER_FLOAT32_ENABLED')) {\n            // Momentarily switching DEBUG flag to false so we don't throw an\n            // error trying to upload a small value.\n            var debugFlag = env().getBool('DEBUG');\n            env().set('DEBUG', false);\n\n            var underflowCheckValue = _this13.abs(scalar(1e-8)).dataSync()[0];\n\n            env().set('DEBUG', debugFlag);\n\n            if (underflowCheckValue > 0) {\n              return 32;\n            }\n          }\n\n          return 16;\n        });\n      }\n\n      return this.floatPrecisionValue;\n    }\n    /** Returns the smallest representable number.  */\n\n  }, {\n    key: \"epsilon\",\n    value: function epsilon() {\n      return this.floatPrecision() === 32 ? EPSILON_FLOAT32 : EPSILON_FLOAT16;\n    }\n  }, {\n    key: \"uploadToGPU\",\n    value: function uploadToGPU(dataId) {\n      var texData = this.texData.get(dataId);\n      var shape = texData.shape,\n          dtype = texData.dtype,\n          values = texData.values,\n          texture = texData.texture,\n          usage = texData.usage,\n          isPacked = texData.isPacked;\n\n      if (texture != null) {\n        // Array is already on GPU. No-op.\n        return;\n      }\n\n      var shouldTimeProgram = this.activeTimers != null;\n      var start;\n\n      if (shouldTimeProgram) {\n        start = util.now();\n      }\n\n      var texShape = texData.texShape;\n\n      if (texShape == null) {\n        texShape = webgl_util.getTextureShapeFromLogicalShape(shape, isPacked);\n        texData.texShape = texShape;\n      }\n\n      if (values != null) {\n        var shapeAs3D = webgl_util.getShapeAs3D(shape);\n        var program;\n        var width = texShape[1],\n            height = texShape[0];\n        var isByteArray = values instanceof Uint8Array;\n\n        if (isPacked) {\n          var _tex_util$getPackedMa = tex_util.getPackedMatrixTextureShapeWidthHeight(texShape[0], texShape[1]);\n\n          var _tex_util$getPackedMa2 = _slicedToArray(_tex_util$getPackedMa, 2);\n\n          width = _tex_util$getPackedMa2[0];\n          height = _tex_util$getPackedMa2[1];\n          program = new EncodeMatrixPackedProgram(shapeAs3D, [height, width], isByteArray);\n        } else {\n          program = new EncodeMatrixProgram(shapeAs3D, [height, width], isByteArray);\n        }\n\n        var tempDenseInputHandle = this.makeTensorInfo([height, width], dtype);\n\n        if (isByteArray) {\n          this.texData.get(tempDenseInputHandle.dataId).usage = TextureUsage.PIXELS;\n        } else {\n          this.texData.get(tempDenseInputHandle.dataId).usage = TextureUsage.UPLOAD;\n        }\n\n        this.gpgpu.uploadDenseMatrixToTexture(this.getTexture(tempDenseInputHandle.dataId), width, height, values); // We want the output to remain packed regardless of the value of\n        // WEBGL_PACK.\n\n        var preventEagerUnpacking = true;\n        var encodedOutputTarget = this.runWebGLProgram(program, [tempDenseInputHandle], dtype, null, preventEagerUnpacking); // Have the original texture assume the identity of the encoded output.\n\n        var outputTexData = this.texData.get(encodedOutputTarget.dataId);\n        texData.texture = outputTexData.texture;\n        texData.texShape = outputTexData.texShape;\n        texData.isPacked = outputTexData.isPacked;\n        texData.usage = outputTexData.usage;\n        this.disposeIntermediateTensorInfo(tempDenseInputHandle);\n        this.texData.delete(encodedOutputTarget.dataId); // Once uploaded, don't store the values on cpu.\n\n        texData.values = null;\n\n        if (shouldTimeProgram) {\n          this.uploadWaitMs += util.now() - start;\n        }\n      } else {\n        var newTexture = this.acquireTexture(texShape, usage, dtype, isPacked);\n        texData.texture = newTexture;\n      }\n    }\n  }, {\n    key: \"convertAndCacheOnCPU\",\n    value: function convertAndCacheOnCPU(dataId, float32Values) {\n      var texData = this.texData.get(dataId);\n      var dtype = texData.dtype;\n      this.releaseGPUData(dataId);\n\n      if (float32Values != null) {\n        texData.values = float32ToTypedArray(float32Values, dtype);\n      }\n\n      return texData.values;\n    }\n  }, {\n    key: \"acquireTexture\",\n    value: function acquireTexture(texShape, texType, dtype, isPacked) {\n      this.numBytesInGPU += this.computeBytes(texShape, dtype);\n\n      if (!this.warnedAboutMemory && this.numBytesInGPU > this.numMBBeforeWarning * 1024 * 1024) {\n        var mb = (this.numBytesInGPU / 1024 / 1024).toFixed(2);\n        this.warnedAboutMemory = true;\n        console.warn(\"High memory usage in GPU: \".concat(mb, \" MB, \") + \"most likely due to a memory leak\");\n      }\n\n      return this.textureManager.acquireTexture(texShape, texType, isPacked);\n    }\n  }, {\n    key: \"computeBytes\",\n    value: function computeBytes(shape, dtype) {\n      return shape[0] * shape[1] * util.bytesPerElement(dtype);\n    }\n  }, {\n    key: \"tryRunOnCpuOrThrow\",\n    value: function tryRunOnCpuOrThrow(inputs, fn) {\n      if (this.shouldExecuteOnCPU(inputs)) {\n        try {\n          return fn();\n        } catch (e) {\n          if (env().getBool('IS_TEST')) {\n            throw new Error('CPU forwarding failed');\n          }\n        }\n      }\n\n      return null;\n    }\n  }]);\n\n  return MathBackendWebGL;\n}(KernelBackend);\n\nfunction float32ToTypedArray(a, dtype) {\n  if (dtype === 'float32' || dtype === 'complex64') {\n    return a;\n  } else if (dtype === 'int32' || dtype === 'bool') {\n    var result = dtype === 'int32' ? new Int32Array(a.length) : new Uint8Array(a.length);\n\n    for (var i = 0; i < result.length; ++i) {\n      result[i] = Math.round(a[i]);\n    }\n\n    return result;\n  } else {\n    throw new Error(\"Unknown dtype \".concat(dtype));\n  }\n}","map":null,"metadata":{},"sourceType":"module"}