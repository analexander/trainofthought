{"ast":null,"code":"import _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\n\n/**\n * @license\n * Copyright 2017 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { backend_util } from '@tensorflow/tfjs-core';\nvar CHECK_NAN_SNIPPET = \"\\n  if (isnan(a)) return a;\\n  if (isnan(b)) return b;\\n\"; // We use native integer division to deal with floating point imprecision. Since\n// we implement floor division and glsl implements truncated division, we\n// correct for this by subtracting 1 from result when the result is negative and\n// there is a remainder.\n\nexport var INT_DIV = \"\\n  float s = sign(a) * sign(b);\\n  int ia = round(a);\\n  int ib = round(b);\\n  if (ib != 0) {\\n    // Windows (D3D) wants guaranteed non-zero int division at compile-time.\\n    return float(idiv(ia, ib, s));\\n  } else {\\n    return NAN;\\n  }\\n\";\nexport var POW = \"\\nif(a < 0.0 && floor(b) < b){\\n  return NAN;\\n}\\nif (b == 0.0) {\\n  return 1.0;\\n}\\nreturn (round(mod(b, 2.0)) != 1) ?\\n    pow(abs(a), b) : sign(a) * pow(abs(a), b);\\n\";\nexport var SQUARED_DIFFERENCE = 'return (a - b) * (a - b);';\nexport var EQUAL = \"return float(a == b);\";\nexport var LESS = \"return float(a < b);\";\nexport var LESS_EQUAL = \"return float(a <= b);\";\nexport var GREATER = \"return float(a > b);\";\nexport var GREATER_EQUAL = \"return float(a >= b);\";\nexport var LOGICAL_AND = \"return float(a >= 1.0 && b >= 1.0);\";\nexport var LOGICAL_OR = \"return float(a >= 1.0 || b >= 1.0);\";\nexport var MAX = CHECK_NAN_SNIPPET + \"\\n  return max(a, b);\\n\";\nexport var MIN = CHECK_NAN_SNIPPET + \"\\n  return min(a, b);\\n\";\nexport var MOD = \"if (b == 0.0) return NAN;\\n  return mod(a, b);\";\nexport var ELU_DER = \"return (b >= 1.0) ? a : a * (b + 1.0);\";\nexport var PRELU = \"return (a < 0.) ? b * a : a;\";\nexport var BinaryOpProgram = function BinaryOpProgram(op, aShape, bShape) {\n  _classCallCheck(this, BinaryOpProgram);\n\n  this.variableNames = ['A', 'B'];\n  this.outputShape = backend_util.assertAndGetBroadcastShape(aShape, bShape);\n  this.userCode = \"\\n      float binaryOperation(float a, float b) {\\n        \".concat(op, \"\\n      }\\n\\n      void main() {\\n        float a = getAAtOutCoords();\\n        float b = getBAtOutCoords();\\n        setOutput(binaryOperation(a, b));\\n      }\\n    \");\n};","map":null,"metadata":{},"sourceType":"module"}