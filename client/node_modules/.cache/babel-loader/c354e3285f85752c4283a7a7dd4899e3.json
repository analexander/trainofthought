{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it; if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = o[Symbol.iterator](); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { complex } from '../ops/complex';\nimport { tensor } from '../ops/tensor';\nimport { sizeFromShape } from '../util';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/** Number of bytes reserved for the length of the string. (32bit integer). */\n\nvar NUM_BYTES_STRING_LENGTH = 4;\n/**\n * Encode a map from names to weight values as an ArrayBuffer, along with an\n * `Array` of `WeightsManifestEntry` as specification of the encoded weights.\n *\n * This function does not perform sharding.\n *\n * This function is the reverse of `decodeWeights`.\n *\n * @param tensors A map (\"dict\") from names to tensors.\n * @param group Group to which the weights belong (optional).\n * @returns A `Promise` of\n *   - A flat `ArrayBuffer` with all the binary values of the `Tensor`s\n *     concatenated.\n *   - An `Array` of `WeightManifestEntry`s, carrying information including\n *     tensor names, `dtype`s and shapes.\n * @throws Error: on unsupported tensor `dtype`.\n */\n\nexport function encodeWeights(_x, _x2) {\n  return _encodeWeights.apply(this, arguments);\n}\n/**\n * Decode flat ArrayBuffer as weights.\n *\n * This function does not handle sharding.\n *\n * This function is the reverse of `encodeWeights`.\n *\n * @param buffer A flat ArrayBuffer carrying the binary values of the tensors\n *   concatenated in the order specified in `specs`.\n * @param specs Specifications of the names, dtypes and shapes of the tensors\n *   whose value are encoded by `buffer`.\n * @return A map from tensor name to tensor value, with the names corresponding\n *   to names in `specs`.\n * @throws Error, if any of the tensors has unsupported dtype.\n */\n\nfunction _encodeWeights() {\n  _encodeWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(tensors, group) {\n    var specs, dataPromises, names, _loop, i, tensorValues;\n\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            // TODO(adarob, cais): Support quantization.\n            specs = [];\n            dataPromises = [];\n            names = Array.isArray(tensors) ? tensors.map(function (tensor) {\n              return tensor.name;\n            }) : Object.keys(tensors);\n\n            _loop = function _loop(i) {\n              var name = names[i];\n              var t = Array.isArray(tensors) ? tensors[i].tensor : tensors[name];\n\n              if (t.dtype !== 'float32' && t.dtype !== 'int32' && t.dtype !== 'bool' && t.dtype !== 'string' && t.dtype !== 'complex64') {\n                throw new Error(\"Unsupported dtype in weight '\".concat(name, \"': \").concat(t.dtype));\n              }\n\n              var spec = {\n                name: name,\n                shape: t.shape,\n                dtype: t.dtype\n              };\n\n              if (t.dtype === 'string') {\n                var utf8bytes = new Promise( /*#__PURE__*/function () {\n                  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(resolve) {\n                    var vals, totalNumBytes, bytes, offset, _i6, val, bytesOfLength;\n\n                    return _regeneratorRuntime.wrap(function _callee$(_context) {\n                      while (1) {\n                        switch (_context.prev = _context.next) {\n                          case 0:\n                            _context.next = 2;\n                            return t.bytes();\n\n                          case 2:\n                            vals = _context.sent;\n                            totalNumBytes = vals.reduce(function (p, c) {\n                              return p + c.length;\n                            }, 0) + NUM_BYTES_STRING_LENGTH * vals.length;\n                            bytes = new Uint8Array(totalNumBytes);\n                            offset = 0;\n\n                            for (_i6 = 0; _i6 < vals.length; _i6++) {\n                              val = vals[_i6];\n                              bytesOfLength = new Uint8Array(new Uint32Array([val.length]).buffer);\n                              bytes.set(bytesOfLength, offset);\n                              offset += NUM_BYTES_STRING_LENGTH;\n                              bytes.set(val, offset);\n                              offset += val.length;\n                            }\n\n                            resolve(bytes);\n\n                          case 8:\n                          case \"end\":\n                            return _context.stop();\n                        }\n                      }\n                    }, _callee);\n                  }));\n\n                  return function (_x3) {\n                    return _ref.apply(this, arguments);\n                  };\n                }());\n                dataPromises.push(utf8bytes);\n              } else {\n                dataPromises.push(t.data());\n              }\n\n              if (group != null) {\n                spec.group = group;\n              }\n\n              specs.push(spec);\n            };\n\n            for (i = 0; i < names.length; ++i) {\n              _loop(i);\n            }\n\n            _context2.next = 7;\n            return Promise.all(dataPromises);\n\n          case 7:\n            tensorValues = _context2.sent;\n            return _context2.abrupt(\"return\", {\n              data: concatenateTypedArrays(tensorValues),\n              specs: specs\n            });\n\n          case 9:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return _encodeWeights.apply(this, arguments);\n}\n\nexport function decodeWeights(buffer, specs) {\n  // TODO(adarob, cais): Support quantization.\n  var out = {};\n  var float16Decode;\n  var offset = 0;\n\n  var _iterator = _createForOfIteratorHelper(specs),\n      _step;\n\n  try {\n    for (_iterator.s(); !(_step = _iterator.n()).done;) {\n      var spec = _step.value;\n      var name = spec.name;\n      var dtype = spec.dtype;\n      var shape = spec.shape;\n      var size = sizeFromShape(shape);\n      var values = void 0;\n\n      if ('quantization' in spec) {\n        var quantization = spec.quantization;\n\n        if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n          if (!('min' in quantization && 'scale' in quantization)) {\n            throw new Error(\"Weight \".concat(spec.name, \" with quantization \").concat(quantization.dtype, \" \") + \"doesn't have corresponding metadata min and scale.\");\n          }\n        } else if (quantization.dtype === 'float16') {\n          if (dtype !== 'float32') {\n            throw new Error(\"Weight \".concat(spec.name, \" is quantized with \").concat(quantization.dtype, \" \") + \"which only supports weights of type float32 not \".concat(dtype, \".\"));\n          }\n        } else {\n          throw new Error(\"Weight \".concat(spec.name, \" has unknown \") + \"quantization dtype \".concat(quantization.dtype, \". \") + \"Supported quantization dtypes are: \" + \"'uint8', 'uint16', and 'float16'.\");\n        }\n\n        var quantizationSizeFactor = DTYPE_VALUE_SIZE_MAP[quantization.dtype];\n        var byteBuffer = buffer.slice(offset, offset + size * quantizationSizeFactor);\n        var quantizedArray = quantization.dtype === 'uint8' ? new Uint8Array(byteBuffer) : new Uint16Array(byteBuffer);\n\n        if (dtype === 'float32') {\n          if (quantization.dtype === 'uint8' || quantization.dtype === 'uint16') {\n            values = new Float32Array(quantizedArray.length);\n\n            for (var i = 0; i < quantizedArray.length; i++) {\n              var v = quantizedArray[i];\n              values[i] = v * quantization.scale + quantization.min;\n            }\n          } else if (quantization.dtype === 'float16') {\n            if (float16Decode === undefined) {\n              float16Decode = getFloat16Decoder();\n            }\n\n            values = float16Decode(quantizedArray);\n          } else {\n            throw new Error(\"Unsupported quantization type \".concat(quantization.dtype, \" \") + \"for weight type float32.\");\n          }\n        } else if (dtype === 'int32') {\n          if (quantization.dtype !== 'uint8' && quantization.dtype !== 'uint16') {\n            throw new Error(\"Unsupported quantization type \".concat(quantization.dtype, \" \") + \"for weight type int32.\");\n          }\n\n          values = new Int32Array(quantizedArray.length);\n\n          for (var _i = 0; _i < quantizedArray.length; _i++) {\n            var _v = quantizedArray[_i];\n            values[_i] = Math.round(_v * quantization.scale + quantization.min);\n          }\n        } else {\n          throw new Error(\"Unsupported dtype in weight '\".concat(name, \"': \").concat(dtype));\n        }\n\n        offset += size * quantizationSizeFactor;\n      } else if (dtype === 'string') {\n        var _size = sizeFromShape(spec.shape);\n\n        values = [];\n\n        for (var _i2 = 0; _i2 < _size; _i2++) {\n          var byteLength = new Uint32Array(buffer.slice(offset, offset + NUM_BYTES_STRING_LENGTH))[0];\n          offset += NUM_BYTES_STRING_LENGTH;\n          var bytes = new Uint8Array(buffer.slice(offset, offset + byteLength));\n          values.push(bytes);\n          offset += byteLength;\n        }\n      } else {\n        var dtypeFactor = DTYPE_VALUE_SIZE_MAP[dtype];\n\n        var _byteBuffer = buffer.slice(offset, offset + size * dtypeFactor);\n\n        if (dtype === 'float32') {\n          values = new Float32Array(_byteBuffer);\n        } else if (dtype === 'int32') {\n          values = new Int32Array(_byteBuffer);\n        } else if (dtype === 'bool') {\n          values = new Uint8Array(_byteBuffer);\n        } else if (dtype === 'complex64') {\n          values = new Float32Array(_byteBuffer);\n          var real = new Float32Array(values.length / 2);\n          var image = new Float32Array(values.length / 2);\n\n          for (var _i3 = 0; _i3 < real.length; _i3++) {\n            real[_i3] = values[_i3 * 2];\n            image[_i3] = values[_i3 * 2 + 1];\n          }\n\n          var realTensor = tensor(real, shape, 'float32');\n          var imageTensor = tensor(image, shape, 'float32');\n          out[name] = complex(realTensor, imageTensor);\n          realTensor.dispose();\n          imageTensor.dispose();\n        } else {\n          throw new Error(\"Unsupported dtype in weight '\".concat(name, \"': \").concat(dtype));\n        }\n\n        offset += size * dtypeFactor;\n      }\n\n      if (dtype !== 'complex64') {\n        out[name] = tensor(values, shape, dtype);\n      }\n    }\n  } catch (err) {\n    _iterator.e(err);\n  } finally {\n    _iterator.f();\n  }\n\n  return out;\n}\n/**\n * Concatenate TypedArrays into an ArrayBuffer.\n */\n\nexport function concatenateTypedArrays(xs) {\n  // TODO(adarob, cais): Support quantization.\n  if (xs === null) {\n    throw new Error(\"Invalid input value: \".concat(JSON.stringify(xs)));\n  }\n\n  var totalByteLength = 0; // `normalizedXs` is here for this reason: a `TypedArray`'s `buffer'\n  // can have a different byte length from that of the `TypedArray` itself,\n  // for example, when the `TypedArray` is created from an offset in an\n  // `ArrayBuffer`. `normliazedXs` holds `TypedArray`s whose `buffer`s match\n  // the `TypedArray` in byte length. If an element of `xs` does not show\n  // this property, a new `TypedArray` that satisfy this property will be\n  // constructed and pushed into `normalizedXs`.\n\n  var normalizedXs = [];\n  xs.forEach(function (x) {\n    totalByteLength += x.byteLength; // tslint:disable:no-any\n\n    normalizedXs.push(x.byteLength === x.buffer.byteLength ? x : new x.constructor(x));\n\n    if (!(x instanceof Float32Array || x instanceof Int32Array || x instanceof Uint8Array)) {\n      throw new Error(\"Unsupported TypedArray subtype: \".concat(x.constructor.name));\n    } // tslint:enable:no-any\n\n  });\n  var y = new Uint8Array(totalByteLength);\n  var offset = 0;\n  normalizedXs.forEach(function (x) {\n    y.set(new Uint8Array(x.buffer), offset);\n    offset += x.byteLength;\n  });\n  return y.buffer;\n} // Use Buffer on Node.js instead of Blob/atob/btoa\n\nvar useNodeBuffer = typeof Buffer !== 'undefined' && (typeof Blob === 'undefined' || typeof atob === 'undefined' || typeof btoa === 'undefined');\n/**\n * Calculate the byte length of a JavaScript string.\n *\n * Note that a JavaScript string can contain wide characters, therefore the\n * length of the string is not necessarily equal to the byte length.\n *\n * @param str Input string.\n * @returns Byte length.\n */\n\nexport function stringByteLength(str) {\n  if (useNodeBuffer) {\n    return Buffer.byteLength(str);\n  }\n\n  return new Blob([str]).size;\n}\n/**\n * Encode an ArrayBuffer as a base64 encoded string.\n *\n * @param buffer `ArrayBuffer` to be converted.\n * @returns A string that base64-encodes `buffer`.\n */\n\nexport function arrayBufferToBase64String(buffer) {\n  if (useNodeBuffer) {\n    return Buffer.from(buffer).toString('base64');\n  }\n\n  var buf = new Uint8Array(buffer);\n  var s = '';\n\n  for (var i = 0, l = buf.length; i < l; i++) {\n    s += String.fromCharCode(buf[i]);\n  }\n\n  return btoa(s);\n}\n/**\n * Decode a base64 string as an ArrayBuffer.\n *\n * @param str Base64 string.\n * @returns Decoded `ArrayBuffer`.\n */\n\nexport function base64StringToArrayBuffer(str) {\n  if (useNodeBuffer) {\n    var buf = Buffer.from(str, 'base64');\n    return buf.buffer.slice(buf.byteOffset, buf.byteOffset + buf.byteLength);\n  }\n\n  var s = atob(str);\n  var buffer = new Uint8Array(s.length);\n\n  for (var i = 0; i < s.length; ++i) {\n    buffer.set([s.charCodeAt(i)], i);\n  }\n\n  return buffer.buffer;\n}\n/**\n * Concatenate a number of ArrayBuffers into one.\n *\n * @param buffers A number of array buffers to concatenate.\n * @returns Result of concatenating `buffers` in order.\n */\n\nexport function concatenateArrayBuffers(buffers) {\n  if (buffers.length === 1) {\n    return buffers[0];\n  }\n\n  var totalByteLength = 0;\n  buffers.forEach(function (buffer) {\n    totalByteLength += buffer.byteLength;\n  });\n  var temp = new Uint8Array(totalByteLength);\n  var offset = 0;\n  buffers.forEach(function (buffer) {\n    temp.set(new Uint8Array(buffer), offset);\n    offset += buffer.byteLength;\n  });\n  return temp.buffer;\n}\n/**\n * Get the basename of a path.\n *\n * Behaves in a way analogous to Linux's basename command.\n *\n * @param path\n */\n\nexport function basename(path) {\n  var SEPARATOR = '/';\n  path = path.trim();\n\n  while (path.endsWith(SEPARATOR)) {\n    path = path.slice(0, path.length - 1);\n  }\n\n  var items = path.split(SEPARATOR);\n  return items[items.length - 1];\n}\n/**\n * Populate ModelArtifactsInfo fields for a model with JSON topology.\n * @param modelArtifacts\n * @returns A ModelArtifactsInfo object.\n */\n\nexport function getModelArtifactsInfoForJSON(modelArtifacts) {\n  if (modelArtifacts.modelTopology instanceof ArrayBuffer) {\n    throw new Error('Expected JSON model topology, received ArrayBuffer.');\n  }\n\n  return {\n    dateSaved: new Date(),\n    modelTopologyType: 'JSON',\n    modelTopologyBytes: modelArtifacts.modelTopology == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.modelTopology)),\n    weightSpecsBytes: modelArtifacts.weightSpecs == null ? 0 : stringByteLength(JSON.stringify(modelArtifacts.weightSpecs)),\n    weightDataBytes: modelArtifacts.weightData == null ? 0 : modelArtifacts.weightData.byteLength\n  };\n}\n/**\n * Computes mantisa table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 2048 mantissa lookup values.\n */\n\nfunction computeFloat16MantisaTable() {\n  var convertMantissa = function convertMantissa(i) {\n    var m = i << 13;\n    var e = 0;\n\n    while ((m & 0x00800000) === 0) {\n      e -= 0x00800000;\n      m <<= 1;\n    }\n\n    m &= ~0x00800000;\n    e += 0x38800000;\n    return m | e;\n  };\n\n  var mantisaTable = new Uint32Array(2048);\n  mantisaTable[0] = 0;\n\n  for (var i = 1; i < 1024; i++) {\n    mantisaTable[i] = convertMantissa(i);\n  }\n\n  for (var _i4 = 1024; _i4 < 2048; _i4++) {\n    mantisaTable[_i4] = 0x38000000 + (_i4 - 1024 << 13);\n  }\n\n  return mantisaTable;\n}\n/**\n * Computes exponent table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 64 exponent lookup values.\n */\n\n\nfunction computeFloat16ExponentTable() {\n  var exponentTable = new Uint32Array(64);\n  exponentTable[0] = 0;\n  exponentTable[31] = 0x47800000;\n  exponentTable[32] = 0x80000000;\n  exponentTable[63] = 0xc7800000;\n\n  for (var i = 1; i < 31; i++) {\n    exponentTable[i] = i << 23;\n  }\n\n  for (var _i5 = 33; _i5 < 63; _i5++) {\n    exponentTable[_i5] = 0x80000000 + (_i5 - 32 << 23);\n  }\n\n  return exponentTable;\n}\n/**\n * Computes offset table for casting Float16 to Float32\n * See http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n *\n * @returns Uint32Array, 6d offset values.\n */\n\n\nfunction computeFloat16OffsetTable() {\n  var offsetTable = new Uint32Array(64);\n\n  for (var i = 0; i < 64; i++) {\n    offsetTable[i] = 1024;\n  }\n\n  offsetTable[0] = offsetTable[32] = 0;\n  return offsetTable;\n}\n/**\n * Retrieve a Float16 decoder which will decode a ByteArray of Float16 values\n * to a Float32Array.\n *\n * @returns Function (buffer: Uint16Array) => Float32Array which decodes\n *          the Uint16Array of Float16 bytes to a Float32Array.\n */\n\n\nexport function getFloat16Decoder() {\n  // Algorithm is based off of\n  // http://www.fox-toolkit.org/ftp/fasthalffloatconversion.pdf\n  // Cache lookup tables\n  var mantisaTable = computeFloat16MantisaTable();\n  var exponentTable = computeFloat16ExponentTable();\n  var offsetTable = computeFloat16OffsetTable();\n  return function (quantizedArray) {\n    var buffer = new ArrayBuffer(4 * quantizedArray.length);\n    var bufferUint32View = new Uint32Array(buffer);\n\n    for (var index = 0; index < quantizedArray.length; index++) {\n      var float16Bits = quantizedArray[index];\n      var float32Bits = mantisaTable[offsetTable[float16Bits >> 10] + (float16Bits & 0x3ff)] + exponentTable[float16Bits >> 10];\n      bufferUint32View[index] = float32Bits;\n    }\n\n    return new Float32Array(buffer);\n  };\n}","map":null,"metadata":{},"sourceType":"module"}