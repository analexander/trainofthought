{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport { env, tensor, util } from '@tensorflow/tfjs-core';\nimport { LazyIterator } from './lazy_iterator';\n/**\n * Provide a stream of tensors from microphone audio stream. The tensors are\n * representing audio data as frequency-domain spectrogram generated with\n * browser's native FFT. Tensors representing time-domain waveform is available\n * based on configuration. Only works in browser environment.\n */\n\nexport var MicrophoneIterator = /*#__PURE__*/function (_LazyIterator) {\n  _inherits(MicrophoneIterator, _LazyIterator);\n\n  function MicrophoneIterator(microphoneConfig) {\n    var _this;\n\n    _classCallCheck(this, MicrophoneIterator);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(MicrophoneIterator).call(this));\n    _this.microphoneConfig = microphoneConfig;\n    _this.isClosed = false;\n    _this.fftSize = microphoneConfig.fftSize || 1024;\n    var fftSizeLog2 = Math.log2(_this.fftSize);\n\n    if (_this.fftSize < 0 || fftSizeLog2 < 4 || fftSizeLog2 > 14 || !Number.isInteger(fftSizeLog2)) {\n      throw new Error(\"Invalid fftSize: it must be a power of 2 between \" + \"2 to 4 and 2 to 14, but got \".concat(_this.fftSize));\n    }\n\n    _this.numFrames = microphoneConfig.numFramesPerSpectrogram || 43;\n    _this.sampleRateHz = microphoneConfig.sampleRateHz;\n    _this.columnTruncateLength = microphoneConfig.columnTruncateLength || _this.fftSize;\n    _this.audioTrackConstraints = microphoneConfig.audioTrackConstraints;\n    _this.smoothingTimeConstant = microphoneConfig.smoothingTimeConstant || 0;\n    _this.includeSpectrogram = microphoneConfig.includeSpectrogram === false ? false : true;\n    _this.includeWaveform = microphoneConfig.includeWaveform === true ? true : false;\n\n    if (!_this.includeSpectrogram && !_this.includeWaveform) {\n      throw new Error('Both includeSpectrogram and includeWaveform are false. ' + 'At least one type of data should be returned.');\n    }\n\n    return _this;\n  }\n\n  _createClass(MicrophoneIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"microphone\";\n    } // Construct a MicrophoneIterator and start the audio stream.\n\n  }, {\n    key: \"start\",\n    // Start the audio stream and FFT.\n    value: function () {\n      var _start = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var ctxConstructor, streamSource;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                _context.prev = 0;\n                _context.next = 3;\n                return navigator.mediaDevices.getUserMedia({\n                  audio: this.audioTrackConstraints == null ? true : this.audioTrackConstraints,\n                  video: false\n                });\n\n              case 3:\n                this.stream = _context.sent;\n                _context.next = 9;\n                break;\n\n              case 6:\n                _context.prev = 6;\n                _context.t0 = _context[\"catch\"](0);\n                throw new Error(\"Error thrown while initializing video stream: \".concat(_context.t0.message));\n\n              case 9:\n                if (this.stream) {\n                  _context.next = 11;\n                  break;\n                }\n\n                throw new Error('Could not obtain audio from microphone.');\n\n              case 11:\n                ctxConstructor = // tslint:disable-next-line:no-any\n                window.AudioContext || window.webkitAudioContext;\n                this.audioContext = new ctxConstructor();\n\n                if (this.sampleRateHz) {\n                  _context.next = 17;\n                  break;\n                }\n\n                // If sample rate is not provided, use the available sample rate on\n                // device.\n                this.sampleRateHz = this.audioContext.sampleRate;\n                _context.next = 19;\n                break;\n\n              case 17:\n                if (!(this.audioContext.sampleRate !== this.sampleRateHz)) {\n                  _context.next = 19;\n                  break;\n                }\n\n                throw new Error(\"Mismatch in sampling rate: \" + \"Expected: \".concat(this.sampleRateHz, \"; \") + \"Actual: \".concat(this.audioContext.sampleRate));\n\n              case 19:\n                streamSource = this.audioContext.createMediaStreamSource(this.stream);\n                this.analyser = this.audioContext.createAnalyser();\n                this.analyser.fftSize = this.fftSize * 2;\n                this.analyser.smoothingTimeConstant = this.smoothingTimeConstant;\n                streamSource.connect(this.analyser);\n                this.freqData = new Float32Array(this.fftSize);\n                this.timeData = new Float32Array(this.fftSize);\n                return _context.abrupt(\"return\");\n\n              case 27:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this, [[0, 6]]);\n      }));\n\n      function start() {\n        return _start.apply(this, arguments);\n      }\n\n      return start;\n    }()\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        var spectrogramTensor, waveformTensor, audioDataQueue, freqData, timeData;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                if (!this.isClosed) {\n                  _context2.next = 2;\n                  break;\n                }\n\n                return _context2.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 2:\n                _context2.next = 4;\n                return this.getAudioData();\n\n              case 4:\n                audioDataQueue = _context2.sent;\n\n                if (this.includeSpectrogram) {\n                  freqData = this.flattenQueue(audioDataQueue.freqDataQueue);\n                  spectrogramTensor = this.getTensorFromAudioDataArray(freqData, [this.numFrames, this.columnTruncateLength, 1]);\n                }\n\n                if (this.includeWaveform) {\n                  timeData = this.flattenQueue(audioDataQueue.timeDataQueue);\n                  waveformTensor = this.getTensorFromAudioDataArray(timeData, [this.numFrames * this.fftSize, 1]);\n                }\n\n                return _context2.abrupt(\"return\", {\n                  value: {\n                    'spectrogram': spectrogramTensor,\n                    'waveform': waveformTensor\n                  },\n                  done: false\n                });\n\n              case 8:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function next() {\n        return _next.apply(this, arguments);\n      }\n\n      return next;\n    }() // Capture one result from the audio stream, and extract the value from\n    // iterator.next() result.\n\n  }, {\n    key: \"capture\",\n    value: function () {\n      var _capture = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                _context3.next = 2;\n                return this.next();\n\n              case 2:\n                return _context3.abrupt(\"return\", _context3.sent.value);\n\n              case 3:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function capture() {\n        return _capture.apply(this, arguments);\n      }\n\n      return capture;\n    }()\n  }, {\n    key: \"getAudioData\",\n    value: function () {\n      var _getAudioData = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4() {\n        var _this2 = this;\n\n        var freqDataQueue, timeDataQueue, currentFrames;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                freqDataQueue = [];\n                timeDataQueue = [];\n                currentFrames = 0;\n                return _context4.abrupt(\"return\", new Promise(function (resolve) {\n                  var intervalID = setInterval(function () {\n                    if (_this2.includeSpectrogram) {\n                      _this2.analyser.getFloatFrequencyData(_this2.freqData); // If the audio stream is initializing, return empty queue.\n\n\n                      if (_this2.freqData[0] === -Infinity) {\n                        resolve({\n                          freqDataQueue: freqDataQueue,\n                          timeDataQueue: timeDataQueue\n                        });\n                      }\n\n                      freqDataQueue.push(_this2.freqData.slice(0, _this2.columnTruncateLength));\n                    }\n\n                    if (_this2.includeWaveform) {\n                      _this2.analyser.getFloatTimeDomainData(_this2.timeData);\n\n                      timeDataQueue.push(_this2.timeData.slice());\n                    } // Clean interval and return when all frames have been collected\n\n\n                    if (++currentFrames === _this2.numFrames) {\n                      clearInterval(intervalID);\n                      resolve({\n                        freqDataQueue: freqDataQueue,\n                        timeDataQueue: timeDataQueue\n                      });\n                    }\n                  }, _this2.fftSize / _this2.sampleRateHz * 1e3);\n                }));\n\n              case 4:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4);\n      }));\n\n      function getAudioData() {\n        return _getAudioData.apply(this, arguments);\n      }\n\n      return getAudioData;\n    }() // Stop the audio stream and pause the iterator.\n\n  }, {\n    key: \"stop\",\n    value: function stop() {\n      if (!this.isClosed) {\n        this.isClosed = true;\n        this.analyser.disconnect();\n        this.audioContext.close();\n\n        if (this.stream != null && this.stream.getTracks().length > 0) {\n          this.stream.getTracks()[0].stop();\n        }\n      }\n    } // Override toArray() function to prevent collecting.\n\n  }, {\n    key: \"toArray\",\n    value: function toArray() {\n      throw new Error('Can not convert infinite audio stream to array.');\n    } // Return audio sampling rate in Hz\n\n  }, {\n    key: \"getSampleRate\",\n    value: function getSampleRate() {\n      return this.sampleRateHz;\n    }\n  }, {\n    key: \"flattenQueue\",\n    value: function flattenQueue(queue) {\n      var frameSize = queue[0].length;\n      var freqData = new Float32Array(queue.length * frameSize);\n      queue.forEach(function (data, i) {\n        return freqData.set(data, i * frameSize);\n      });\n      return freqData;\n    }\n  }, {\n    key: \"getTensorFromAudioDataArray\",\n    value: function getTensorFromAudioDataArray(freqData, shape) {\n      var vals = new Float32Array(util.sizeFromShape(shape)); // If the data is less than the output shape, the rest is padded with zeros.\n\n      vals.set(freqData, vals.length - freqData.length);\n      return tensor(vals, shape);\n    }\n  }], [{\n    key: \"create\",\n    value: function () {\n      var _create = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5() {\n        var microphoneConfig,\n            microphoneIterator,\n            _args5 = arguments;\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                microphoneConfig = _args5.length > 0 && _args5[0] !== undefined ? _args5[0] : {};\n\n                if (!env().get('IS_NODE')) {\n                  _context5.next = 3;\n                  break;\n                }\n\n                throw new Error('microphone API is only supported in browser environment.');\n\n              case 3:\n                microphoneIterator = new MicrophoneIterator(microphoneConfig); // Call async function start() to initialize the audio stream.\n\n                _context5.next = 6;\n                return microphoneIterator.start();\n\n              case 6:\n                return _context5.abrupt(\"return\", microphoneIterator);\n\n              case 7:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5);\n      }));\n\n      function create() {\n        return _create.apply(this, arguments);\n      }\n\n      return create;\n    }()\n  }]);\n\n  return MicrophoneIterator;\n}(LazyIterator);","map":null,"metadata":{},"sourceType":"module"}