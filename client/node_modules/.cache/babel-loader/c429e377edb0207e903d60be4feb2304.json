{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _toConsumableArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _taggedTemplateLiteral from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/taggedTemplateLiteral\";\n\nvar _this = this,\n    _jsxFileName = \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/FaceDetectionComponent/FaceDetectionComponent.js\";\n\nfunction _templateObject2() {\n  var data = _taggedTemplateLiteral([\"\\n    position: absolute;\\n    top: 0;\\n    left: 0;\\n\"]);\n\n  _templateObject2 = function _templateObject2() {\n    return data;\n  };\n\n  return data;\n}\n\nfunction _templateObject() {\n  var data = _taggedTemplateLiteral([\"\\n    position: relative;\\n\"]);\n\n  _templateObject = function _templateObject() {\n    return data;\n  };\n\n  return data;\n}\n\nimport React, { useEffect, useRef, useState } from \"react\";\nimport { CameraComponent } from \"../CameraComponent/CameraComponent\";\nimport CanvasComponent from \"../CanvasComponent/CanvasComponent\";\nimport styled from \"styled-components\";\nimport { nets, loadFaceExpressionModel, matchDimensions, resizeResults, detectSingleFace, TinyFaceDetectorOptions, draw } from \"face-api.js\";\nvar ContainerComponent = styled.div(_templateObject());\nvar OverlayComponent = styled.div(_templateObject2());\n\nvar FaceDetectionComponent = function FaceDetectionComponent() {\n  var videoRef = useRef();\n  var canvasRef = useRef();\n\n  var _useState = useState(),\n      _useState2 = _slicedToArray(_useState, 2),\n      emotion = _useState2[0],\n      setEmotion = _useState2[1];\n\n  useEffect(function () {\n    captureEmotion();\n  }, []);\n\n  var captureEmotion = function captureEmotion() {\n    var expressions = result.expressions;\n    var maxValue = Math.max.apply(Math, _toConsumableArray(Object.values(expressions)));\n    var emotion = Object.keys(expressions).filter(function (item) {\n      return expressions[item] === maxValue;\n    });\n  };\n\n  var initModels = /*#__PURE__*/function () {\n    var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              _context.next = 2;\n              return nets.tinyFaceDetector.load(\"/models/\");\n\n            case 2:\n              _context.next = 4;\n              return loadFaceExpressionModel(\"/models/\");\n\n            case 4:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee);\n    }));\n\n    return function initModels() {\n      return _ref.apply(this, arguments);\n    };\n  }();\n\n  var redirectToPage = function redirectToPage(emotion) {\n    console.log(emotion); // TODO: Redirect Emotion\n  };\n\n  var startFaceDetection = /*#__PURE__*/function () {\n    var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n      var options, result, dims, resizedResult, minConfidence;\n      return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              options = new TinyFaceDetectorOptions({\n                inputSize: 512,\n                scoreThreshold: 0.5\n              });\n              _context2.next = 3;\n              return detectSingleFace(videoRef.current, options).withFaceExpressions();\n\n            case 3:\n              result = _context2.sent;\n\n              if (result) {\n                dims = matchDimensions(canvasRef.current, videoRef.current, true);\n                resizedResult = resizeResults(result, dims);\n                minConfidence = 0.05;\n                draw.drawDetections(canvasRef.current, resizedResult);\n                draw.drawFaceExpressions(canvasRef.current, resizedResult, minConfidence); /////// expression capture ////////\n                // const captureEmotion =  () => {\n                // const expressions = result.expressions;\n                // const maxValue = Math.max(...Object.values(expressions));\n                // const emotion = Object.keys(expressions).filter(\n                //     item => expressions[item] === maxValue\n                //     );\n                // }\n\n                setEmotion(emotion[0]);\n                redirectToPage(emotion[0]); /////// expression capture ////////\n              } // if (emotion !== undefined) {\n\n\n              setTimeout(function () {\n                return startFaceDetection();\n              }); // }\n\n            case 6:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2);\n    }));\n\n    return function startFaceDetection() {\n      return _ref2.apply(this, arguments);\n    };\n  }();\n\n  useEffect(function () {\n    initModels();\n    ;\n  }, []);\n  return /*#__PURE__*/React.createElement(ContainerComponent, {\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 88,\n      columnNumber: 9\n    }\n  }, /*#__PURE__*/React.createElement(CameraComponent, {\n    videoRef: videoRef,\n    onReady: startFaceDetection,\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 89,\n      columnNumber: 13\n    }\n  }), /*#__PURE__*/React.createElement(OverlayComponent, {\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 90,\n      columnNumber: 13\n    }\n  }, /*#__PURE__*/React.createElement(CanvasComponent, {\n    canvasRef: canvasRef,\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 91,\n      columnNumber: 17\n    }\n  })), /*#__PURE__*/React.createElement(\"h1\", {\n    __self: _this,\n    __source: {\n      fileName: _jsxFileName,\n      lineNumber: 93,\n      columnNumber: 13\n    }\n  }, \"Emotion: \", emotion));\n};\n\nexport default FaceDetectionComponent;","map":{"version":3,"sources":["/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/FaceDetectionComponent/FaceDetectionComponent.js"],"names":["React","useEffect","useRef","useState","CameraComponent","CanvasComponent","styled","nets","loadFaceExpressionModel","matchDimensions","resizeResults","detectSingleFace","TinyFaceDetectorOptions","draw","ContainerComponent","div","OverlayComponent","FaceDetectionComponent","videoRef","canvasRef","emotion","setEmotion","captureEmotion","expressions","result","maxValue","Math","max","Object","values","keys","filter","item","initModels","tinyFaceDetector","load","redirectToPage","console","log","startFaceDetection","options","inputSize","scoreThreshold","current","withFaceExpressions","dims","resizedResult","minConfidence","drawDetections","drawFaceExpressions","setTimeout"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,EAA2BC,MAA3B,EAAmCC,QAAnC,QAAmD,OAAnD;AAEA,SAASC,eAAT,QAAgC,oCAAhC;AACA,OAAOC,eAAP,MAA4B,oCAA5B;AACA,OAAOC,MAAP,MAAmB,mBAAnB;AACA,SACIC,IADJ,EACUC,uBADV,EACmCC,eADnC,EAEIC,aAFJ,EAEmBC,gBAFnB,EAEqCC,uBAFrC,EAGIC,IAHJ,QAIO,aAJP;AAMA,IAAMC,kBAAkB,GAAGR,MAAM,CAACS,GAAV,mBAAxB;AAIA,IAAMC,gBAAgB,GAAGV,MAAM,CAACS,GAAV,oBAAtB;;AAOA,IAAME,sBAAsB,GAAG,SAAzBA,sBAAyB,GAAM;AACjC,MAAMC,QAAQ,GAAGhB,MAAM,EAAvB;AACA,MAAMiB,SAAS,GAAGjB,MAAM,EAAxB;;AAFiC,kBAGHC,QAAQ,EAHL;AAAA;AAAA,MAG1BiB,OAH0B;AAAA,MAGjBC,UAHiB;;AAKjCpB,EAAAA,SAAS,CAAC,YAAM;AACZqB,IAAAA,cAAc;AACjB,GAFQ,EAEN,EAFM,CAAT;;AAIA,MAAMA,cAAc,GAAI,SAAlBA,cAAkB,GAAM;AAC1B,QAAMC,WAAW,GAAGC,MAAM,CAACD,WAA3B;AACA,QAAME,QAAQ,GAAGC,IAAI,CAACC,GAAL,OAAAD,IAAI,qBAAQE,MAAM,CAACC,MAAP,CAAcN,WAAd,CAAR,EAArB;AACA,QAAMH,OAAO,GAAGQ,MAAM,CAACE,IAAP,CAAYP,WAAZ,EAAyBQ,MAAzB,CACZ,UAAAC,IAAI;AAAA,aAAIT,WAAW,CAACS,IAAD,CAAX,KAAsBP,QAA1B;AAAA,KADQ,CAAhB;AAGC,GANL;;AAQA,MAAMQ,UAAU;AAAA,wEAAG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBACT1B,IAAI,CAAC2B,gBAAL,CAAsBC,IAAtB,CAA2B,UAA3B,CADS;;AAAA;AAAA;AAAA,qBAET3B,uBAAuB,CAAC,UAAD,CAFd;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAH;;AAAA,oBAAVyB,UAAU;AAAA;AAAA;AAAA,KAAhB;;AAKA,MAAMG,cAAc,GAAG,SAAjBA,cAAiB,CAAChB,OAAD,EAAa;AAChCiB,IAAAA,OAAO,CAACC,GAAR,CAAYlB,OAAZ,EADgC,CAEhC;AACH,GAHD;;AAKA,MAAMmB,kBAAkB;AAAA,yEAAG;AAAA;AAAA;AAAA;AAAA;AAAA;AACjBC,cAAAA,OADiB,GACP,IAAI5B,uBAAJ,CAA4B;AAAE6B,gBAAAA,SAAS,EAAE,GAAb;AAAkBC,gBAAAA,cAAc,EAAE;AAAlC,eAA5B,CADO;AAAA;AAAA,qBAEF/B,gBAAgB,CAACO,QAAQ,CAACyB,OAAV,EAAmBH,OAAnB,CAAhB,CAA4CI,mBAA5C,EAFE;;AAAA;AAEjBpB,cAAAA,MAFiB;;AAGvB,kBAAIA,MAAJ,EAAY;AAEFqB,gBAAAA,IAFE,GAEKpC,eAAe,CAACU,SAAS,CAACwB,OAAX,EAAoBzB,QAAQ,CAACyB,OAA7B,EAAsC,IAAtC,CAFpB;AAGFG,gBAAAA,aAHE,GAGcpC,aAAa,CAACc,MAAD,EAASqB,IAAT,CAH3B;AAIFE,gBAAAA,aAJE,GAIc,IAJd;AAKRlC,gBAAAA,IAAI,CAACmC,cAAL,CAAoB7B,SAAS,CAACwB,OAA9B,EAAuCG,aAAvC;AACAjC,gBAAAA,IAAI,CAACoC,mBAAL,CAAyB9B,SAAS,CAACwB,OAAnC,EAA4CG,aAA5C,EAA2DC,aAA3D,EANQ,CAQR;AAEA;AACA;AACA;AACA;AACA;AACA;AACA;;AAEA1B,gBAAAA,UAAU,CAACD,OAAO,CAAC,CAAD,CAAR,CAAV;AACAgB,gBAAAA,cAAc,CAAChB,OAAO,CAAC,CAAD,CAAR,CAAd,CAnBQ,CAqBR;AAEH,eA1BsB,CA2BvB;;;AACI8B,cAAAA,UAAU,CAAC;AAAA,uBAAMX,kBAAkB,EAAxB;AAAA,eAAD,CAAV,CA5BmB,CA6BvB;;AA7BuB;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,KAAH;;AAAA,oBAAlBA,kBAAkB;AAAA;AAAA;AAAA,KAAxB;;AAgCAtC,EAAAA,SAAS,CAAC,YAAM;AACZgC,IAAAA,UAAU;AAAG;AAChB,GAFQ,EAEN,EAFM,CAAT;AAKA,sBACI,oBAAC,kBAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI,oBAAC,eAAD;AAAiB,IAAA,QAAQ,EAAEf,QAA3B;AAAqC,IAAA,OAAO,EAAEqB,kBAA9C;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADJ,eAEI,oBAAC,gBAAD;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBACI,oBAAC,eAAD;AAAiB,IAAA,SAAS,EAAEpB,SAA5B;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,IADJ,CAFJ,eAKI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,kBAAcC,OAAd,CALJ,CADJ;AASH,CAzED;;AA2EA,eAAeH,sBAAf","sourcesContent":["import React, { useEffect, useRef, useState } from \"react\";\n\nimport { CameraComponent } from \"../CameraComponent/CameraComponent\";\nimport CanvasComponent from \"../CanvasComponent/CanvasComponent\";\nimport styled from \"styled-components\";\nimport {\n    nets, loadFaceExpressionModel, matchDimensions,\n    resizeResults, detectSingleFace, TinyFaceDetectorOptions,\n    draw\n} from \"face-api.js\";\n\nconst ContainerComponent = styled.div`\n    position: relative;\n`;\n\nconst OverlayComponent = styled.div`\n    position: absolute;\n    top: 0;\n    left: 0;\n`;\n\n\nconst FaceDetectionComponent = () => {\n    const videoRef = useRef();\n    const canvasRef = useRef();\n    const [emotion, setEmotion] = useState();\n\n    useEffect(() => {\n        captureEmotion();\n    }, []);\n\n    const captureEmotion =  () => {\n        const expressions = result.expressions;\n        const maxValue = Math.max(...Object.values(expressions));\n        const emotion = Object.keys(expressions).filter(\n            item => expressions[item] === maxValue\n            );\n        }\n\n    const initModels = async () => {\n        await nets.tinyFaceDetector.load(\"/models/\");\n        await loadFaceExpressionModel(\"/models/\");\n    }\n\n    const redirectToPage = (emotion) => {\n        console.log(emotion);\n        // TODO: Redirect Emotion\n    }\n\n    const startFaceDetection = async () => {\n        const options = new TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });\n        const result = await detectSingleFace(videoRef.current, options).withFaceExpressions();\n        if (result) {\n\n            const dims = matchDimensions(canvasRef.current, videoRef.current, true);\n            const resizedResult = resizeResults(result, dims);\n            const minConfidence = 0.05;\n            draw.drawDetections(canvasRef.current, resizedResult);\n            draw.drawFaceExpressions(canvasRef.current, resizedResult, minConfidence);\n\n            /////// expression capture ////////\n\n            // const captureEmotion =  () => {\n            // const expressions = result.expressions;\n            // const maxValue = Math.max(...Object.values(expressions));\n            // const emotion = Object.keys(expressions).filter(\n            //     item => expressions[item] === maxValue\n            //     );\n            // }\n\n            setEmotion(emotion[0]);\n            redirectToPage(emotion[0]);\n            \n            /////// expression capture ////////\n\n        }\n        // if (emotion !== undefined) {\n            setTimeout(() => startFaceDetection());\n        // }\n    };\n\n    useEffect(() => {\n        initModels();;\n    }, []);\n\n\n    return (\n        <ContainerComponent>\n            <CameraComponent videoRef={videoRef} onReady={startFaceDetection} />\n            <OverlayComponent>\n                <CanvasComponent canvasRef={canvasRef} />\n            </OverlayComponent>\n            <h1>Emotion: {emotion}</h1>\n        </ContainerComponent>\n    );\n};\n\nexport default FaceDetectionComponent;"]},"metadata":{},"sourceType":"module"}