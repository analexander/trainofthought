{"ast":null,"code":"import _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../../engine';\nimport { customGrad } from '../../gradients';\nimport { FusedDepthwiseConv2D } from '../../kernel_names';\nimport { makeTypesMatch } from '../../tensor_util';\nimport { convertToTensor } from '../../tensor_util_env';\nimport * as util from '../../util';\nimport { add } from '../add';\nimport * as broadcast_util from '../broadcast_util';\nimport * as conv_util from '../conv_util';\nimport { depthwiseConv2d as unfusedDepthwiseConv2d } from '../depthwise_conv2d';\nimport { depthwiseConv2dNativeBackpropFilter } from '../depthwise_conv2d_native_backprop_filter';\nimport { depthwiseConv2dNativeBackpropInput } from '../depthwise_conv2d_native_backprop_input';\nimport { applyActivation, getFusedBiasGradient, getFusedDyActivation, shouldFuse } from '../fused_util';\nimport { op } from '../operation';\nimport { reshape } from '../reshape';\n/**\n * Computes depthwise 2D convolution, optionally fused with adding a\n * bias and applying an activation.\n *\n * Given a 4D `input` array and a `filter` array of shape\n * `[filterHeight, filterWidth, inChannels, channelMultiplier]` containing\n * `inChannels` convolutional filters of depth 1, this op applies a\n * different filter to each input channel (expanding from 1 channel to\n * `channelMultiplier` channels for each), then concatenates the results\n * together. The output has `inChannels * channelMultiplier` channels.\n *\n * See\n * [https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d](\n *     https://www.tensorflow.org/api_docs/python/tf/nn/depthwise_conv2d)\n * for more details.\n *\n * @param obj An object with the following properties:\n * @param x The input tensor, of rank 4 or rank 3, of shape\n *     `[batch, height, width, inChannels]`. If rank 3, batch of 1 is\n * assumed.\n * @param filter The filter tensor, rank 4, of shape\n *     `[filterHeight, filterWidth, inChannels, channelMultiplier]`.\n * @param strides The strides of the convolution: `[strideHeight,\n * strideWidth]`. If strides is a single number, then `strideHeight ==\n * strideWidth`.\n * @param pad The type of padding algorithm.\n *   - `same` and stride 1: output will be of same size as input,\n *       regardless of filter size.\n *   - `valid`: output will be smaller than input if filter is larger\n *       than 1x1.\n *   - For more info, see this guide:\n *     [https://www.tensorflow.org/api_guides/python/nn#Convolution](\n *          https://www.tensorflow.org/api_guides/python/nn#Convolution)\n * @param dilations The dilation rates: `[dilationHeight, dilationWidth]`\n *     in which we sample input values across the height and width dimensions\n *     in atrous convolution. Defaults to `[1, 1]`. If `rate` is a single\n *     number, then `dilationHeight == dilationWidth`. If it is greater than\n *     1, then all values of `strides` must be 1.\n * @param dataFormat: An optional string from: \"NHWC\", \"NCHW\". Defaults to\n *     \"NHWC\". Specify the data format of the input and output data. With the\n *     default format \"NHWC\", the data is stored in the order of: [batch,\n *     height, width, channels]. Only \"NHWC\" is currently supported.\n * @param dimRoundingMode The rounding mode used when computing output\n *     dimensions if pad is a number. If none is provided, it will not round\n *     and error if the output is of fractional size.\n * @param bias Tensor to be added to the result.\n * @param activation Name of activation kernel (defaults to `linear`).\n * @param preluActivationWeights Tensor of prelu weights to be applied as part\n *     of a `prelu` activation, typically the same shape as `x`.\n */\n\nfunction fusedDepthwiseConv2d_(_ref) {\n  var x = _ref.x,\n      filter = _ref.filter,\n      strides = _ref.strides,\n      pad = _ref.pad,\n      _ref$dataFormat = _ref.dataFormat,\n      dataFormat = _ref$dataFormat === void 0 ? 'NHWC' : _ref$dataFormat,\n      _ref$dilations = _ref.dilations,\n      dilations = _ref$dilations === void 0 ? [1, 1] : _ref$dilations,\n      dimRoundingMode = _ref.dimRoundingMode,\n      bias = _ref.bias,\n      _ref$activation = _ref.activation,\n      activation = _ref$activation === void 0 ? 'linear' : _ref$activation,\n      preluActivationWeights = _ref.preluActivationWeights;\n\n  if (shouldFuse(ENGINE.state.gradientDepth, activation) === false) {\n    var result = unfusedDepthwiseConv2d(x, filter, strides, pad, dataFormat, dilations, dimRoundingMode);\n\n    if (bias != null) {\n      result = add(result, bias);\n    }\n\n    return applyActivation(result, activation, preluActivationWeights);\n  }\n\n  var $x = convertToTensor(x, 'x', 'depthwiseConv2d');\n  var $filter = convertToTensor(filter, 'filter', 'depthwiseConv2d');\n  var x4D = $x;\n  var reshapedTo4D = false;\n\n  if ($x.rank === 3) {\n    reshapedTo4D = true;\n    x4D = reshape($x, [1, $x.shape[0], $x.shape[1], $x.shape[2]]);\n  }\n\n  util.assert(x4D.rank === 4, function () {\n    return \"Error in fused depthwiseConv2d: input must be rank 4, but got \" + \"rank \".concat(x4D.rank, \".\");\n  });\n  util.assert($filter.rank === 4, function () {\n    return \"Error in fused depthwiseConv2d: filter must be rank 4, \" + \"but got rank \".concat($filter.rank, \".\");\n  });\n  util.assert(x4D.shape[3] === $filter.shape[2], function () {\n    return \"Error in fused depthwiseConv2d: number of input channels \" + \"(\".concat(x4D.shape[3], \") must match the inChannels dimension in \") + \"filter \".concat($filter.shape[2], \".\");\n  });\n\n  if (dilations == null) {\n    dilations = [1, 1];\n  }\n\n  util.assert(conv_util.eitherStridesOrDilationsAreOne(strides, dilations), function () {\n    return 'Error in fused depthwiseConv2d: Either strides or dilations must ' + \"be 1. Got strides \".concat(strides, \" and dilations '\").concat(dilations, \"'\");\n  });\n\n  if (dimRoundingMode != null) {\n    util.assert(util.isInt(pad), function () {\n      return \"Error in fused depthwiseConv2d: pad must be an integer when \" + \"using dimRoundingMode \".concat(dimRoundingMode, \" but got pad \").concat(pad, \".\");\n    });\n  }\n\n  var convInfo = conv_util.computeConv2DInfo(x4D.shape, $filter.shape, strides, dilations, pad, dimRoundingMode, true\n  /* depthwise */\n  );\n  var $bias;\n\n  if (bias != null) {\n    $bias = convertToTensor(bias, 'bias', 'fused conv2d');\n\n    var _makeTypesMatch = makeTypesMatch($bias, $x);\n\n    var _makeTypesMatch2 = _slicedToArray(_makeTypesMatch, 1);\n\n    $bias = _makeTypesMatch2[0];\n    broadcast_util.assertAndGetBroadcastShape(convInfo.outShape, $bias.shape);\n  }\n\n  var $preluActivationWeights;\n\n  if (preluActivationWeights != null) {\n    $preluActivationWeights = convertToTensor(preluActivationWeights, 'prelu weights', 'fused depthwiseConv2d');\n  }\n\n  var grad = function grad(dy, saved) {\n    util.assert(conv_util.tupleValuesAreOne(dilations), function () {\n      return 'Error in gradient of fused depthwiseConv2d: dilation rates ' + \"greater than 1 are not yet supported. Got dilations \" + \"'\".concat(dilations, \"'\");\n    });\n\n    var _saved = _slicedToArray(saved, 4),\n        $filter = _saved[0],\n        x4D = _saved[1],\n        y = _saved[2],\n        bias = _saved[3];\n\n    var dyActivation = getFusedDyActivation(dy, y, activation);\n    var xDer = depthwiseConv2dNativeBackpropInput(x4D.shape, dyActivation, $filter, strides, pad, dilations, dimRoundingMode);\n    var filterDer = depthwiseConv2dNativeBackpropFilter(x4D, dyActivation, $filter.shape, strides, pad, dilations, dimRoundingMode);\n\n    if (bias != null) {\n      var biasDer = getFusedBiasGradient($bias, dyActivation);\n      return [xDer, filterDer, biasDer];\n    }\n\n    return [xDer, filterDer];\n  };\n\n  var forward = function forward(backend) {\n    var res = backend.fusedDepthwiseConv2D({\n      input: x4D,\n      filter: $filter,\n      convInfo: convInfo,\n      bias: $bias,\n      activation: activation,\n      preluActivationWeights: $preluActivationWeights\n    });\n    return res;\n  };\n\n  var inputs = {\n    x: x4D,\n    filter: $filter,\n    bias: $bias,\n    preluActivationWeights: $preluActivationWeights\n  };\n  var attrs = {\n    strides: strides,\n    pad: pad,\n    dataFormat: dataFormat,\n    dilations: dilations,\n    dimRoundingMode: dimRoundingMode,\n    activation: activation\n  }; // Depending on the the params passed in we will have different number of\n  // inputs and thus a a different number of elements in the gradient.\n\n  if (bias == null) {\n    var customOp = customGrad(function (x4D, filter, save) {\n      var res = ENGINE.runKernelFunc(forward, inputs, null\n      /* grad */\n      , FusedDepthwiseConv2D, attrs);\n      save([filter, x4D, res]);\n\n      if (reshapedTo4D) {\n        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n      }\n\n      return {\n        value: res,\n        gradFunc: grad\n      };\n    });\n    return customOp(x4D, $filter);\n  } else {\n    var customOpWithBias = customGrad(function (x4D, filter, bias, save) {\n      var res = ENGINE.runKernelFunc(forward, inputs, null\n      /* grad */\n      , FusedDepthwiseConv2D, attrs);\n      save([filter, x4D, res, bias]);\n\n      if (reshapedTo4D) {\n        res = reshape(res, [res.shape[1], res.shape[2], res.shape[3]]);\n      }\n\n      return {\n        value: res,\n        gradFunc: grad\n      };\n    });\n    return customOpWithBias(x4D, $filter, $bias);\n  }\n}\n\nexport var depthwiseConv2d = op({\n  fusedDepthwiseConv2d_: fusedDepthwiseConv2d_\n});","map":null,"metadata":{},"sourceType":"module"}