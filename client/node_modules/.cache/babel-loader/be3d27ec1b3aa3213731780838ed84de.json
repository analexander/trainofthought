{"ast":null,"code":"import _toConsumableArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { tidy, util } from '@tensorflow/tfjs-core';\nimport { getNodeNameAndIndex, getParamValue, getTensor, getTensorsForCurrentContenxt, parseNodeName } from '../operations/executors/utils';\nimport { executeOp } from '../operations/operation_executor';\nimport { ExecutionContext } from './execution_context';\nimport { getExecutionSubgraph, getNodesInTopologicalOrder, isControlFlow } from './model_analysis';\nexport var GraphExecutor = /*#__PURE__*/function () {\n  /**\n   *\n   * @param graph Graph the model or function graph to be executed.\n   * @param parent When building function exector you need to set the parent\n   * executor. Since the weights and function executor maps are set at parant\n   * level, that function executor can access the function maps and weight maps\n   * through the parent.\n   */\n  function GraphExecutor(graph, parent) {\n    var _this = this;\n\n    _classCallCheck(this, GraphExecutor);\n\n    this.graph = graph;\n    this.parent = parent;\n    this.compiledMap = new Map();\n    this._weightMap = {};\n    this.SEPERATOR = ',';\n    this._functions = {};\n    this._functionExecutorMap = {};\n    this._outputs = graph.outputs;\n    this._inputs = graph.inputs;\n    this._initNodes = graph.initNodes;\n    this._signature = graph.signature;\n    this._functions = graph.functions; // create sub-graph executors\n\n    if (graph.functions != null) {\n      Object.keys(graph.functions).forEach(function (name) {\n        _this._functionExecutorMap[name] = new GraphExecutor(graph.functions[name], _this);\n      });\n    }\n  }\n\n  _createClass(GraphExecutor, [{\n    key: \"getCompilationKey\",\n    value: function getCompilationKey(inputs, outputs) {\n      var sortedInputs = inputs.map(function (node) {\n        return node.name;\n      }).sort();\n      var sortedOutputs = outputs.map(function (node) {\n        return node.name;\n      }).sort();\n      return sortedInputs.join(this.SEPERATOR) + '--' + sortedOutputs.join(this.SEPERATOR);\n    }\n    /**\n     * Compiles the inference graph and returns the minimal set of nodes that are\n     * required for execution, in the correct execution order.\n     */\n\n  }, {\n    key: \"compile\",\n    value: function compile(inputs, outputs) {\n      var executionInfo = getExecutionSubgraph(inputs, outputs, this.weightMap, this._initNodes);\n      var missingInputs = executionInfo.missingInputs,\n          dynamicNode = executionInfo.dynamicNode,\n          syncInputs = executionInfo.syncInputs;\n\n      if (dynamicNode != null) {\n        throw new Error(\"This execution contains the node '\".concat(dynamicNode.name, \"', which has \") + \"the dynamic op '\".concat(dynamicNode.op, \"'. Please use \") + \"model.executeAsync() instead. Alternatively, to avoid the \" + \"dynamic ops, specify the inputs [\".concat(syncInputs, \"]\"));\n      }\n\n      if (missingInputs.length > 0) {\n        var outNames = outputs.map(function (n) {\n          return n.name;\n        });\n        var inNames = Object.keys(inputs);\n        throw new Error(\"Cannot compute the outputs [\".concat(outNames, \"] from the provided inputs \") + \"[\".concat(inNames, \"]. Missing the following inputs: [\").concat(missingInputs, \"]\"));\n      }\n\n      return getNodesInTopologicalOrder(this.graph, this.weightMap, executionInfo);\n    }\n    /**\n     * Executes the inference for given input tensors.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model, if\n     * no outputs are specified, the default outputs of the model would be used.\n     * You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     */\n\n  }, {\n    key: \"execute\",\n    value: function execute(inputs, outputs) {\n      var _this2 = this;\n\n      inputs = this.mapInputs(inputs);\n      var names = Object.keys(inputs).sort();\n      this.checkInputs(inputs);\n      this.checkInputShapeAndType(inputs);\n      outputs = this.mapOutputs(outputs);\n      this.checkOutputs(outputs);\n      var inputNodes = names.map(function (name) {\n        return _this2.graph.nodes[parseNodeName(name)[0]];\n      });\n      var outputNodeNames = outputs.map(function (name) {\n        return parseNodeName(name)[0];\n      });\n      var outputNodes = outputNodeNames.map(function (name) {\n        return _this2.graph.nodes[name];\n      }); // If no outputs are specified, then use the default outputs of the model.\n\n      if (outputNodes.length === 0) {\n        outputNodes = this._outputs;\n      }\n\n      var compilationKey = this.getCompilationKey(inputNodes, outputNodes); // Do nothing if the compiled graph cache contains the input.\n\n      var orderedNodes = this.compiledMap.get(compilationKey);\n\n      if (orderedNodes == null) {\n        orderedNodes = this.compile(inputs, outputNodes);\n        this.compiledMap.set(compilationKey, orderedNodes);\n      }\n\n      var tensorArrayMap = {};\n      var tensorListMap = {};\n      return tidy(function () {\n        var context = new ExecutionContext(_this2.weightMap, tensorArrayMap, tensorListMap, _this2.functionExecutorMap);\n        var tensorsMap = Object.assign({}, _this2.weightMap);\n        Object.keys(inputs).forEach(function (name) {\n          var _parseNodeName = parseNodeName(name),\n              _parseNodeName2 = _slicedToArray(_parseNodeName, 2),\n              nodeName = _parseNodeName2[0],\n              index = _parseNodeName2[1];\n\n          var tensors = [];\n          tensors[index] = inputs[name];\n          tensorsMap[nodeName] = tensors;\n        });\n\n        var tensorsToKeep = _this2.getFrozenTensorIds(tensorsMap);\n\n        var intermediateTensorConsumerCount = {};\n\n        for (var i = 0; i < orderedNodes.length; i++) {\n          var node = orderedNodes[i];\n\n          if (!tensorsMap[node.name]) {\n            var tensors = executeOp(node, tensorsMap, context, _this2._resourceManager);\n\n            if (util.isPromise(tensors)) {\n              throw new Error(\"The execution of the op '\".concat(node.op, \"' returned a promise. \") + \"Please use model.executeAsync() instead.\");\n            }\n\n            tensorsMap[node.name] = tensors;\n\n            _this2.checkTensorForDisposal(node.name, node, tensorsMap, context, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount);\n          }\n        } // dispose the context for the root executor\n\n\n        if (_this2.parent == null) {\n          context.dispose(tensorsToKeep);\n        }\n\n        return outputs.map(function (name) {\n          return getTensor(name, tensorsMap, context);\n        });\n      });\n    }\n  }, {\n    key: \"getFrozenTensorIds\",\n    value: function getFrozenTensorIds(tensorMap) {\n      var ids = [].concat.apply([], Object.keys(tensorMap).map(function (key) {\n        return tensorMap[key];\n      }).map(function (tensors) {\n        return tensors.map(function (tensor) {\n          return tensor.id;\n        });\n      }));\n      return new Set(ids);\n    }\n  }, {\n    key: \"checkTensorForDisposal\",\n    value: function checkTensorForDisposal(nodeName, node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount) {\n      // Skip output nodes and any control flow nodes, since its dependency is\n      // tricky to track correctly.\n      if (node.category === 'control' || outputNames.indexOf(nodeName) !== -1) {\n        return;\n      }\n\n      tensorMap[nodeName].forEach(function (tensor) {\n        if (tensor != null) {\n          intermediateTensorConsumerCount[tensor.id] = (intermediateTensorConsumerCount[tensor.id] || 0) + node.children.length;\n        }\n      });\n      node.inputs.forEach(function (input) {\n        // Skip any control flow nodes, since its dependency is tricky to track\n        // correctly.\n        if (input.category !== 'control') {\n          var tensors = getTensorsForCurrentContenxt(input.name, tensorMap, context);\n\n          if (tensors != null) {\n            tensors.forEach(function (tensor) {\n              if (tensor && !tensorsToKeep.has(tensor.id)) {\n                var count = intermediateTensorConsumerCount[tensor.id];\n\n                if (count === 1) {\n                  tensor.dispose();\n                  delete intermediateTensorConsumerCount[tensor.id];\n                } else if (count != null) {\n                  // only intermediate nodes has count set, inputs and weights are\n                  // not.\n                  intermediateTensorConsumerCount[tensor.id]--;\n                }\n              }\n            });\n          }\n        }\n      });\n    }\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs output node name from the Tensorflow model, if no outputs\n     * are specified, the default outputs of the model would be used. You can\n     * inspect intermediate nodes of the model by adding them to the outputs\n     * array.\n     */\n\n  }, {\n    key: \"executeAsync\",\n    value: function () {\n      var _executeAsync2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(inputs, outputs) {\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                return _context.abrupt(\"return\", this._executeAsync(inputs, outputs));\n\n              case 1:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function executeAsync(_x, _x2) {\n        return _executeAsync2.apply(this, arguments);\n      }\n\n      return executeAsync;\n    }()\n    /**\n     * Executes the inference for given input tensors in Async fashion.\n     * @param inputs Tensor map for the model inputs, keyed by the input node\n     * names.\n     * @param outputs Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Optional. Flag for executing a function.\n     * @param tensorArrayMap Optional, global TensorArray map by id. Used for\n     * function execution.\n     * @param tensorArrayMap Optinal global TensorList map by id. Used for\n     * function execution.\n     */\n\n  }, {\n    key: \"_executeAsync\",\n    value: function () {\n      var _executeAsync3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(inputs, outputs) {\n        var isFunctionExecution,\n            tensorArrayMap,\n            tensorListMap,\n            context,\n            tensorMap,\n            results,\n            outputIds,\n            inputIds,\n            keepIds,\n            _args2 = arguments;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                isFunctionExecution = _args2.length > 2 && _args2[2] !== undefined ? _args2[2] : false;\n                tensorArrayMap = _args2.length > 3 && _args2[3] !== undefined ? _args2[3] : {};\n                tensorListMap = _args2.length > 4 && _args2[4] !== undefined ? _args2[4] : {};\n\n                if (!isFunctionExecution) {\n                  inputs = this.mapInputs(inputs);\n                  this.checkInputs(inputs);\n                  this.checkInputShapeAndType(inputs);\n                  outputs = this.mapOutputs(outputs);\n                  this.checkOutputs(outputs);\n                }\n\n                context = new ExecutionContext(this.weightMap, tensorArrayMap, tensorListMap, this.functionExecutorMap); // Graph with control flow op requires runtime evaluation of the execution\n                // order, while without control flow the execution order is pre-determined\n                // in the compile method.\n\n                _context2.next = 7;\n                return this.executeWithControlFlow(inputs, context, outputs, isFunctionExecution);\n\n              case 7:\n                tensorMap = _context2.sent;\n                results = outputs.map(function (name) {\n                  return getTensor(name, tensorMap, context);\n                }); // dispose all the intermediate tensors\n\n                outputIds = results.map(function (t) {\n                  return t.id;\n                });\n                inputIds = Object.keys(inputs).map(function (name) {\n                  return inputs[name].id;\n                });\n                keepIds = new Set([].concat(_toConsumableArray(outputIds), _toConsumableArray(inputIds), _toConsumableArray(this.weightIds)));\n                Object.keys(tensorMap).forEach(function (key) {\n                  var tensorArray = tensorMap[key];\n                  tensorArray.forEach(function (tensor) {\n                    if (tensor && !tensor.isDisposed && !keepIds.has(tensor.id)) {\n                      tensor.dispose();\n                    }\n                  });\n                }); // dispose the context for the root executor\n\n                if (this.parent == null) {\n                  context.dispose(keepIds);\n                }\n\n                return _context2.abrupt(\"return\", results);\n\n              case 15:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function _executeAsync(_x3, _x4) {\n        return _executeAsync3.apply(this, arguments);\n      }\n\n      return _executeAsync;\n    }()\n  }, {\n    key: \"executeFunctionAsync\",\n    value: function () {\n      var _executeFunctionAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(inputs, tensorArrayMap, tensorListMap) {\n        var _this3 = this;\n\n        var mappedInputs;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                mappedInputs = inputs.reduce(function (map, tensor, index) {\n                  map[_this3.inputs[index].name] = tensor;\n                  return map;\n                }, {});\n                return _context3.abrupt(\"return\", this._executeAsync(mappedInputs, this.outputNodes, true, tensorArrayMap, tensorListMap));\n\n              case 2:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function executeFunctionAsync(_x5, _x6, _x7) {\n        return _executeFunctionAsync.apply(this, arguments);\n      }\n\n      return executeFunctionAsync;\n    }()\n    /**\n     * When there are control flow nodes in the graph, the graph execution use\n     * ExecutionContext to keep track of the frames and loop iterators.\n     * @param inputs placeholder tensors for the graph.\n     * @param context the execution context object for current execution.\n     * @param outputNames Optional. output node name from the Tensorflow model,\n     * if no outputs are specified, the default outputs of the model would be\n     * used. You can inspect intermediate nodes of the model by adding them to the\n     * outputs array.\n     * @param isFunctionExecution Flag for executing a function.\n     */\n\n  }, {\n    key: \"executeWithControlFlow\",\n    value: function () {\n      var _executeWithControlFlow = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(inputs, context, outputNames, isFunctionExecution) {\n        var _this4 = this;\n\n        var names, inputNodes, outputNodeNames, outputNodes, _getExecutionSubgraph, usedNodes, missingInputs, dynamicNode, syncInputs, stack, tensorsMap, intermediateTensorConsumerCount, tensorsToKeep, added, promises, missingOutputs, alternativeMsg;\n\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                names = Object.keys(inputs);\n                inputNodes = names.map(function (name) {\n                  return _this4.graph.nodes[parseNodeName(name)[0]];\n                });\n                outputNodeNames = outputNames.map(function (name) {\n                  return parseNodeName(name)[0];\n                });\n                outputNodes = outputNodeNames.map(function (name) {\n                  return _this4.graph.nodes[name];\n                }); // If no outputs are specified, then use the default outputs of the model.\n\n                if (outputNodes.length === 0) {\n                  outputNodes = this._outputs;\n                }\n\n                _getExecutionSubgraph = getExecutionSubgraph(inputs, outputNodes, this.weightMap, this._initNodes), usedNodes = _getExecutionSubgraph.usedNodes, missingInputs = _getExecutionSubgraph.missingInputs, dynamicNode = _getExecutionSubgraph.dynamicNode, syncInputs = _getExecutionSubgraph.syncInputs; // First nodes to execute include inputNodes, weights, and initNodes.\n\n                stack = [].concat(_toConsumableArray(inputNodes), _toConsumableArray(this.graph.weights), _toConsumableArray(this._initNodes || [])).map(function (node) {\n                  return {\n                    node: node,\n                    contexts: context.currentContext\n                  };\n                });\n                tensorsMap = Object.assign({}, this.weightMap);\n                Object.keys(inputs).forEach(function (name) {\n                  var _parseNodeName3 = parseNodeName(name),\n                      _parseNodeName4 = _slicedToArray(_parseNodeName3, 2),\n                      nodeName = _parseNodeName4[0],\n                      index = _parseNodeName4[1];\n\n                  var tensors = [];\n                  tensors[index] = inputs[name];\n                  tensorsMap[nodeName] = tensors;\n                });\n                intermediateTensorConsumerCount = {};\n                tensorsToKeep = this.getFrozenTensorIds(tensorsMap);\n                added = {};\n\n              case 12:\n                if (!(stack.length > 0)) {\n                  _context4.next = 18;\n                  break;\n                }\n\n                promises = this.processStack(inputNodes, stack, context, tensorsMap, added, tensorsToKeep, outputNodeNames, intermediateTensorConsumerCount, usedNodes);\n                _context4.next = 16;\n                return Promise.all(promises);\n\n              case 16:\n                _context4.next = 12;\n                break;\n\n              case 18:\n                if (dynamicNode == null && !isFunctionExecution) {\n                  console.warn(\"This model execution did not contain any nodes with control flow \" + \"or dynamic output shapes. You can use model.execute() instead.\");\n                }\n\n                missingOutputs = outputNodes.filter(function (node) {\n                  return !isControlFlow(node) && !getTensor(node.name, tensorsMap, context);\n                }).map(function (node) {\n                  return node.name;\n                });\n\n                if (!(missingOutputs.length > 0)) {\n                  _context4.next = 24;\n                  break;\n                }\n\n                alternativeMsg = '';\n\n                if (dynamicNode != null) {\n                  alternativeMsg = \"Alternatively, to avoid the dynamic ops, use model.execute() \" + \"and specify the inputs [\".concat(syncInputs, \"]\");\n                }\n\n                throw new Error(\"Cannot compute the outputs [\".concat(missingOutputs, \"] from the provided \") + \"inputs [\".concat(names, \"]. Consider providing the following inputs: \") + \"[\".concat(missingInputs, \"]. \").concat(alternativeMsg));\n\n              case 24:\n                return _context4.abrupt(\"return\", tensorsMap);\n\n              case 25:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function executeWithControlFlow(_x8, _x9, _x10, _x11) {\n        return _executeWithControlFlow.apply(this, arguments);\n      }\n\n      return executeWithControlFlow;\n    }()\n  }, {\n    key: \"processStack\",\n    value: function processStack(inputNodes, stack, context, tensorMap, added, tensorsToKeep, outputNames, intermediateTensorConsumerCount, usedNodes) {\n      var _this5 = this;\n\n      var promises = [];\n\n      var _loop = function _loop() {\n        var item = stack.pop();\n        context.currentContext = item.contexts;\n        var nodeName = ''; // The tensor of the Enter op with isConstant set should be set\n        // in the parent scope, so it will be available as constant for the\n        // whole loop.\n\n        if (item.node.op === 'Enter' && getParamValue('isConstant', item.node, tensorMap, context)) {\n          var _getNodeNameAndIndex = getNodeNameAndIndex(item.node.name, context);\n\n          var _getNodeNameAndIndex2 = _slicedToArray(_getNodeNameAndIndex, 1);\n\n          nodeName = _getNodeNameAndIndex2[0];\n        } // only process nodes that are not in the tensorMap yet, this include\n        // inputNodes and internal initNodes.\n\n\n        if (tensorMap[item.node.name] == null) {\n          var tensors = executeOp(item.node, tensorMap, context, _this5._resourceManager);\n\n          if (!nodeName) {\n            var _getNodeNameAndIndex3 = getNodeNameAndIndex(item.node.name, context);\n\n            var _getNodeNameAndIndex4 = _slicedToArray(_getNodeNameAndIndex3, 1);\n\n            nodeName = _getNodeNameAndIndex4[0];\n          }\n\n          var currentContext = context.currentContext;\n\n          if (util.isPromise(tensors)) {\n            promises.push(tensors.then(function (t) {\n              tensorMap[nodeName] = t;\n              context.currentContext = currentContext;\n\n              _this5.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n\n              _this5.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n\n              return t;\n            }));\n          } else {\n            tensorMap[nodeName] = tensors;\n\n            _this5.checkTensorForDisposal(nodeName, item.node, tensorMap, context, tensorsToKeep, outputNames, intermediateTensorConsumerCount);\n\n            _this5.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n          }\n        } else {\n          _this5.processChildNodes(item.node, stack, context, tensorMap, added, usedNodes);\n        }\n      };\n\n      while (stack.length > 0) {\n        _loop();\n      }\n\n      return promises;\n    }\n  }, {\n    key: \"processChildNodes\",\n    value: function processChildNodes(node, stack, context, tensorMap, added, usedNodes) {\n      node.children.forEach(function (childNode) {\n        var _getNodeNameAndIndex5 = getNodeNameAndIndex(childNode.name, context),\n            _getNodeNameAndIndex6 = _slicedToArray(_getNodeNameAndIndex5, 1),\n            nodeName = _getNodeNameAndIndex6[0];\n\n        if (added[nodeName] || !usedNodes.has(childNode.name)) {\n          return;\n        } // Merge op can be pushed if any of its inputs has value.\n\n\n        if (childNode.op === 'Merge') {\n          if (childNode.inputNames.some(function (name) {\n            return !!getTensor(name, tensorMap, context);\n          })) {\n            added[nodeName] = true;\n            stack.push({\n              contexts: context.currentContext,\n              node: childNode\n            });\n          }\n        } else // Otherwise all inputs must to have value.\n          if (childNode.inputNames.every(function (name) {\n            return !!getTensor(name, tensorMap, context);\n          })) {\n            added[nodeName] = true;\n            stack.push({\n              contexts: context.currentContext,\n              node: childNode\n            });\n          }\n      });\n    }\n    /**\n     * Releases the memory used by the weight tensors.\n     */\n\n  }, {\n    key: \"dispose\",\n    value: function dispose() {\n      var _this6 = this;\n\n      Object.keys(this.weightMap).forEach(function (key) {\n        return _this6.weightMap[key].forEach(function (tensor) {\n          return tensor.dispose();\n        });\n      });\n    }\n  }, {\n    key: \"checkInputShapeAndType\",\n    value: function checkInputShapeAndType(inputs) {\n      var _this7 = this;\n\n      Object.keys(inputs).forEach(function (name) {\n        var input = inputs[name];\n\n        var _parseNodeName5 = parseNodeName(name),\n            _parseNodeName6 = _slicedToArray(_parseNodeName5, 1),\n            nodeName = _parseNodeName6[0];\n\n        var node = _this7.graph.nodes[nodeName];\n\n        if (node.attrParams['shape'] && node.attrParams['shape'].value) {\n          var shape = node.attrParams['shape'].value;\n          var match = shape.length === input.shape.length && input.shape.every(function (dim, index) {\n            return shape[index] === -1 || shape[index] === dim;\n          });\n          util.assert(match, function () {\n            return \"The shape of dict['\".concat(node.name, \"'] provided in \") + \"model.execute(dict) must be [\".concat(shape, \"], but was \") + \"[\".concat(input.shape, \"]\");\n          });\n        }\n\n        if (node.attrParams['dtype'] && node.attrParams['dtype'].value) {\n          util.assert(input.dtype === node.attrParams['dtype'].value, function () {\n            return \"The dtype of dict['\".concat(node.name, \"'] provided in \") + \"model.execute(dict) must be \" + \"\".concat(node.attrParams['dtype'].value, \", but was \").concat(input.dtype);\n          });\n        }\n      });\n    }\n  }, {\n    key: \"mapInputs\",\n    value: function mapInputs(inputs) {\n      var result = {};\n\n      for (var inputName in inputs) {\n        if (this._signature != null && this._signature.inputs != null && this._signature.inputs[inputName] != null) {\n          var tensor = this._signature.inputs[inputName];\n          result[tensor.name] = inputs[inputName];\n        } else {\n          result[inputName] = inputs[inputName];\n        }\n      }\n\n      return result;\n    }\n  }, {\n    key: \"checkInputs\",\n    value: function checkInputs(inputs) {\n      var _this8 = this;\n\n      var notInGraph = Object.keys(inputs).filter(function (name) {\n        var _parseNodeName7 = parseNodeName(name),\n            _parseNodeName8 = _slicedToArray(_parseNodeName7, 1),\n            nodeName = _parseNodeName8[0];\n\n        return _this8.graph.nodes[nodeName] == null;\n      });\n\n      if (notInGraph.length > 0) {\n        throw new Error(\"The dict provided in model.execute(dict) has \" + \"keys: [\".concat(notInGraph, \"] that are not part of graph\"));\n      }\n    }\n  }, {\n    key: \"mapOutputs\",\n    value: function mapOutputs(outputs) {\n      var _this9 = this;\n\n      return outputs.map(function (name) {\n        if (_this9._signature != null && _this9._signature.outputs != null && _this9._signature.outputs[name] != null) {\n          var tensor = _this9._signature.outputs[name];\n          return tensor.name;\n        }\n\n        return name;\n      }, {});\n    }\n  }, {\n    key: \"checkOutputs\",\n    value: function checkOutputs(outputs) {\n      var _this10 = this;\n\n      outputs.forEach(function (name) {\n        var _parseNodeName9 = parseNodeName(name),\n            _parseNodeName10 = _slicedToArray(_parseNodeName9, 1),\n            normalizedName = _parseNodeName10[0];\n\n        if (!_this10.graph.nodes[normalizedName]) {\n          throw new Error(\"The output '\".concat(name, \"' is not found in the graph\"));\n        }\n      });\n    }\n  }, {\n    key: \"weightIds\",\n    get: function get() {\n      return this.parent ? this.parent.weightIds : this._weightIds;\n    }\n  }, {\n    key: \"functionExecutorMap\",\n    get: function get() {\n      return this.parent ? this.parent.functionExecutorMap : this._functionExecutorMap;\n    }\n  }, {\n    key: \"weightMap\",\n    get: function get() {\n      return this.parent ? this.parent.weightMap : this._weightMap;\n    },\n    set: function set(weightMap) {\n      var _ref;\n\n      var weightIds = Object.keys(weightMap).map(function (key) {\n        return weightMap[key].map(function (tensor) {\n          return tensor.id;\n        });\n      });\n      this._weightIds = (_ref = []).concat.apply(_ref, _toConsumableArray(weightIds));\n      this._weightMap = weightMap;\n    }\n    /**\n     * Set `ResourceManager` shared by executors of a model.\n     * @param resourceManager: `ResourceManager` of the `GraphModel`.\n     */\n\n  }, {\n    key: \"resourceManager\",\n    set: function set(resourceManager) {\n      this._resourceManager = resourceManager;\n    }\n  }, {\n    key: \"inputs\",\n    get: function get() {\n      return this._inputs.map(function (node) {\n        return {\n          name: node.name,\n          shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n          dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n        };\n      });\n    }\n  }, {\n    key: \"outputs\",\n    get: function get() {\n      return this._outputs.map(function (node) {\n        return {\n          name: node.name,\n          shape: node.attrParams['shape'] ? node.attrParams['shape'].value : undefined,\n          dtype: node.attrParams['dtype'] ? node.attrParams['dtype'].value : undefined\n        };\n      });\n    }\n  }, {\n    key: \"inputNodes\",\n    get: function get() {\n      return this._inputs.map(function (node) {\n        return node.signatureKey || node.name;\n      });\n    }\n  }, {\n    key: \"outputNodes\",\n    get: function get() {\n      return this._outputs.map(function (node) {\n        var name = node.signatureKey || node.name;\n        return node.defaultOutput ? \"\".concat(name, \":\").concat(node.defaultOutput) : name;\n      });\n    }\n  }, {\n    key: \"functions\",\n    get: function get() {\n      var _this11 = this;\n\n      return Object.keys(this._functions).reduce(function (map, key) {\n        map[key] = _this11._functions[key].signature;\n        return map;\n      }, {});\n    }\n  }]);\n\n  return GraphExecutor;\n}();","map":null,"metadata":{},"sourceType":"module"}