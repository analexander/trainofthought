{"ast":null,"code":"/*import React, { useEffect, useRef } from \"react\";\nimport { CameraComponent } from \"../CameraComponent/CameraComponent\";\nimport CanvasComponent from \"../CanvasComponent/CanvasComponent\";\nimport styled from \"styled-components\";\nimport {\n    nets, loadFaceExpressionModel, matchDimensions,\n    resizeResults, detectSingleFace, TinyFaceDetectorOptions,\n    draw\n} from \"face-api.min.js\";\n\nconst ContainerComponent = styled.div`\n    position: relative;\n`;\n\nconst OverlayComponent = styled.div`\n    position: absolute;\n    top: 0;\n    left: 0;\n`;\n\nconst FaceDetectionComponent = () => {\n    const videoRef = useRef();\n    const canvasRef = useRef();\n\n    const initModels = async () => {\n        await nets.tinyFaceDetector.load(\"/models/\");\n        await loadFaceExpressionModel(\"/models/\");\n    }\n\n    const startFaceDetection = async () => {\n        const options = new TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });\n        const result = await detectSingleFace(videoRef.current, options).withFaceExpressions();\n        if (result) {\n            const dims = matchDimensions(canvasRef.current, videoRef.current, true);\n            const resizedResult = resizeResults(result, dims);\n            const minConfidence = 0.05;\n            draw.drawDetections(canvasRef.current, resizedResult);\n            draw.drawFaceExpressions(canvasRef.current, resizedResult, minConfidence);\n\n///// expression capture ////////\n\n            const expressions = result.expressions;\n            const maxValue = Math.max(...Object.values(expressions));\n            const emotion = Object.keys(expressions).filter(\n                item => expressions[item] === maxValue\n            );\n            setTimeout(() => {\n                console.log(emotion[0])\n              }, 5000);\n\n ///// expression capture ////////\n\n        }\n        setTimeout(() => startFaceDetection());\n    };\n\n    useEffect(() => {\n        initModels();\n    }, []);\n\n\n    return (\n        <ContainerComponent>\n            <CameraComponent videoRef={videoRef} onReady={startFaceDetection} />\n            <OverlayComponent>\n                <CanvasComponent canvasRef={canvasRef} />\n            </OverlayComponent>\n        </ContainerComponent>\n    );\n};\n\nexport default FaceDetectionComponent;*/","map":{"version":3,"sources":["/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/FaceDetectionComponent/FaceDetectionComponent.js"],"names":[],"mappings":"AAAA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA;AACA","sourcesContent":["/*import React, { useEffect, useRef } from \"react\";\nimport { CameraComponent } from \"../CameraComponent/CameraComponent\";\nimport CanvasComponent from \"../CanvasComponent/CanvasComponent\";\nimport styled from \"styled-components\";\nimport {\n    nets, loadFaceExpressionModel, matchDimensions,\n    resizeResults, detectSingleFace, TinyFaceDetectorOptions,\n    draw\n} from \"face-api.min.js\";\n\nconst ContainerComponent = styled.div`\n    position: relative;\n`;\n\nconst OverlayComponent = styled.div`\n    position: absolute;\n    top: 0;\n    left: 0;\n`;\n\nconst FaceDetectionComponent = () => {\n    const videoRef = useRef();\n    const canvasRef = useRef();\n\n    const initModels = async () => {\n        await nets.tinyFaceDetector.load(\"/models/\");\n        await loadFaceExpressionModel(\"/models/\");\n    }\n\n    const startFaceDetection = async () => {\n        const options = new TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });\n        const result = await detectSingleFace(videoRef.current, options).withFaceExpressions();\n        if (result) {\n            const dims = matchDimensions(canvasRef.current, videoRef.current, true);\n            const resizedResult = resizeResults(result, dims);\n            const minConfidence = 0.05;\n            draw.drawDetections(canvasRef.current, resizedResult);\n            draw.drawFaceExpressions(canvasRef.current, resizedResult, minConfidence);\n\n///// expression capture ////////\n\n            const expressions = result.expressions;\n            const maxValue = Math.max(...Object.values(expressions));\n            const emotion = Object.keys(expressions).filter(\n                item => expressions[item] === maxValue\n            );\n            setTimeout(() => {\n                console.log(emotion[0])\n              }, 5000);\n\n ///// expression capture ////////\n\n        }\n        setTimeout(() => startFaceDetection());\n    };\n\n    useEffect(() => {\n        initModels();\n    }, []);\n\n\n    return (\n        <ContainerComponent>\n            <CameraComponent videoRef={videoRef} onReady={startFaceDetection} />\n            <OverlayComponent>\n                <CanvasComponent canvasRef={canvasRef} />\n            </OverlayComponent>\n        </ContainerComponent>\n    );\n};\n\nexport default FaceDetectionComponent;*/"]},"metadata":{},"sourceType":"module"}