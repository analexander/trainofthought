{"ast":null,"code":"import _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\nimport _toConsumableArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/toConsumableArray\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _get from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/get\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\n\n/**\n * @license\n * Copyright 2020 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\nvar __rest = this && this.__rest || function (s, e) {\n  var t = {};\n\n  for (var p in s) {\n    if (Object.prototype.hasOwnProperty.call(s, p) && e.indexOf(p) < 0) t[p] = s[p];\n  }\n\n  if (s != null && typeof Object.getOwnPropertySymbols === \"function\") for (var i = 0, p = Object.getOwnPropertySymbols(s); i < p.length; i++) {\n    if (e.indexOf(p[i]) < 0 && Object.prototype.propertyIsEnumerable.call(s, p[i])) t[p[i]] = s[p[i]];\n  }\n  return t;\n};\n\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { util } from '@tensorflow/tfjs-core';\nimport * as K from '../backend/tfjs_backend';\nimport { checkDataFormat, checkPaddingMode } from '../common';\nimport { InputSpec } from '../engine/topology';\nimport { AttributeError, NotImplementedError, ValueError } from '../errors';\nimport { Initializer } from '../initializers';\nimport { convOutputLength, normalizeArray } from '../utils/conv_utils';\nimport { assertPositiveInteger } from '../utils/generic_utils';\nimport { getExactlyOneShape } from '../utils/types_utils';\nimport { generateDropoutMask, LSTMCell, RNN, RNNCell } from './recurrent';\n\nvar ConvRNN2DCell = /*#__PURE__*/function (_RNNCell) {\n  _inherits(ConvRNN2DCell, _RNNCell);\n\n  function ConvRNN2DCell() {\n    _classCallCheck(this, ConvRNN2DCell);\n\n    return _possibleConstructorReturn(this, _getPrototypeOf(ConvRNN2DCell).apply(this, arguments));\n  }\n\n  return ConvRNN2DCell;\n}(RNNCell);\n/**\n * Base class for convolutional-recurrent layers.\n */\n\n\nvar ConvRNN2D = /*#__PURE__*/function (_RNN) {\n  _inherits(ConvRNN2D, _RNN);\n\n  function ConvRNN2D(args) {\n    var _this;\n\n    _classCallCheck(this, ConvRNN2D);\n\n    if (args.unroll) {\n      throw new NotImplementedError('Unrolling is not possible with convolutional RNNs.');\n    }\n\n    if (Array.isArray(args.cell)) {\n      throw new NotImplementedError('It is not possible at the moment to stack convolutional cells.');\n    }\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(ConvRNN2D).call(this, args));\n    _this.inputSpec = [new InputSpec({\n      ndim: 5\n    })];\n    return _this;\n  }\n\n  _createClass(ConvRNN2D, [{\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this2 = this;\n\n      return tfc.tidy(function () {\n        if (_this2.cell.dropoutMask != null) {\n          tfc.dispose(_this2.cell.dropoutMask);\n          _this2.cell.dropoutMask = null;\n        }\n\n        if (_this2.cell.recurrentDropoutMask != null) {\n          tfc.dispose(_this2.cell.recurrentDropoutMask);\n          _this2.cell.recurrentDropoutMask = null;\n        }\n\n        if (kwargs && kwargs['constants']) {\n          throw new ValueError('ConvRNN2D cell does not support constants');\n        }\n\n        var mask = kwargs == null ? null : kwargs['mask'];\n        var training = kwargs == null ? null : kwargs['training'];\n        var initialState = kwargs == null ? null : kwargs['initialState'];\n        return _get(_getPrototypeOf(ConvRNN2D.prototype), \"call\", _this2).call(_this2, inputs, {\n          mask: mask,\n          training: training,\n          initialState: initialState\n        });\n      });\n    }\n  }, {\n    key: \"computeOutputShape\",\n    value: function computeOutputShape(inputShape) {\n      var outShape = this.computeSingleOutputShape(inputShape);\n\n      if (!this.returnSequences) {\n        outShape = [outShape[0]].concat(_toConsumableArray(outShape.slice(2)));\n      }\n\n      if (this.returnState) {\n        outShape = [outShape].concat(_toConsumableArray(Array(2).fill([inputShape[0]].concat(_toConsumableArray(outShape.slice(-3))))));\n      }\n\n      return outShape;\n    }\n  }, {\n    key: \"getInitialState\",\n    value: function getInitialState(inputs) {\n      var _this3 = this;\n\n      return tfc.tidy(function () {\n        var stateSize = _this3.cell.stateSize;\n        var inputShape = inputs.shape;\n\n        var outputShape = _this3.computeSingleOutputShape(inputShape);\n\n        var stateShape = [outputShape[0]].concat(_toConsumableArray(outputShape.slice(2)));\n        var initialState = tfc.zeros(stateShape);\n\n        if (Array.isArray(stateSize)) {\n          return Array(stateSize.length).fill(initialState);\n        }\n\n        return [initialState];\n      });\n    }\n  }, {\n    key: \"resetStates\",\n    value: function resetStates(states) {\n      var _this4 = this;\n\n      var training = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : false;\n      tfc.tidy(function () {\n        if (!_this4.stateful) {\n          throw new AttributeError('Cannot call resetStates() on an RNN Layer that is not stateful.');\n        }\n\n        var inputShape = _this4.inputSpec[0].shape;\n\n        var outputShape = _this4.computeSingleOutputShape(inputShape);\n\n        var stateShape = [outputShape[0]].concat(_toConsumableArray(outputShape.slice(2)));\n        var batchSize = inputShape[0];\n\n        if (batchSize == null) {\n          throw new ValueError('If an RNN is stateful, it needs to know its batch size. Specify ' + 'the batch size of your input tensors: \\n' + '- If using a Sequential model, specify the batch size by ' + 'passing a `batchInputShape` option to your first layer.\\n' + '- If using the functional API, specify the batch size by ' + 'passing a `batchShape` option to your Input layer.');\n        } // Initialize state if null.\n\n\n        if (_this4.getStates() == null) {\n          if (Array.isArray(_this4.cell.stateSize)) {\n            _this4.states_ = _this4.cell.stateSize.map(function () {\n              return tfc.zeros(stateShape);\n            });\n          } else {\n            _this4.states_ = [tfc.zeros(stateShape)];\n          }\n        } else if (states == null) {\n          // Dispose old state tensors.\n          tfc.dispose(_this4.states_); // For stateful RNNs, fully dispose kept old states.\n\n          if (_this4.keptStates != null) {\n            tfc.dispose(_this4.keptStates);\n            _this4.keptStates = [];\n          }\n\n          if (Array.isArray(_this4.cell.stateSize)) {\n            _this4.states_ = _this4.cell.stateSize.map(function () {\n              return tfc.zeros(stateShape);\n            });\n          } else {\n            _this4.states_[0] = tfc.zeros(stateShape);\n          }\n        } else {\n          if (!Array.isArray(states)) {\n            states = [states];\n          }\n\n          if (states.length !== _this4.states_.length) {\n            throw new ValueError(\"Layer \".concat(_this4.name, \" expects \").concat(_this4.states_.length, \" state(s), \") + \"but it received \".concat(states.length, \" state value(s). Input \") + \"received: \".concat(states));\n          }\n\n          if (training) {\n            // Store old state tensors for complete disposal later, i.e., during\n            // the next no-arg call to this method. We do not dispose the old\n            // states immediately because that BPTT (among other things) require\n            // them.\n            _this4.keptStates.push(_this4.states_.slice());\n          } else {\n            tfc.dispose(_this4.states_);\n          }\n\n          for (var index = 0; index < _this4.states_.length; ++index) {\n            var value = states[index];\n            var expectedShape = stateShape;\n\n            if (!util.arraysEqual(value.shape, expectedShape)) {\n              throw new ValueError(\"State \".concat(index, \" is incompatible with layer \").concat(_this4.name, \": \") + \"expected shape=\".concat(expectedShape, \", received shape=\").concat(value.shape));\n            }\n\n            _this4.states_[index] = value;\n          }\n        }\n\n        _this4.states_ = _this4.states_.map(function (state) {\n          return tfc.keep(state.clone());\n        });\n      });\n    }\n  }, {\n    key: \"computeSingleOutputShape\",\n    value: function computeSingleOutputShape(inputShape) {\n      var _this$cell = this.cell,\n          dataFormat = _this$cell.dataFormat,\n          filters = _this$cell.filters,\n          kernelSize = _this$cell.kernelSize,\n          padding = _this$cell.padding,\n          strides = _this$cell.strides,\n          dilationRate = _this$cell.dilationRate;\n      var isChannelsFirst = dataFormat === 'channelsFirst';\n      var h = inputShape[isChannelsFirst ? 3 : 2];\n      var w = inputShape[isChannelsFirst ? 4 : 3];\n      var hOut = convOutputLength(h, kernelSize[0], padding, strides[0], dilationRate[0]);\n      var wOut = convOutputLength(w, kernelSize[1], padding, strides[1], dilationRate[1]);\n      var outShape = [].concat(_toConsumableArray(inputShape.slice(0, 2)), _toConsumableArray(isChannelsFirst ? [filters, hOut, wOut] : [hOut, wOut, filters]));\n      return outShape;\n    }\n  }]);\n\n  return ConvRNN2D;\n}(RNN);\n/** @nocollapse */\n\n\nConvRNN2D.className = 'ConvRNN2D';\nexport var ConvLSTM2DCell = /*#__PURE__*/function (_LSTMCell) {\n  _inherits(ConvLSTM2DCell, _LSTMCell);\n\n  function ConvLSTM2DCell(args) {\n    var _this5;\n\n    _classCallCheck(this, ConvLSTM2DCell);\n\n    var filters = args.filters,\n        kernelSize = args.kernelSize,\n        strides = args.strides,\n        padding = args.padding,\n        dataFormat = args.dataFormat,\n        dilationRate = args.dilationRate;\n    _this5 = _possibleConstructorReturn(this, _getPrototypeOf(ConvLSTM2DCell).call(this, Object.assign({}, args, {\n      units: filters\n    })));\n    _this5.filters = filters;\n    assertPositiveInteger(_this5.filters, 'filters');\n    _this5.kernelSize = normalizeArray(kernelSize, 2, 'kernelSize');\n\n    _this5.kernelSize.forEach(function (size) {\n      return assertPositiveInteger(size, 'kernelSize');\n    });\n\n    _this5.strides = normalizeArray(strides || 1, 2, 'strides');\n\n    _this5.strides.forEach(function (stride) {\n      return assertPositiveInteger(stride, 'strides');\n    });\n\n    _this5.padding = padding || 'valid';\n    checkPaddingMode(_this5.padding);\n    _this5.dataFormat = dataFormat || 'channelsLast';\n    checkDataFormat(_this5.dataFormat);\n    _this5.dilationRate = normalizeArray(dilationRate || 1, 2, 'dilationRate');\n\n    _this5.dilationRate.forEach(function (rate) {\n      return assertPositiveInteger(rate, 'dilationRate');\n    });\n\n    return _this5;\n  }\n\n  _createClass(ConvLSTM2DCell, [{\n    key: \"build\",\n    value: function build(inputShape) {\n      var _a;\n\n      inputShape = getExactlyOneShape(inputShape);\n      var channelAxis = this.dataFormat === 'channelsFirst' ? 1 : inputShape.length - 1;\n\n      if (inputShape[channelAxis] == null) {\n        throw new ValueError(\"The channel dimension of the input should be defined. \" + \"Found \".concat(inputShape[channelAxis]));\n      }\n\n      var inputDim = inputShape[channelAxis];\n      var numOfKernels = 4;\n      var kernelShape = this.kernelSize.concat([inputDim, this.filters * numOfKernels]);\n      this.kernel = this.addWeight('kernel', kernelShape, null, this.kernelInitializer, this.kernelRegularizer, true, this.kernelConstraint);\n      var recurrentKernelShape = this.kernelSize.concat([this.filters, this.filters * numOfKernels]);\n      this.recurrentKernel = this.addWeight('recurrent_kernel', recurrentKernelShape, null, this.recurrentInitializer, this.recurrentRegularizer, true, this.recurrentConstraint);\n\n      if (this.useBias) {\n        var biasInitializer;\n\n        if (this.unitForgetBias) {\n          var init = this.biasInitializer;\n          var filters = this.filters;\n          biasInitializer = new (_a = /*#__PURE__*/function (_Initializer) {\n            _inherits(CustomInit, _Initializer);\n\n            function CustomInit() {\n              _classCallCheck(this, CustomInit);\n\n              return _possibleConstructorReturn(this, _getPrototypeOf(CustomInit).apply(this, arguments));\n            }\n\n            _createClass(CustomInit, [{\n              key: \"apply\",\n              value: function apply(shape, dtype) {\n                var biasI = init.apply([filters]);\n                var biasF = tfc.ones([filters]);\n                var biasCAndO = init.apply([filters * 2]);\n                return K.concatenate([biasI, biasF, biasCAndO]);\n              }\n            }]);\n\n            return CustomInit;\n          }(Initializer),\n          /** @nocollapse */\n          _a.className = 'CustomInit', _a)();\n        } else {\n          biasInitializer = this.biasInitializer;\n        }\n\n        this.bias = this.addWeight('bias', [this.filters * numOfKernels], null, biasInitializer, this.biasRegularizer, true, this.biasConstraint);\n      }\n\n      this.built = true;\n    }\n  }, {\n    key: \"call\",\n    value: function call(inputs, kwargs) {\n      var _this6 = this;\n\n      return tfc.tidy(function () {\n        if (inputs.length !== 3) {\n          throw new ValueError(\"ConvLSTM2DCell expects 3 input Tensors (inputs, h, c), got \" + \"\".concat(inputs.length, \".\"));\n        }\n\n        var training = kwargs['training'] || false;\n        var x = inputs[0]; // Current input\n\n        var hTMinus1 = inputs[1]; // Previous memory state.\n\n        var cTMinus1 = inputs[2]; // Previous carry state.\n\n        var numOfKernels = 4;\n\n        if (0 < _this6.dropout && _this6.dropout < 1 && _this6.dropoutMask == null) {\n          _this6.dropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(x);\n            },\n            rate: _this6.dropout,\n            training: training,\n            count: numOfKernels\n          });\n        }\n\n        var dropoutMask = _this6.dropoutMask;\n\n        var applyDropout = function applyDropout(x, mask, index) {\n          if (!mask || !mask[index]) {\n            return x;\n          }\n\n          return tfc.mul(mask[index], x);\n        };\n\n        var xI = applyDropout(x, dropoutMask, 0);\n        var xF = applyDropout(x, dropoutMask, 1);\n        var xC = applyDropout(x, dropoutMask, 2);\n        var xO = applyDropout(x, dropoutMask, 3);\n\n        if (0 < _this6.recurrentDropout && _this6.recurrentDropout < 1 && _this6.recurrentDropoutMask == null) {\n          _this6.recurrentDropoutMask = generateDropoutMask({\n            ones: function ones() {\n              return tfc.onesLike(hTMinus1);\n            },\n            rate: _this6.recurrentDropout,\n            training: training,\n            count: numOfKernels\n          });\n        }\n\n        var recDropoutMask = _this6.recurrentDropoutMask;\n        var hI = applyDropout(hTMinus1, recDropoutMask, 0);\n        var hF = applyDropout(hTMinus1, recDropoutMask, 1);\n        var hC = applyDropout(hTMinus1, recDropoutMask, 2);\n        var hO = applyDropout(hTMinus1, recDropoutMask, 3);\n        var kernelChannelAxis = 3;\n\n        var _tfc$split = tfc.split(_this6.kernel.read(), numOfKernels, kernelChannelAxis),\n            _tfc$split2 = _slicedToArray(_tfc$split, 4),\n            kernelI = _tfc$split2[0],\n            kernelF = _tfc$split2[1],\n            kernelC = _tfc$split2[2],\n            kernelO = _tfc$split2[3];\n\n        var _ref = _this6.useBias ? tfc.split(_this6.bias.read(), numOfKernels) : [null, null, null, null],\n            _ref2 = _slicedToArray(_ref, 4),\n            biasI = _ref2[0],\n            biasF = _ref2[1],\n            biasC = _ref2[2],\n            biasO = _ref2[3];\n\n        xI = _this6.inputConv(xI, kernelI, biasI, _this6.padding);\n        xF = _this6.inputConv(xF, kernelF, biasF, _this6.padding);\n        xC = _this6.inputConv(xC, kernelC, biasC, _this6.padding);\n        xO = _this6.inputConv(xO, kernelO, biasO, _this6.padding);\n\n        var _tfc$split3 = tfc.split(_this6.recurrentKernel.read(), numOfKernels, kernelChannelAxis),\n            _tfc$split4 = _slicedToArray(_tfc$split3, 4),\n            recKernelI = _tfc$split4[0],\n            recKernelF = _tfc$split4[1],\n            recKernelC = _tfc$split4[2],\n            recKernelO = _tfc$split4[3];\n\n        hI = _this6.recurrentConv(hI, recKernelI);\n        hF = _this6.recurrentConv(hF, recKernelF);\n        hC = _this6.recurrentConv(hC, recKernelC);\n        hO = _this6.recurrentConv(hO, recKernelO);\n\n        var i = _this6.recurrentActivation.apply(tfc.add(xI, hI));\n\n        var f = _this6.recurrentActivation.apply(tfc.add(xF, hF));\n\n        var c = tfc.add(tfc.mul(f, cTMinus1), tfc.mul(i, _this6.activation.apply(tfc.add(xC, hC))));\n        var h = tfc.mul(_this6.recurrentActivation.apply(tfc.add(xO, hO)), _this6.activation.apply(c));\n        return [h, h, c];\n      });\n    }\n  }, {\n    key: \"getConfig\",\n    value: function getConfig() {\n      var _a = _get(_getPrototypeOf(ConvLSTM2DCell.prototype), \"getConfig\", this).call(this),\n          _ = _a['units'],\n          baseConfig = __rest(_a, ['units']);\n\n      var config = {\n        filters: this.filters,\n        kernelSize: this.kernelSize,\n        padding: this.padding,\n        dataFormat: this.dataFormat,\n        dilationRate: this.dilationRate,\n        strides: this.strides\n      };\n      return Object.assign({}, baseConfig, config);\n    }\n  }, {\n    key: \"inputConv\",\n    value: function inputConv(x, w, b, padding) {\n      var out = tfc.conv2d(x, w, this.strides, padding || 'valid', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC', this.dilationRate);\n\n      if (b) {\n        return K.biasAdd(out, b, this.dataFormat);\n      }\n\n      return out;\n    }\n  }, {\n    key: \"recurrentConv\",\n    value: function recurrentConv(x, w) {\n      var strides = 1;\n      return tfc.conv2d(x, w, strides, 'same', this.dataFormat === 'channelsFirst' ? 'NCHW' : 'NHWC');\n    }\n  }]);\n\n  return ConvLSTM2DCell;\n}(LSTMCell);\n/** @nocollapse */\n\nConvLSTM2DCell.className = 'ConvLSTM2DCell';\ntfc.serialization.registerClass(ConvLSTM2DCell);\nexport var ConvLSTM2D = /*#__PURE__*/function (_ConvRNN2D) {\n  _inherits(ConvLSTM2D, _ConvRNN2D);\n\n  function ConvLSTM2D(args) {\n    _classCallCheck(this, ConvLSTM2D);\n\n    var cell = new ConvLSTM2DCell(args);\n    return _possibleConstructorReturn(this, _getPrototypeOf(ConvLSTM2D).call(this, Object.assign({}, args, {\n      cell: cell\n    })));\n  }\n  /** @nocollapse */\n\n\n  _createClass(ConvLSTM2D, null, [{\n    key: \"fromConfig\",\n    value: function fromConfig(cls, config) {\n      return new cls(config);\n    }\n  }]);\n\n  return ConvLSTM2D;\n}(ConvRNN2D);\n/** @nocollapse */\n\nConvLSTM2D.className = 'ConvLSTM2D';\ntfc.serialization.registerClass(ConvLSTM2D);","map":null,"metadata":{},"sourceType":"module"}