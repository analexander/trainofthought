{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nvar _jsxFileName = \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/facerec/VideoStream.js\";\nimport React, { Component } from \"react\";\nimport \"./styles.css\"; // import \"./face_expression_model-weights_manifest.json\"\n// import \"./tiny_face_detector_model-weights_manifest.json\"\n\nimport Video from \"./Video\";\nimport * as canvas from 'canvas';\nimport * as faceapi from 'face-api.js';\n\nvar VideoStream = /*#__PURE__*/function (_Component) {\n  _inherits(VideoStream, _Component);\n\n  function VideoStream() {\n    var _getPrototypeOf2;\n\n    var _this;\n\n    _classCallCheck(this, VideoStream);\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    _this = _possibleConstructorReturn(this, (_getPrototypeOf2 = _getPrototypeOf(VideoStream)).call.apply(_getPrototypeOf2, [this].concat(args)));\n    _this.renderVideo = /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n      var canvasElement, videoElement, constraints, stream, onPlay;\n      return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              fetch(\"./face_expression_model-weights_manifest.json\");\n              fetch(\"./tiny_face_detector_model-weights_manifest.json\"); // load the face detection model\n\n              _context2.next = 4;\n              return faceapi.nets.tinyFaceDetector.load('/');\n\n            case 4:\n              _context2.next = 6;\n              return faceapi.loadFaceExpressionModel('/');\n\n            case 6:\n              // get canvas and video elements\n              canvasElement = document.getElementById(\"overlay\");\n              videoElement = document.querySelector(\"video\"); // get Webcam video stream\n\n              constraints = {\n                audio: false,\n                video: {}\n              };\n              _context2.next = 11;\n              return navigator.mediaDevices.getUserMedia(constraints);\n\n            case 11:\n              stream = _context2.sent;\n\n              // what to do when the video stream is available\n              // AKA facial recogition \n              onPlay = /*#__PURE__*/function () {\n                var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n                  var options, result, dims, resizedResult, minConfidence;\n                  return _regeneratorRuntime.wrap(function _callee$(_context) {\n                    while (1) {\n                      switch (_context.prev = _context.next) {\n                        case 0:\n                          options = new faceapi.TinyFaceDetectorOptions({\n                            inputSize: 512,\n                            scoreThreshold: 0.5\n                          });\n                          _context.next = 3;\n                          return faceapi.detectSingleFace(videoElement, options).withFaceExpressions();\n\n                        case 3:\n                          result = _context.sent;\n\n                          if (result) {\n                            dims = faceapi.matchDimensions(canvasElement, videoElement, true);\n                            resizedResult = faceapi.resizeResults(result, dims);\n                            minConfidence = 0.05;\n                            faceapi.draw.drawDetections(canvasElement, resizedResult);\n                            faceapi.draw.drawFaceExpressions(canvasElement, resizedResult, minConfidence);\n                          }\n\n                          setTimeout(function () {\n                            return onPlay();\n                          });\n\n                        case 6:\n                        case \"end\":\n                          return _context.stop();\n                      }\n                    }\n                  }, _callee);\n                }));\n\n                return function onPlay() {\n                  return _ref2.apply(this, arguments);\n                };\n              }();\n\n              videoElement.srcObject = stream;\n\n              videoElement.onloadedmetadata = function () {\n                videoElement.play();\n              };\n\n              videoElement.onplay = onPlay;\n\n            case 16:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2);\n    }));\n    return _this;\n  }\n\n  _createClass(VideoStream, [{\n    key: \"componentDidMount\",\n    value: function componentDidMount() {\n      this.renderVideo();\n    }\n  }, {\n    key: \"render\",\n    value: function render() {\n      return /*#__PURE__*/React.createElement(\"div\", {\n        style: {\n          position: \"relative\"\n        },\n        __self: this,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 62,\n          columnNumber: 17\n        }\n      }, /*#__PURE__*/React.createElement(\"video\", {\n        onLoadedMetadata: function onLoadedMetadata() {\n          return \"onPlay\";\n        },\n        id: \"inputVideo\",\n        className: \"video-circle\",\n        width: \"500\",\n        height: \"500\",\n        autoPlay: true,\n        muted: true,\n        playsInline: true,\n        __self: this,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 63,\n          columnNumber: 21\n        }\n      }), /*#__PURE__*/React.createElement(\"canvas\", {\n        id: \"overlay\",\n        __self: this,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 64,\n          columnNumber: 21\n        }\n      }));\n    }\n  }]);\n\n  return VideoStream;\n}(Component);\n\nexport default VideoStream;","map":{"version":3,"sources":["/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/facerec/VideoStream.js"],"names":["React","Component","Video","canvas","faceapi","VideoStream","renderVideo","fetch","nets","tinyFaceDetector","load","loadFaceExpressionModel","canvasElement","document","getElementById","videoElement","querySelector","constraints","audio","video","navigator","mediaDevices","getUserMedia","stream","onPlay","options","TinyFaceDetectorOptions","inputSize","scoreThreshold","detectSingleFace","withFaceExpressions","result","dims","matchDimensions","resizedResult","resizeResults","minConfidence","draw","drawDetections","drawFaceExpressions","setTimeout","srcObject","onloadedmetadata","play","onplay","position"],"mappings":";;;;;;;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAO,cAAP,C,CACA;AACA;;AACA,OAAOC,KAAP,MAAkB,SAAlB;AACA,OAAO,KAAKC,MAAZ,MAAwB,QAAxB;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;;IAGMC,W;;;;;;;;;;;;;;;UAMFC,W,yEAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AACVC,cAAAA,KAAK,CAAE,+CAAF,CAAL;AACAA,cAAAA,KAAK,CAAE,kDAAF,CAAL,CAFU,CAKV;;AALU;AAAA,qBAMJH,OAAO,CAACI,IAAR,CAAaC,gBAAb,CAA8BC,IAA9B,CAAmC,GAAnC,CANI;;AAAA;AAAA;AAAA,qBAQJN,OAAO,CAACO,uBAAR,CAAgC,GAAhC,CARI;;AAAA;AAUV;AACMC,cAAAA,aAXI,GAWYC,QAAQ,CAACC,cAAT,CAAwB,SAAxB,CAXZ;AAYJC,cAAAA,YAZI,GAYWF,QAAQ,CAACG,aAAT,CAAuB,OAAvB,CAZX,EAcV;;AACMC,cAAAA,WAfI,GAeU;AAAEC,gBAAAA,KAAK,EAAE,KAAT;AAAgBC,gBAAAA,KAAK,EAAE;AAAvB,eAfV;AAAA;AAAA,qBAgBWC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoCL,WAApC,CAhBX;;AAAA;AAgBJM,cAAAA,MAhBI;;AAkBV;AACA;AACMC,cAAAA,MApBI;AAAA,qFAoBK;AAAA;AAAA;AAAA;AAAA;AAAA;AAELC,0BAAAA,OAFK,GAEK,IAAIrB,OAAO,CAACsB,uBAAZ,CAAoC;AAAEC,4BAAAA,SAAS,EAAE,GAAb;AAAkBC,4BAAAA,cAAc,EAAE;AAAlC,2BAApC,CAFL;AAAA;AAAA,iCAGUxB,OAAO,CAACyB,gBAAR,CAAyBd,YAAzB,EAAuCU,OAAvC,EAAgDK,mBAAhD,EAHV;;AAAA;AAGLC,0BAAAA,MAHK;;AAKX,8BAAIA,MAAJ,EAAY;AACFC,4BAAAA,IADE,GACK5B,OAAO,CAAC6B,eAAR,CAAwBrB,aAAxB,EAAuCG,YAAvC,EAAqD,IAArD,CADL;AAEFmB,4BAAAA,aAFE,GAEc9B,OAAO,CAAC+B,aAAR,CAAsBJ,MAAtB,EAA8BC,IAA9B,CAFd;AAGFI,4BAAAA,aAHE,GAGc,IAHd;AAIRhC,4BAAAA,OAAO,CAACiC,IAAR,CAAaC,cAAb,CAA4B1B,aAA5B,EAA2CsB,aAA3C;AACA9B,4BAAAA,OAAO,CAACiC,IAAR,CAAaE,mBAAb,CAAiC3B,aAAjC,EAAgDsB,aAAhD,EAA+DE,aAA/D;AACH;;AAEDI,0BAAAA,UAAU,CAAC;AAAA,mCAAMhB,MAAM,EAAZ;AAAA,2BAAD,CAAV;;AAbW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBApBL;;AAAA,gCAoBJA,MApBI;AAAA;AAAA;AAAA;;AAoCVT,cAAAA,YAAY,CAAC0B,SAAb,GAAyBlB,MAAzB;;AACAR,cAAAA,YAAY,CAAC2B,gBAAb,GAAgC,YAAM;AAClC3B,gBAAAA,YAAY,CAAC4B,IAAb;AACH,eAFD;;AAGA5B,cAAAA,YAAY,CAAC6B,MAAb,GAAsBpB,MAAtB;;AAxCU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,K;;;;;;wCAJM;AAChB,WAAKlB,WAAL;AACH;;;6BA8CY;AACL,0BACI;AAAK,QAAA,KAAK,EAAE;AAAEuC,UAAAA,QAAQ,EAAE;AAAZ,SAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBACI;AAAO,QAAA,gBAAgB,EAAE;AAAA,iBAAM,QAAN;AAAA,SAAzB;AAAyC,QAAA,EAAE,EAAC,YAA5C;AAAyD,QAAA,SAAS,EAAC,cAAnE;AAAkF,QAAA,KAAK,EAAC,KAAxF;AAA8F,QAAA,MAAM,EAAC,KAArG;AAA2G,QAAA,QAAQ,MAAnH;AAAoH,QAAA,KAAK,MAAzH;AAA0H,QAAA,WAAW,MAArI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADJ,eAEI;AAAQ,QAAA,EAAE,EAAC,SAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAFJ,CADJ;AAMH;;;;EAzDiB5C,S;;AA4D1B,eAAeI,WAAf","sourcesContent":["import React, { Component } from \"react\"\nimport \"./styles.css\"\n// import \"./face_expression_model-weights_manifest.json\"\n// import \"./tiny_face_detector_model-weights_manifest.json\"\nimport Video from \"./Video\"\nimport * as canvas from 'canvas';\nimport * as faceapi from 'face-api.js';\n\n\nclass VideoStream extends Component {\n\n    componentDidMount() {\n        this.renderVideo();\n    }\n\n    renderVideo = async () => {\n        fetch (\"./face_expression_model-weights_manifest.json\")\n        fetch (\"./tiny_face_detector_model-weights_manifest.json\")\n\n\n        // load the face detection model\n        await faceapi.nets.tinyFaceDetector.load('/');\n        // load the face expression detection model\n        await faceapi.loadFaceExpressionModel('/');\n\n        // get canvas and video elements\n        const canvasElement = document.getElementById(\"overlay\");\n        const videoElement = document.querySelector(\"video\");\n\n        // get Webcam video stream\n        const constraints = { audio: false, video: {} };\n        const stream = await navigator.mediaDevices.getUserMedia(constraints);\n\n        // what to do when the video stream is available\n        // AKA facial recogition \n        const onPlay = async () => {\n\n            const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });\n            const result = await faceapi.detectSingleFace(videoElement, options).withFaceExpressions();\n\n            if (result) {\n                const dims = faceapi.matchDimensions(canvasElement, videoElement, true);\n                const resizedResult = faceapi.resizeResults(result, dims);\n                const minConfidence = 0.05;\n                faceapi.draw.drawDetections(canvasElement, resizedResult);\n                faceapi.draw.drawFaceExpressions(canvasElement, resizedResult, minConfidence);\n            }\n\n            setTimeout(() => onPlay());\n        }\n\n        videoElement.srcObject = stream;\n        videoElement.onloadedmetadata = () => {\n            videoElement.play();\n        };\n        videoElement.onplay = onPlay;\n\n    }\n\n        render() {\n            return (\n                <div style={{ position: \"relative\" }}>\n                    <video onLoadedMetadata={() => \"onPlay\"} id=\"inputVideo\" className=\"video-circle\" width=\"500\" height=\"500\" autoPlay muted playsInline></video>\n                    <canvas id=\"overlay\" />\n                </div>\n            )\n        }\n    }\n\nexport default VideoStream"]},"metadata":{},"sourceType":"module"}