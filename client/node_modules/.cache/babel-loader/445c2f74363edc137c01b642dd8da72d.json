{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { env } from '../environment';\nimport * as util from '../util';\nimport { decodeWeights } from './io_utils';\nimport { monitorPromisesProgress } from './progress';\nimport { DTYPE_VALUE_SIZE_MAP } from './types';\n/**\n * Reads binary weights data from a number of URLs.\n *\n * @param fetchURLs URLs to send the HTTP requests at, using `fetch` calls.\n * @param requestOptions RequestInit (options) for the HTTP requests.\n * @param fetchFunc Optional overriding value for the `window.fetch` function.\n * @param onProgress Optional, progress callback function, fired periodically\n *   before the load is completed.\n * @returns A `Promise` of an Array of `ArrayBuffer`. The Array has the same\n *   length as `fetchURLs`.\n */\n\nexport function loadWeightsAsArrayBuffer(_x, _x2) {\n  return _loadWeightsAsArrayBuffer.apply(this, arguments);\n}\n/**\n * Reads a weights manifest JSON configuration, fetches the weights and\n * returns them as `Tensor`s.\n *\n * @param manifest The weights manifest JSON.\n * @param filePathPrefix The path prefix for filenames given in the manifest.\n *     Defaults to the empty string.\n * @param weightNames The names of the weights to be fetched.\n */\n\nfunction _loadWeightsAsArrayBuffer() {\n  _loadWeightsAsArrayBuffer = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2(fetchURLs, loadOptions) {\n    var fetchFunc, requests, fetchStartFraction, fetchEndFraction, responses, bufferPromises, bufferStartFraction, bufferEndFraction, buffers;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            if (loadOptions == null) {\n              loadOptions = {};\n            }\n\n            fetchFunc = loadOptions.fetchFunc == null ? env().platform.fetch : loadOptions.fetchFunc; // Create the requests for all of the weights in parallel.\n\n            requests = fetchURLs.map(function (fetchURL) {\n              return fetchFunc(fetchURL, loadOptions.requestInit, {\n                isBinary: true\n              });\n            });\n            fetchStartFraction = 0;\n            fetchEndFraction = 0.5;\n\n            if (!(loadOptions.onProgress == null)) {\n              _context2.next = 11;\n              break;\n            }\n\n            _context2.next = 8;\n            return Promise.all(requests);\n\n          case 8:\n            _context2.t0 = _context2.sent;\n            _context2.next = 14;\n            break;\n\n          case 11:\n            _context2.next = 13;\n            return monitorPromisesProgress(requests, loadOptions.onProgress, fetchStartFraction, fetchEndFraction);\n\n          case 13:\n            _context2.t0 = _context2.sent;\n\n          case 14:\n            responses = _context2.t0;\n            bufferPromises = responses.map(function (response) {\n              return response.arrayBuffer();\n            });\n            bufferStartFraction = 0.5;\n            bufferEndFraction = 1;\n\n            if (!(loadOptions.onProgress == null)) {\n              _context2.next = 24;\n              break;\n            }\n\n            _context2.next = 21;\n            return Promise.all(bufferPromises);\n\n          case 21:\n            _context2.t1 = _context2.sent;\n            _context2.next = 27;\n            break;\n\n          case 24:\n            _context2.next = 26;\n            return monitorPromisesProgress(bufferPromises, loadOptions.onProgress, bufferStartFraction, bufferEndFraction);\n\n          case 26:\n            _context2.t1 = _context2.sent;\n\n          case 27:\n            buffers = _context2.t1;\n            return _context2.abrupt(\"return\", buffers);\n\n          case 29:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return _loadWeightsAsArrayBuffer.apply(this, arguments);\n}\n\nexport function loadWeights(_x3) {\n  return _loadWeights.apply(this, arguments);\n}\n/**\n * Creates a function, which reads a weights manifest JSON configuration,\n * fetches the weight files using the specified function and returns them as\n * `Tensor`s.\n *\n * ```js\n * // example for creating a nodejs weight loader, which reads the weight files\n * // from disk using fs.readFileSync\n *\n * import * as fs from 'fs'\n *\n * const fetchWeightsFromDisk = (filePaths: string[]) =>\n *   filePaths.map(filePath => fs.readFileSync(filePath).buffer)\n *\n * const loadWeights = tf.io.weightsLoaderFactory(fetchWeightsFromDisk)\n *\n * const manifest = JSON.parse(\n *   fs.readFileSync('./my_model-weights_manifest').toString()\n * )\n * const weightMap = await loadWeights(manifest, './')\n * ```\n * @param fetchWeightsFunction The function used for fetching the weight files.\n * @returns Weight loading function.\n */\n\nfunction _loadWeights() {\n  _loadWeights = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3(manifest) {\n    var filePathPrefix,\n        weightNames,\n        requestInit,\n        fetchWeights,\n        loadWeights,\n        _args3 = arguments;\n    return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n      while (1) {\n        switch (_context3.prev = _context3.next) {\n          case 0:\n            filePathPrefix = _args3.length > 1 && _args3[1] !== undefined ? _args3[1] : '';\n            weightNames = _args3.length > 2 ? _args3[2] : undefined;\n            requestInit = _args3.length > 3 ? _args3[3] : undefined;\n\n            // TODO(nsthorat): Groups are currently fetched atomically. If you need a\n            // single weight from a group, the whole group will be fetched. At a future\n            // date, we should support fetching only the individual shards within a\n            // group that are needed to reconstruct the requested weight.\n            // TODO(cais): Use `decodeWeights` for implementation.\n            fetchWeights = function fetchWeights(fetchUrls) {\n              return loadWeightsAsArrayBuffer(fetchUrls, {\n                requestInit: requestInit\n              });\n            };\n\n            loadWeights = weightsLoaderFactory(fetchWeights);\n            return _context3.abrupt(\"return\", loadWeights(manifest, filePathPrefix, weightNames));\n\n          case 6:\n          case \"end\":\n            return _context3.stop();\n        }\n      }\n    }, _callee3);\n  }));\n  return _loadWeights.apply(this, arguments);\n}\n\nexport function weightsLoaderFactory(fetchWeightsFunction) {\n  return /*#__PURE__*/function () {\n    var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee(manifest) {\n      var filePathPrefix,\n          weightNames,\n          groupIndicesToFetchMap,\n          groupWeightsToFetch,\n          weightsFound,\n          allManifestWeightNames,\n          weightsNotFound,\n          groupIndicesToFetch,\n          fetchUrls,\n          buffers,\n          weightsTensorMap,\n          bufferIndexOffset,\n          _args = arguments;\n      return _regeneratorRuntime.wrap(function _callee$(_context) {\n        while (1) {\n          switch (_context.prev = _context.next) {\n            case 0:\n              filePathPrefix = _args.length > 1 && _args[1] !== undefined ? _args[1] : '';\n              weightNames = _args.length > 2 ? _args[2] : undefined;\n              // Collect all the groups, weights, and their relative offsets to be\n              // fetched.\n              groupIndicesToFetchMap = manifest.map(function () {\n                return false;\n              });\n              groupWeightsToFetch = {};\n              weightsFound = weightNames != null ? weightNames.map(function () {\n                return false;\n              }) : [];\n              allManifestWeightNames = [];\n              manifest.forEach(function (manifestGroupConfig, groupIndex) {\n                var groupOffset = 0;\n                manifestGroupConfig.weights.forEach(function (weightsEntry) {\n                  var rawDtype = 'quantization' in weightsEntry ? weightsEntry.quantization.dtype : weightsEntry.dtype;\n                  var weightsBytes = DTYPE_VALUE_SIZE_MAP[rawDtype] * util.sizeFromShape(weightsEntry.shape);\n\n                  var enqueueWeightsForFetchingFn = function enqueueWeightsForFetchingFn() {\n                    groupIndicesToFetchMap[groupIndex] = true;\n\n                    if (groupWeightsToFetch[groupIndex] == null) {\n                      groupWeightsToFetch[groupIndex] = [];\n                    }\n\n                    groupWeightsToFetch[groupIndex].push({\n                      manifestEntry: weightsEntry,\n                      groupOffset: groupOffset,\n                      sizeBytes: weightsBytes\n                    });\n                  };\n\n                  if (weightNames != null) {\n                    weightNames.forEach(function (weightName, weightIndex) {\n                      if (weightName === weightsEntry.name) {\n                        enqueueWeightsForFetchingFn();\n                        weightsFound[weightIndex] = true;\n                      }\n                    });\n                  } else {\n                    enqueueWeightsForFetchingFn();\n                  }\n\n                  allManifestWeightNames.push(weightsEntry.name);\n                  groupOffset += weightsBytes;\n                });\n              });\n\n              if (weightsFound.every(function (found) {\n                return found;\n              })) {\n                _context.next = 10;\n                break;\n              }\n\n              weightsNotFound = weightNames.filter(function (_, i) {\n                return !weightsFound[i];\n              });\n              throw new Error(\"Could not find weights in manifest with names: \" + \"\".concat(weightsNotFound.join(', '), \". \\n\") + \"Manifest JSON has weights with names: \" + \"\".concat(allManifestWeightNames.join(', '), \".\"));\n\n            case 10:\n              // Convert the one-hot boolean groupId => shouldFetch map to a list of group\n              // IDs.\n              groupIndicesToFetch = groupIndicesToFetchMap.reduce(function (accumulator, shouldFetch, i) {\n                if (shouldFetch) {\n                  accumulator.push(i);\n                }\n\n                return accumulator;\n              }, []);\n              fetchUrls = [];\n              groupIndicesToFetch.forEach(function (i) {\n                manifest[i].paths.forEach(function (filepath) {\n                  var fetchUrl = filePathPrefix + (!filePathPrefix.endsWith('/') ? '/' : '') + filepath;\n                  fetchUrls.push(fetchUrl);\n                });\n              });\n              _context.next = 15;\n              return fetchWeightsFunction(fetchUrls);\n\n            case 15:\n              buffers = _context.sent;\n              weightsTensorMap = {};\n              bufferIndexOffset = 0;\n              groupIndicesToFetch.forEach(function (i) {\n                var numBuffers = manifest[i].paths.length;\n                var groupBytes = 0;\n\n                for (var _i = 0; _i < numBuffers; _i++) {\n                  groupBytes += buffers[bufferIndexOffset + _i].byteLength;\n                } // Create a buffer for the whole group.\n\n\n                var groupBuffer = new ArrayBuffer(groupBytes);\n                var groupByteBuffer = new Uint8Array(groupBuffer);\n                var groupBufferOffset = 0;\n\n                for (var _i2 = 0; _i2 < numBuffers; _i2++) {\n                  var buffer = new Uint8Array(buffers[bufferIndexOffset + _i2]);\n                  groupByteBuffer.set(buffer, groupBufferOffset);\n                  groupBufferOffset += buffer.byteLength;\n                }\n\n                var weightsEntries = groupWeightsToFetch[i];\n                weightsEntries.forEach(function (weightsEntry) {\n                  var byteBuffer = groupBuffer.slice(weightsEntry.groupOffset, weightsEntry.groupOffset + weightsEntry.sizeBytes);\n                  var nameToTensorMap = decodeWeights(byteBuffer, [weightsEntry.manifestEntry]);\n\n                  for (var name in nameToTensorMap) {\n                    weightsTensorMap[name] = nameToTensorMap[name];\n                  }\n                });\n                bufferIndexOffset += numBuffers;\n              });\n              return _context.abrupt(\"return\", weightsTensorMap);\n\n            case 20:\n            case \"end\":\n              return _context.stop();\n          }\n        }\n      }, _callee);\n    }));\n\n    return function (_x4) {\n      return _ref.apply(this, arguments);\n    };\n  }();\n}","map":null,"metadata":{},"sourceType":"module"}