{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\nvar _this = this,\n    _jsxFileName = \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/facerec/VidContainer.js\";\n\nimport React from \"react\";\nimport \"./styles.css\";\nimport \"./face_expression_model-weights_manifest.json\";\nimport \"./tiny_face_detector_model-weights_manifest.json\";\nimport Video from \"./Video\";\nimport * as canvas from 'canvas';\nimport * as faceapi from 'face-api.js';\nvar Canvas = canvas.Canvas,\n    Image = canvas.Image,\n    ImageData = canvas.ImageData;\nfaceapi.env.monkeyPatch({\n  Canvas: Canvas,\n  Image: Image,\n  ImageData: ImageData\n});\n\nvar VidContainer = /*#__PURE__*/function () {\n  var _ref = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n    var canvasElement, videoElement, constraints, stream, onPlay;\n    return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n      while (1) {\n        switch (_context2.prev = _context2.next) {\n          case 0:\n            _context2.next = 2;\n            return faceapi.nets.tinyFaceDetector.load('/');\n\n          case 2:\n            _context2.next = 4;\n            return faceapi.loadFaceExpressionModel('/');\n\n          case 4:\n            // get canvas and video elements\n            canvasElement = document.getElementById(\"overlay\");\n            videoElement = document.querySelector(\"video\"); // get Webcam video stream\n\n            constraints = {\n              audio: false,\n              video: []\n            };\n            _context2.next = 9;\n            return navigator.mediaDevices.getUserMedia(constraints);\n\n          case 9:\n            stream = _context2.sent;\n\n            // what to do when the video stream is available\n            // AKA facial recogition \n            onPlay = /*#__PURE__*/function () {\n              var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n                var options, result, dims, resizedResult, minConfidence;\n                return _regeneratorRuntime.wrap(function _callee$(_context) {\n                  while (1) {\n                    switch (_context.prev = _context.next) {\n                      case 0:\n                        options = new faceapi.TinyFaceDetectorOptions({\n                          inputSize: 512,\n                          scoreThreshold: 0.5\n                        });\n                        _context.next = 3;\n                        return faceapi.detectSingleFace(videoElement, options).withFaceExpressions();\n\n                      case 3:\n                        result = _context.sent;\n\n                        if (result) {\n                          dims = faceapi.matchDimensions(canvasElement, videoElement, true);\n                          resizedResult = faceapi.resizeResults(result, dims);\n                          minConfidence = 0.05;\n                          faceapi.draw.drawDetections(canvasElement, resizedResult);\n                          faceapi.draw.drawFaceExpressions(canvasElement, resizedResult, minConfidence);\n                        }\n\n                        setTimeout(function () {\n                          return onPlay();\n                        });\n\n                      case 6:\n                      case \"end\":\n                        return _context.stop();\n                    }\n                  }\n                }, _callee);\n              }));\n\n              return function onPlay() {\n                return _ref2.apply(this, arguments);\n              };\n            }();\n\n            videoElement.srcObject = stream;\n\n            videoElement.onloadedmetadata = function () {\n              videoElement.play();\n            };\n\n            videoElement.onplay = onPlay;\n            return _context2.abrupt(\"return\", /*#__PURE__*/React.createElement(\"div\", {\n              style: {\n                position: \"relative\"\n              },\n              __self: _this,\n              __source: {\n                fileName: _jsxFileName,\n                lineNumber: 54,\n                columnNumber: 9\n              }\n            }, /*#__PURE__*/React.createElement(\"video\", {\n              onLoadedMetadata: onPlay,\n              id: \"inputVideo\",\n              className: \"video-circle\",\n              width: \"500\",\n              height: \"500\",\n              autoPlay: true,\n              muted: true,\n              playsInline: true,\n              __self: _this,\n              __source: {\n                fileName: _jsxFileName,\n                lineNumber: 55,\n                columnNumber: 7\n              }\n            }), /*#__PURE__*/React.createElement(\"canvas\", {\n              id: \"overlay\",\n              __self: _this,\n              __source: {\n                fileName: _jsxFileName,\n                lineNumber: 56,\n                columnNumber: 7\n              }\n            })));\n\n          case 15:\n          case \"end\":\n            return _context2.stop();\n        }\n      }\n    }, _callee2);\n  }));\n\n  return function VidContainer() {\n    return _ref.apply(this, arguments);\n  };\n}();\n\nexport default VidContainer;","map":{"version":3,"sources":["/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/facerec/VidContainer.js"],"names":["React","Video","canvas","faceapi","Canvas","Image","ImageData","env","monkeyPatch","VidContainer","nets","tinyFaceDetector","load","loadFaceExpressionModel","canvasElement","document","getElementById","videoElement","querySelector","constraints","audio","video","navigator","mediaDevices","getUserMedia","stream","onPlay","options","TinyFaceDetectorOptions","inputSize","scoreThreshold","detectSingleFace","withFaceExpressions","result","dims","matchDimensions","resizedResult","resizeResults","minConfidence","draw","drawDetections","drawFaceExpressions","setTimeout","srcObject","onloadedmetadata","play","onplay","position"],"mappings":";;;;;;AAAA,OAAOA,KAAP,MAAkB,OAAlB;AACA,OAAO,cAAP;AACA,OAAO,+CAAP;AACA,OAAO,kDAAP;AACA,OAAOC,KAAP,MAAkB,SAAlB;AACA,OAAO,KAAKC,MAAZ,MAAwB,QAAxB;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;IACQC,M,GAA6BF,M,CAA7BE,M;IAAQC,K,GAAqBH,M,CAArBG,K;IAAOC,S,GAAcJ,M,CAAdI,S;AACvBH,OAAO,CAACI,GAAR,CAAYC,WAAZ,CAAwB;AAAEJ,EAAAA,MAAM,EAANA,MAAF;AAAUC,EAAAA,KAAK,EAALA,KAAV;AAAiBC,EAAAA,SAAS,EAATA;AAAjB,CAAxB;;AAEA,IAAMG,YAAY;AAAA,sEAAG;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,mBAGPN,OAAO,CAACO,IAAR,CAAaC,gBAAb,CAA8BC,IAA9B,CAAmC,GAAnC,CAHO;;AAAA;AAAA;AAAA,mBAKPT,OAAO,CAACU,uBAAR,CAAgC,GAAhC,CALO;;AAAA;AAOb;AACMC,YAAAA,aARO,GAQSC,QAAQ,CAACC,cAAT,CAAwB,SAAxB,CART;AASPC,YAAAA,YATO,GASQF,QAAQ,CAACG,aAAT,CAAuB,OAAvB,CATR,EAWb;;AACMC,YAAAA,WAZO,GAYO;AAAEC,cAAAA,KAAK,EAAE,KAAT;AAAgBC,cAAAA,KAAK,EAAE;AAAvB,aAZP;AAAA;AAAA,mBAaQC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoCL,WAApC,CAbR;;AAAA;AAaPM,YAAAA,MAbO;;AAeb;AACA;AACMC,YAAAA,MAjBO;AAAA,mFAiBE;AAAA;AAAA;AAAA;AAAA;AAAA;AAELC,wBAAAA,OAFK,GAEK,IAAIxB,OAAO,CAACyB,uBAAZ,CAAoC;AAAEC,0BAAAA,SAAS,EAAE,GAAb;AAAkBC,0BAAAA,cAAc,EAAE;AAAlC,yBAApC,CAFL;AAAA;AAAA,+BAGU3B,OAAO,CAAC4B,gBAAR,CAAyBd,YAAzB,EAAuCU,OAAvC,EAAgDK,mBAAhD,EAHV;;AAAA;AAGLC,wBAAAA,MAHK;;AAKX,4BAAIA,MAAJ,EAAY;AACFC,0BAAAA,IADE,GACK/B,OAAO,CAACgC,eAAR,CAAwBrB,aAAxB,EAAuCG,YAAvC,EAAqD,IAArD,CADL;AAEFmB,0BAAAA,aAFE,GAEcjC,OAAO,CAACkC,aAAR,CAAsBJ,MAAtB,EAA8BC,IAA9B,CAFd;AAGFI,0BAAAA,aAHE,GAGc,IAHd;AAIRnC,0BAAAA,OAAO,CAACoC,IAAR,CAAaC,cAAb,CAA4B1B,aAA5B,EAA2CsB,aAA3C;AACAjC,0BAAAA,OAAO,CAACoC,IAAR,CAAaE,mBAAb,CAAiC3B,aAAjC,EAAgDsB,aAAhD,EAA+DE,aAA/D;AACH;;AAEDI,wBAAAA,UAAU,CAAC;AAAA,iCAAMhB,MAAM,EAAZ;AAAA,yBAAD,CAAV;;AAbW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,eAjBF;;AAAA,8BAiBPA,MAjBO;AAAA;AAAA;AAAA;;AAiCbT,YAAAA,YAAY,CAAC0B,SAAb,GAAyBlB,MAAzB;;AACAR,YAAAA,YAAY,CAAC2B,gBAAb,GAAgC,YAAM;AAClC3B,cAAAA,YAAY,CAAC4B,IAAb;AACH,aAFD;;AAGA5B,YAAAA,YAAY,CAAC6B,MAAb,GAAsBpB,MAAtB;AArCa,2DA2Cb;AAAK,cAAA,KAAK,EAAE;AAACqB,gBAAAA,QAAQ,EAAE;AAAX,eAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,4BACF;AAAO,cAAA,gBAAgB,EAAGrB,MAA1B;AAAmC,cAAA,EAAE,EAAC,YAAtC;AAAmD,cAAA,SAAS,EAAC,cAA7D;AAA4E,cAAA,KAAK,EAAC,KAAlF;AAAwF,cAAA,MAAM,EAAC,KAA/F;AAAqG,cAAA,QAAQ,MAA7G;AAA8G,cAAA,KAAK,MAAnH;AAAoH,cAAA,WAAW,MAA/H;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cADE,eAEF;AAAQ,cAAA,EAAE,EAAC,SAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,cAFE,CA3Ca;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,GAAH;;AAAA,kBAAZjB,YAAY;AAAA;AAAA;AAAA,GAAlB;;AAkDA,eAAeA,YAAf","sourcesContent":["import React from \"react\"\nimport \"./styles.css\"\nimport \"./face_expression_model-weights_manifest.json\"\nimport \"./tiny_face_detector_model-weights_manifest.json\"\nimport Video from \"./Video\"\nimport * as canvas from 'canvas';\nimport * as faceapi from 'face-api.js';\nconst { Canvas, Image, ImageData } = canvas\nfaceapi.env.monkeyPatch({ Canvas, Image, ImageData })\n\nconst VidContainer = async () => {\n\n        // load the face detection model\n        await faceapi.nets.tinyFaceDetector.load('/');\n        // load the face expression detection model\n        await faceapi.loadFaceExpressionModel('/');\n    \n        // get canvas and video elements\n        const canvasElement = document.getElementById(\"overlay\");\n        const videoElement = document.querySelector(\"video\");\n    \n        // get Webcam video stream\n        const constraints = { audio: false, video: [] };\n        const stream = await navigator.mediaDevices.getUserMedia(constraints);\n    \n        // what to do when the video stream is available\n        // AKA facial recogition \n        const onPlay = async () => {\n    \n            const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });\n            const result = await faceapi.detectSingleFace(videoElement, options).withFaceExpressions();\n    \n            if (result) {\n                const dims = faceapi.matchDimensions(canvasElement, videoElement, true);\n                const resizedResult = faceapi.resizeResults(result, dims);\n                const minConfidence = 0.05;\n                faceapi.draw.drawDetections(canvasElement, resizedResult);\n                faceapi.draw.drawFaceExpressions(canvasElement, resizedResult, minConfidence);\n            }\n    \n            setTimeout(() => onPlay());\n        }\n    \n        videoElement.srcObject = stream;\n        videoElement.onloadedmetadata = () => {\n            videoElement.play();\n        };\n        videoElement.onplay = onPlay;\n    \n  \n\n\n        return (\n        <div style={{position: \"relative\"}}>\n      <video onLoadedMetadata={(onPlay)} id=\"inputVideo\" className=\"video-circle\" width=\"500\" height=\"500\" autoPlay muted playsInline></video>\n      <canvas id=\"overlay\" />\n    </div>\n        )\n}\n\nexport default VidContainer"]},"metadata":{},"sourceType":"module"}