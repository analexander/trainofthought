{"ast":null,"code":"import { AgeGenderNet } from '../ageGenderNet/AgeGenderNet';\nimport { FaceExpressionNet } from '../faceExpressionNet/FaceExpressionNet';\nimport { FaceLandmark68Net } from '../faceLandmarkNet/FaceLandmark68Net';\nimport { FaceLandmark68TinyNet } from '../faceLandmarkNet/FaceLandmark68TinyNet';\nimport { FaceRecognitionNet } from '../faceRecognitionNet/FaceRecognitionNet';\nimport { Mtcnn } from '../mtcnn/Mtcnn';\nimport { SsdMobilenetv1 } from '../ssdMobilenetv1/SsdMobilenetv1';\nimport { TinyFaceDetector } from '../tinyFaceDetector/TinyFaceDetector';\nimport { TinyYolov2 } from '../tinyYolov2';\nexport var nets = {\n  ssdMobilenetv1: new SsdMobilenetv1(),\n  tinyFaceDetector: new TinyFaceDetector(),\n  tinyYolov2: new TinyYolov2(),\n  mtcnn: new Mtcnn(),\n  faceLandmark68Net: new FaceLandmark68Net(),\n  faceLandmark68TinyNet: new FaceLandmark68TinyNet(),\n  faceRecognitionNet: new FaceRecognitionNet(),\n  faceExpressionNet: new FaceExpressionNet(),\n  ageGenderNet: new AgeGenderNet()\n};\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var ssdMobilenetv1 = function ssdMobilenetv1(input, options) {\n  return nets.ssdMobilenetv1.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var tinyFaceDetector = function tinyFaceDetector(input, options) {\n  return nets.tinyFaceDetector.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\n\nexport var tinyYolov2 = function tinyYolov2(input, options) {\n  return nets.tinyYolov2.locateFaces(input, options);\n};\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\n\nexport var mtcnn = function mtcnn(input, options) {\n  return nets.mtcnn.forward(input, options);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\n\nexport var detectFaceLandmarks = function detectFaceLandmarks(input) {\n  return nets.faceLandmark68Net.detectLandmarks(input);\n};\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\n\nexport var detectFaceLandmarksTiny = function detectFaceLandmarksTiny(input) {\n  return nets.faceLandmark68TinyNet.detectLandmarks(input);\n};\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\n\nexport var computeFaceDescriptor = function computeFaceDescriptor(input) {\n  return nets.faceRecognitionNet.computeFaceDescriptor(input);\n};\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\n\nexport var recognizeFaceExpressions = function recognizeFaceExpressions(input) {\n  return nets.faceExpressionNet.predictExpressions(input);\n};\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\n\nexport var predictAgeAndGender = function predictAgeAndGender(input) {\n  return nets.ageGenderNet.predictAgeAndGender(input);\n};\nexport var loadSsdMobilenetv1Model = function loadSsdMobilenetv1Model(url) {\n  return nets.ssdMobilenetv1.load(url);\n};\nexport var loadTinyFaceDetectorModel = function loadTinyFaceDetectorModel(url) {\n  return nets.tinyFaceDetector.load(url);\n};\nexport var loadMtcnnModel = function loadMtcnnModel(url) {\n  return nets.mtcnn.load(url);\n};\nexport var loadTinyYolov2Model = function loadTinyYolov2Model(url) {\n  return nets.tinyYolov2.load(url);\n};\nexport var loadFaceLandmarkModel = function loadFaceLandmarkModel(url) {\n  return nets.faceLandmark68Net.load(url);\n};\nexport var loadFaceLandmarkTinyModel = function loadFaceLandmarkTinyModel(url) {\n  return nets.faceLandmark68TinyNet.load(url);\n};\nexport var loadFaceRecognitionModel = function loadFaceRecognitionModel(url) {\n  return nets.faceRecognitionNet.load(url);\n};\nexport var loadFaceExpressionModel = function loadFaceExpressionModel(url) {\n  return nets.faceExpressionNet.load(url);\n};\nexport var loadAgeGenderModel = function loadAgeGenderModel(url) {\n  return nets.ageGenderNet.load(url);\n}; // backward compatibility\n\nexport var loadFaceDetectionModel = loadSsdMobilenetv1Model;\nexport var locateFaces = ssdMobilenetv1;\nexport var detectLandmarks = detectFaceLandmarks;","map":{"version":3,"sources":["../../../src/globalApi/nets.ts"],"names":[],"mappings":"AAAA,SAAS,YAAT,QAA6B,8BAA7B;AAMA,SAAS,iBAAT,QAAkC,wCAAlC;AAEA,SAAS,iBAAT,QAAkC,sCAAlC;AACA,SAAS,qBAAT,QAAsC,0CAAtC;AACA,SAAS,kBAAT,QAAmC,0CAAnC;AAGA,SAAS,KAAT,QAAsB,gBAAtB;AAEA,SAAS,cAAT,QAA+B,kCAA/B;AAEA,SAAS,gBAAT,QAAiC,sCAAjC;AAEA,SAA6B,UAA7B,QAA+C,eAA/C;AAEA,OAAO,IAAM,IAAI,GAAG;AAClB,EAAA,cAAc,EAAE,IAAI,cAAJ,EADE;AAElB,EAAA,gBAAgB,EAAE,IAAI,gBAAJ,EAFA;AAGlB,EAAA,UAAU,EAAE,IAAI,UAAJ,EAHM;AAIlB,EAAA,KAAK,EAAE,IAAI,KAAJ,EAJW;AAKlB,EAAA,iBAAiB,EAAE,IAAI,iBAAJ,EALD;AAMlB,EAAA,qBAAqB,EAAE,IAAI,qBAAJ,EANL;AAOlB,EAAA,kBAAkB,EAAE,IAAI,kBAAJ,EAPF;AAQlB,EAAA,iBAAiB,EAAE,IAAI,iBAAJ,EARD;AASlB,EAAA,YAAY,EAAE,IAAI,YAAJ;AATI,CAAb;AAYP;;;;;;AAMG;;AACH,OAAO,IAAM,cAAc,GAAG,SAAjB,cAAiB,CAAC,KAAD,EAAmB,OAAnB,EAAiD;AAC7E,SAAA,IAAI,CAAC,cAAL,CAAoB,WAApB,CAAgC,KAAhC,EAAuC,OAAvC,CAAA;AAA+C,CAD1C;AAGP;;;;;;AAMG;;AACH,OAAO,IAAM,gBAAgB,GAAG,SAAnB,gBAAmB,CAAC,KAAD,EAAmB,OAAnB,EAAmD;AACjF,SAAA,IAAI,CAAC,gBAAL,CAAsB,WAAtB,CAAkC,KAAlC,EAAyC,OAAzC,CAAA;AAAiD,CAD5C;AAGP;;;;;;AAMG;;AACH,OAAO,IAAM,UAAU,GAAG,SAAb,UAAa,CAAC,KAAD,EAAmB,OAAnB,EAA8C;AACtE,SAAA,IAAI,CAAC,UAAL,CAAgB,WAAhB,CAA4B,KAA5B,EAAmC,OAAnC,CAAA;AAA2C,CADtC;AAGP;;;;;;;AAOG;;AACH,OAAO,IAAM,KAAK,GAAG,SAAR,KAAQ,CAAC,KAAD,EAAmB,OAAnB,EAAwC;AAC3D,SAAA,IAAI,CAAC,KAAL,CAAW,OAAX,CAAmB,KAAnB,EAA0B,OAA1B,CAAA;AAAkC,CAD7B;AAGP;;;;;;AAMG;;AACH,OAAO,IAAM,mBAAmB,GAAG,SAAtB,mBAAsB,CAAC,KAAD,EAAiB;AAClD,SAAA,IAAI,CAAC,iBAAL,CAAuB,eAAvB,CAAuC,KAAvC,CAAA;AAA6C,CADxC;AAGP;;;;;;;;AAQG;;AACH,OAAO,IAAM,uBAAuB,GAAG,SAA1B,uBAA0B,CAAC,KAAD,EAAiB;AACtD,SAAA,IAAI,CAAC,qBAAL,CAA2B,eAA3B,CAA2C,KAA3C,CAAA;AAAiD,CAD5C;AAGP;;;;;;;;;AASG;;AACH,OAAO,IAAM,qBAAqB,GAAG,SAAxB,qBAAwB,CAAC,KAAD,EAAiB;AACpD,SAAA,IAAI,CAAC,kBAAL,CAAwB,qBAAxB,CAA8C,KAA9C,CAAA;AAAoD,CAD/C;AAIP;;;;;;AAMG;;AACH,OAAO,IAAM,wBAAwB,GAAG,SAA3B,wBAA2B,CAAC,KAAD,EAAiB;AACvD,SAAA,IAAI,CAAC,iBAAL,CAAuB,kBAAvB,CAA0C,KAA1C,CAAA;AAAgD,CAD3C;AAGP;;;;;;AAMG;;AACH,OAAO,IAAM,mBAAmB,GAAG,SAAtB,mBAAsB,CAAC,KAAD,EAAiB;AAClD,SAAA,IAAI,CAAC,YAAL,CAAkB,mBAAlB,CAAsC,KAAtC,CAAA;AAA4C,CADvC;AAGP,OAAO,IAAM,uBAAuB,GAAG,SAA1B,uBAA0B,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,cAAL,CAAoB,IAApB,CAAA,GAAA,CAAA;AAA6B,CAA9E;AACP,OAAO,IAAM,yBAAyB,GAAG,SAA5B,yBAA4B,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,gBAAL,CAAsB,IAAtB,CAAA,GAAA,CAAA;AAA+B,CAAlF;AACP,OAAO,IAAM,cAAc,GAAG,SAAjB,cAAiB,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,KAAL,CAAW,IAAX,CAAA,GAAA,CAAA;AAAoB,CAA5D;AACP,OAAO,IAAM,mBAAmB,GAAG,SAAtB,mBAAsB,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,UAAL,CAAgB,IAAhB,CAAA,GAAA,CAAA;AAAyB,CAAtE;AACP,OAAO,IAAM,qBAAqB,GAAG,SAAxB,qBAAwB,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,iBAAL,CAAuB,IAAvB,CAAA,GAAA,CAAA;AAAgC,CAA/E;AACP,OAAO,IAAM,yBAAyB,GAAG,SAA5B,yBAA4B,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,qBAAL,CAA2B,IAA3B,CAAA,GAAA,CAAA;AAAoC,CAAvF;AACP,OAAO,IAAM,wBAAwB,GAAG,SAA3B,wBAA2B,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,kBAAL,CAAwB,IAAxB,CAAA,GAAA,CAAA;AAAiC,CAAnF;AACP,OAAO,IAAM,uBAAuB,GAAG,SAA1B,uBAA0B,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,iBAAL,CAAuB,IAAvB,CAAA,GAAA,CAAA;AAAgC,CAAjF;AACP,OAAO,IAAM,kBAAkB,GAAG,SAArB,kBAAqB,CAAC,GAAD,EAAY;AAAK,SAAA,IAAI,CAAC,YAAL,CAAkB,IAAlB,CAAA,GAAA,CAAA;AAA2B,CAAvE,C,CAEP;;AACA,OAAO,IAAM,sBAAsB,GAAG,uBAA/B;AACP,OAAO,IAAM,WAAW,GAAG,cAApB;AACP,OAAO,IAAM,eAAe,GAAG,mBAAxB","sourceRoot":"","sourcesContent":["import { AgeGenderNet } from '../ageGenderNet/AgeGenderNet';\r\nimport { FaceExpressionNet } from '../faceExpressionNet/FaceExpressionNet';\r\nimport { FaceLandmark68Net } from '../faceLandmarkNet/FaceLandmark68Net';\r\nimport { FaceLandmark68TinyNet } from '../faceLandmarkNet/FaceLandmark68TinyNet';\r\nimport { FaceRecognitionNet } from '../faceRecognitionNet/FaceRecognitionNet';\r\nimport { Mtcnn } from '../mtcnn/Mtcnn';\r\nimport { SsdMobilenetv1 } from '../ssdMobilenetv1/SsdMobilenetv1';\r\nimport { TinyFaceDetector } from '../tinyFaceDetector/TinyFaceDetector';\r\nimport { TinyYolov2 } from '../tinyYolov2';\r\nexport var nets = {\r\n    ssdMobilenetv1: new SsdMobilenetv1(),\r\n    tinyFaceDetector: new TinyFaceDetector(),\r\n    tinyYolov2: new TinyYolov2(),\r\n    mtcnn: new Mtcnn(),\r\n    faceLandmark68Net: new FaceLandmark68Net(),\r\n    faceLandmark68TinyNet: new FaceLandmark68TinyNet(),\r\n    faceRecognitionNet: new FaceRecognitionNet(),\r\n    faceExpressionNet: new FaceExpressionNet(),\r\n    ageGenderNet: new AgeGenderNet()\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using SSD Mobilenetv1 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see SsdMobilenetv1Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nexport var ssdMobilenetv1 = function (input, options) {\r\n    return nets.ssdMobilenetv1.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using the Tiny Face Detector.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyFaceDetectorOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nexport var tinyFaceDetector = function (input, options) {\r\n    return nets.tinyFaceDetector.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image using the Tiny Yolov2 Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see TinyYolov2Options constructor for default parameters).\r\n * @returns Bounding box of each face with score.\r\n */\r\nexport var tinyYolov2 = function (input, options) {\r\n    return nets.tinyYolov2.locateFaces(input, options);\r\n};\r\n/**\r\n * Attempts to detect all faces in an image and the 5 point face landmarks\r\n * of each detected face using the MTCNN Network.\r\n *\r\n * @param input The input image.\r\n * @param options (optional, default: see MtcnnOptions constructor for default parameters).\r\n * @returns Bounding box of each face with score and 5 point face landmarks.\r\n */\r\nexport var mtcnn = function (input, options) {\r\n    return nets.mtcnn.forward(input, options);\r\n};\r\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\r\nexport var detectFaceLandmarks = function (input) {\r\n    return nets.faceLandmark68Net.detectLandmarks(input);\r\n};\r\n/**\r\n * Detects the 68 point face landmark positions of the face shown in an image\r\n * using a tinier version of the 68 point face landmark model, which is slightly\r\n * faster at inference, but also slightly less accurate.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns 68 point face landmarks or array thereof in case of batch input.\r\n */\r\nexport var detectFaceLandmarksTiny = function (input) {\r\n    return nets.faceLandmark68TinyNet.detectLandmarks(input);\r\n};\r\n/**\r\n * Computes a 128 entry vector (face descriptor / face embeddings) from the face shown in an image,\r\n * which uniquely represents the features of that persons face. The computed face descriptor can\r\n * be used to measure the similarity between faces, by computing the euclidean distance of two\r\n * face descriptors.\r\n *\r\n * @param inputs The face image extracted from the aligned bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Face descriptor with 128 entries or array thereof in case of batch input.\r\n */\r\nexport var computeFaceDescriptor = function (input) {\r\n    return nets.faceRecognitionNet.computeFaceDescriptor(input);\r\n};\r\n/**\r\n * Recognizes the facial expressions from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Facial expressions with corresponding probabilities or array thereof in case of batch input.\r\n */\r\nexport var recognizeFaceExpressions = function (input) {\r\n    return nets.faceExpressionNet.predictExpressions(input);\r\n};\r\n/**\r\n * Predicts age and gender from a face image.\r\n *\r\n * @param inputs The face image extracted from the bounding box of a face. Can\r\n * also be an array of input images, which will be batch processed.\r\n * @returns Predictions with age, gender and gender probability or array thereof in case of batch input.\r\n */\r\nexport var predictAgeAndGender = function (input) {\r\n    return nets.ageGenderNet.predictAgeAndGender(input);\r\n};\r\nexport var loadSsdMobilenetv1Model = function (url) { return nets.ssdMobilenetv1.load(url); };\r\nexport var loadTinyFaceDetectorModel = function (url) { return nets.tinyFaceDetector.load(url); };\r\nexport var loadMtcnnModel = function (url) { return nets.mtcnn.load(url); };\r\nexport var loadTinyYolov2Model = function (url) { return nets.tinyYolov2.load(url); };\r\nexport var loadFaceLandmarkModel = function (url) { return nets.faceLandmark68Net.load(url); };\r\nexport var loadFaceLandmarkTinyModel = function (url) { return nets.faceLandmark68TinyNet.load(url); };\r\nexport var loadFaceRecognitionModel = function (url) { return nets.faceRecognitionNet.load(url); };\r\nexport var loadFaceExpressionModel = function (url) { return nets.faceExpressionNet.load(url); };\r\nexport var loadAgeGenderModel = function (url) { return nets.ageGenderNet.load(url); };\r\n// backward compatibility\r\nexport var loadFaceDetectionModel = loadSsdMobilenetv1Model;\r\nexport var locateFaces = ssdMobilenetv1;\r\nexport var detectLandmarks = detectFaceLandmarks;\r\n//# sourceMappingURL=nets.js.map"]},"metadata":{},"sourceType":"module"}