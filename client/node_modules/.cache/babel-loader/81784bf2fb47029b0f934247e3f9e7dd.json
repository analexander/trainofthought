{"ast":null,"code":"import _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nimport _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\n\nfunction _createForOfIteratorHelper(o, allowArrayLike) { var it; if (typeof Symbol === \"undefined\" || o[Symbol.iterator] == null) { if (Array.isArray(o) || (it = _unsupportedIterableToArray(o)) || allowArrayLike && o && typeof o.length === \"number\") { if (it) o = it; var i = 0; var F = function F() {}; return { s: F, n: function n() { if (i >= o.length) return { done: true }; return { done: false, value: o[i++] }; }, e: function e(_e) { throw _e; }, f: F }; } throw new TypeError(\"Invalid attempt to iterate non-iterable instance.\\nIn order to be iterable, non-array objects must have a [Symbol.iterator]() method.\"); } var normalCompletion = true, didErr = false, err; return { s: function s() { it = o[Symbol.iterator](); }, n: function n() { var step = it.next(); normalCompletion = step.done; return step; }, e: function e(_e2) { didErr = true; err = _e2; }, f: function f() { try { if (!normalCompletion && it.return != null) it.return(); } finally { if (didErr) throw err; } } }; }\n\nfunction _unsupportedIterableToArray(o, minLen) { if (!o) return; if (typeof o === \"string\") return _arrayLikeToArray(o, minLen); var n = Object.prototype.toString.call(o).slice(8, -1); if (n === \"Object\" && o.constructor) n = o.constructor.name; if (n === \"Map\" || n === \"Set\") return Array.from(o); if (n === \"Arguments\" || /^(?:Ui|I)nt(?:8|16|32)(?:Clamped)?Array$/.test(n)) return _arrayLikeToArray(o, minLen); }\n\nfunction _arrayLikeToArray(arr, len) { if (len == null || len > arr.length) len = arr.length; for (var i = 0, arr2 = new Array(len); i < len; i++) { arr2[i] = arr[i]; } return arr2; }\n\n/**\n * @license\n * Copyright 2018 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n *\n * =============================================================================\n */\nimport * as tf from '@tensorflow/tfjs-core';\nimport * as seedrandom from 'seedrandom';\nimport { deepClone } from '../util/deep_clone';\nimport { deepMapAndAwaitAll, deepZip, zipToList } from '../util/deep_map';\nimport { GrowingRingBuffer } from '../util/growing_ring_buffer';\nimport { RingBuffer } from '../util/ring_buffer'; // Here we implement a simple asynchronous iterator.\n// This lets us avoid using either third-party stream libraries or\n// recent TypeScript language support requiring polyfills.\n\n/**\n * Create a `LazyIterator` from an array of items.\n */\n\nexport function iteratorFromItems(items) {\n  return new ArrayIterator(items);\n}\n/**\n * Create a `LazyIterator` of incrementing integers.\n */\n\nexport function iteratorFromIncrementing(start) {\n  var i = start;\n  return iteratorFromFunction(function () {\n    return {\n      value: i++,\n      done: false\n    };\n  });\n}\n/**\n * Create a `LazyIterator` from a function.\n *\n * ```js\n * let i = -1;\n * const func = () =>\n *    ++i < 5 ? {value: i, done: false} : {value: null, done: true};\n * const iter = tf.data.iteratorFromFunction(func);\n * await iter.forEachAsync(e => console.log(e));\n * ```\n *\n * @param func A function that produces data on each call.\n */\n\nexport function iteratorFromFunction(func) {\n  return new FunctionCallIterator(func);\n}\n/**\n * Create a `LazyIterator` by concatenating underlying streams, which are\n * themselves provided as a stream.\n *\n * This can also be thought of as a \"stream flatten\" operation.\n *\n * @param baseIterators A stream of streams to be concatenated.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\n\nexport function iteratorFromConcatenated(baseIterators, baseErrorHandler) {\n  return new ChainedIterator(baseIterators, baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by concatenating streams produced by calling a\n * stream-generating function a given number of times.\n *\n * Since a `LazyIterator` is read-once, it cannot be repeated, but this\n * function can be used to achieve a similar effect:\n *\n *   LazyIterator.ofConcatenatedFunction(() => new MyIterator(), 6);\n *\n * @param iteratorFunc: A function that produces a new stream on each call.\n * @param count: The number of times to call the function.\n * @param baseErrorHandler An optional function that can intercept `Error`s\n *   raised during a `next()` call on the base stream.  This function can decide\n *   whether the error should be propagated, whether the error should be\n *   ignored, or whether the base stream should be terminated.\n */\n\nexport function iteratorFromConcatenatedFunction(iteratorFunc, count, baseErrorHandler) {\n  return iteratorFromConcatenated(iteratorFromFunction(iteratorFunc).take(count), baseErrorHandler);\n}\n/**\n * Create a `LazyIterator` by zipping together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\n\nexport function iteratorFromZipped(iterators) {\n  var mismatchMode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;\n  return new ZipIterator(iterators, mismatchMode);\n}\n/**\n * An asynchronous iterator, providing lazy access to a potentially\n * unbounded stream of elements.\n *\n * Iterator can be obtained from a dataset:\n * `const iter = await dataset.iterator();`\n */\n\nexport var LazyIterator = /*#__PURE__*/function () {\n  function LazyIterator() {\n    _classCallCheck(this, LazyIterator);\n  }\n\n  _createClass(LazyIterator, [{\n    key: \"toArray\",\n\n    /**\n     * Collect all remaining elements of a bounded stream into an array.\n     * Obviously this will succeed only for small streams that fit in memory.\n     * Useful for testing.\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n    value: function () {\n      var _toArray = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n        var result, x;\n        return _regeneratorRuntime.wrap(function _callee$(_context) {\n          while (1) {\n            switch (_context.prev = _context.next) {\n              case 0:\n                result = [];\n                _context.next = 3;\n                return this.next();\n\n              case 3:\n                x = _context.sent;\n\n              case 4:\n                if (x.done) {\n                  _context.next = 11;\n                  break;\n                }\n\n                result.push(x.value);\n                _context.next = 8;\n                return this.next();\n\n              case 8:\n                x = _context.sent;\n                _context.next = 4;\n                break;\n\n              case 11:\n                return _context.abrupt(\"return\", result);\n\n              case 12:\n              case \"end\":\n                return _context.stop();\n            }\n          }\n        }, _callee, this);\n      }));\n\n      function toArray() {\n        return _toArray.apply(this, arguments);\n      }\n\n      return toArray;\n    }()\n    /**\n     * Collect all elements of this dataset into an array with prefetching 100\n     * elements. This is useful for testing, because the prefetch changes the\n     * order in which the Promises are resolved along the processing pipeline.\n     * This may help expose bugs where results are dependent on the order of\n     * Promise resolution rather than on the logical order of the stream (i.e.,\n     * due to hidden mutable state).\n     *\n     * @returns A Promise for an array of stream elements, which will resolve\n     *   when the stream is exhausted.\n     */\n\n  }, {\n    key: \"toArrayForTest\",\n    value: function () {\n      var _toArrayForTest = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n        var stream, result, x;\n        return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n          while (1) {\n            switch (_context2.prev = _context2.next) {\n              case 0:\n                stream = this.prefetch(100);\n                result = [];\n                _context2.next = 4;\n                return stream.next();\n\n              case 4:\n                x = _context2.sent;\n\n              case 5:\n                if (x.done) {\n                  _context2.next = 12;\n                  break;\n                }\n\n                result.push(x.value);\n                _context2.next = 9;\n                return stream.next();\n\n              case 9:\n                x = _context2.sent;\n                _context2.next = 5;\n                break;\n\n              case 12:\n                return _context2.abrupt(\"return\", result);\n\n              case 13:\n              case \"end\":\n                return _context2.stop();\n            }\n          }\n        }, _callee2, this);\n      }));\n\n      function toArrayForTest() {\n        return _toArrayForTest.apply(this, arguments);\n      }\n\n      return toArrayForTest;\n    }()\n    /**\n     * Draw items from the stream until it is exhausted.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n\n  }, {\n    key: \"resolveFully\",\n    value: function () {\n      var _resolveFully = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3() {\n        var x;\n        return _regeneratorRuntime.wrap(function _callee3$(_context3) {\n          while (1) {\n            switch (_context3.prev = _context3.next) {\n              case 0:\n                _context3.next = 2;\n                return this.next();\n\n              case 2:\n                x = _context3.sent;\n\n              case 3:\n                if (x.done) {\n                  _context3.next = 9;\n                  break;\n                }\n\n                _context3.next = 6;\n                return this.next();\n\n              case 6:\n                x = _context3.sent;\n                _context3.next = 3;\n                break;\n\n              case 9:\n              case \"end\":\n                return _context3.stop();\n            }\n          }\n        }, _callee3, this);\n      }));\n\n      function resolveFully() {\n        return _resolveFully.apply(this, arguments);\n      }\n\n      return resolveFully;\n    }()\n    /**\n     * Draw items from the stream until it is exhausted, or a predicate fails.\n     *\n     * This can be useful when the stream has side effects but no output.  In\n     * that case, calling this function guarantees that the stream will be\n     * fully processed.\n     */\n\n  }, {\n    key: \"resolveWhile\",\n    value: function () {\n      var _resolveWhile = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee4(predicate) {\n        var x, shouldContinue;\n        return _regeneratorRuntime.wrap(function _callee4$(_context4) {\n          while (1) {\n            switch (_context4.prev = _context4.next) {\n              case 0:\n                _context4.next = 2;\n                return this.next();\n\n              case 2:\n                x = _context4.sent;\n                shouldContinue = predicate(x.value);\n\n              case 4:\n                if (!(!x.done && shouldContinue)) {\n                  _context4.next = 11;\n                  break;\n                }\n\n                _context4.next = 7;\n                return this.next();\n\n              case 7:\n                x = _context4.sent;\n                shouldContinue = predicate(x.value);\n                _context4.next = 4;\n                break;\n\n              case 11:\n              case \"end\":\n                return _context4.stop();\n            }\n          }\n        }, _callee4, this);\n      }));\n\n      function resolveWhile(_x) {\n        return _resolveWhile.apply(this, arguments);\n      }\n\n      return resolveWhile;\n    }()\n    /**\n     * Handles errors thrown on this stream using a provided handler function.\n     *\n     * @param handler A function that handles any `Error` thrown during a `next()`\n     *   call and returns true if the stream should continue (dropping the failed\n     *   call) or false if the stream should quietly terminate.  If the handler\n     *   itself throws (or rethrows) an `Error`, that will be propagated.\n     *\n     * @returns A `LazyIterator` of elements passed through from upstream,\n     *   possibly filtering or terminating on upstream `next()` calls that\n     *   throw an `Error`.\n     */\n\n  }, {\n    key: \"handleErrors\",\n    value: function handleErrors(handler) {\n      return new ErrorHandlingLazyIterator(this, handler);\n    } // TODO(soergel): Implement reduce() etc.\n\n    /**\n     * Filters this stream according to `predicate`.\n     *\n     * @param predicate A function mapping a stream element to a boolean or a\n     * `Promise` for one.\n     *\n     * @returns A `LazyIterator` of elements for which the predicate was true.\n     */\n\n  }, {\n    key: \"filter\",\n    value: function filter(predicate) {\n      return new FilterIterator(this, predicate);\n    }\n    /**\n     * Maps this stream through a 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n\n  }, {\n    key: \"map\",\n    value: function map(transform) {\n      return new MapIterator(this, transform);\n    }\n    /**\n     * Maps this stream through an async 1-to-1 transform.\n     *\n     * @param transform A function mapping a stream element to a `Promise` for a\n     *   transformed stream element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n\n  }, {\n    key: \"mapAsync\",\n    value: function mapAsync(transform) {\n      return new AsyncMapIterator(this, transform);\n    }\n    /**\n     * Maps this stream through a 1-to-1 transform, forcing serial execution.\n     *\n     * @param transform A function mapping a stream element to a transformed\n     *   element.\n     *\n     * @returns A `LazyIterator` of transformed elements.\n     */\n\n  }, {\n    key: \"serialMapAsync\",\n    value: function serialMapAsync(transform) {\n      return new AsyncMapIterator(this, transform).serial();\n    }\n    /**\n     * Maps this stream through a 1-to-many transform.\n     *\n     * @param transform A function mapping a stream element to an array of\n     *   transformed elements.\n     *\n     * @returns A `DataStream` of transformed elements.\n     */\n\n  }, {\n    key: \"flatmap\",\n    value: function flatmap(transform) {\n      return new FlatmapIterator(this, transform);\n    }\n    /**\n     * Apply a function to every element of the stream.\n     *\n     * @param f A function to apply to each stream element.\n     */\n\n  }, {\n    key: \"forEachAsync\",\n    value: function () {\n      var _forEachAsync = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee5(f) {\n        return _regeneratorRuntime.wrap(function _callee5$(_context5) {\n          while (1) {\n            switch (_context5.prev = _context5.next) {\n              case 0:\n                return _context5.abrupt(\"return\", this.map(f).resolveFully());\n\n              case 1:\n              case \"end\":\n                return _context5.stop();\n            }\n          }\n        }, _callee5, this);\n      }));\n\n      function forEachAsync(_x2) {\n        return _forEachAsync.apply(this, arguments);\n      }\n\n      return forEachAsync;\n    }()\n    /**\n     * Apply a function to every element of the stream, forcing serial execution.\n     *\n     * @param f A function to apply to each stream element.  Should return 'true'\n     *   to indicate that the stream should continue, or 'false' to cause it to\n     *   terminate.\n     */\n\n  }, {\n    key: \"serialForEach\",\n    value: function () {\n      var _serialForEach = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee6(f) {\n        return _regeneratorRuntime.wrap(function _callee6$(_context6) {\n          while (1) {\n            switch (_context6.prev = _context6.next) {\n              case 0:\n                return _context6.abrupt(\"return\", this.serialMapAsync(f).resolveWhile(function (x) {\n                  return x === true;\n                }));\n\n              case 1:\n              case \"end\":\n                return _context6.stop();\n            }\n          }\n        }, _callee6, this);\n      }));\n\n      function serialForEach(_x3) {\n        return _serialForEach.apply(this, arguments);\n      }\n\n      return serialForEach;\n    }()\n    /**\n     * Groups elements into batches, represented as arrays of elements.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"Row-major\" means that the resulting batch is simply a collection of\n     * rows: `[row1, row2, row3, ...]`.  This is contrast to the column-major\n     * form, which is needed for vectorized computation.\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @returns A `LazyIterator` of batches of elements, represented as arrays\n     *   of the original element type.\n     */\n\n  }, {\n    key: \"rowMajorBatch\",\n    value: function rowMajorBatch(batchSize) {\n      var smallLastBatch = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      return new RowMajorBatchIterator(this, batchSize, smallLastBatch);\n    }\n    /**\n     * Groups elements into batches, represented in column-major form.\n     *\n     * We can think of the elements of this iterator as 'rows' (even if they are\n     * nested structures).  By the same token, consecutive values for a given\n     * key within the elements form a 'column'.  This matches the usual sense of\n     * 'row' and 'column' when processing tabular data (e.g., parsing a CSV).\n     *\n     * Thus, \"column-major\" means that the resulting batch is a (potentially\n     * nested) structure representing the columns.  Each column entry, then,\n     * contains a collection of the values found in that column for a range of\n     * input elements.  This representation allows for vectorized computation, in\n     * contrast to the row-major form.\n     *\n     * The inputs should all have the same nested structure (i.e., of arrays and\n     * dicts).  The result is a single object with the same nested structure,\n     * where the leaves are arrays collecting the values of the inputs at that\n     * location (or, optionally, the result of a custom function applied to those\n     * arrays).\n     *\n     * @param batchSize The number of elements desired per batch.\n     * @param smallLastBatch Whether to emit the final batch when it has fewer\n     *   than batchSize elements. Default true.\n     * @param zipFn: (optional) A function that expects an array of elements at a\n     *   single node of the object tree, and returns a `DeepMapResult`.  The\n     *   `DeepMapResult` either provides a result value for that node (i.e.,\n     *   representing the subtree), or indicates that the node should be processed\n     *   recursively.  The default zipFn recurses as far as possible and places\n     *   arrays at the leaves.\n     * @returns A `LazyIterator` of batches of elements, represented as an object\n     *   with collections at the leaves.\n     */\n\n  }, {\n    key: \"columnMajorBatch\",\n    value: function columnMajorBatch(batchSize) {\n      var smallLastBatch = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : true;\n      var zipFn = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : zipToList;\n      // First collect the desired number of input elements as a row-major batch.\n      var rowBatches = this.rowMajorBatch(batchSize, smallLastBatch); // Now 'rotate' or 'pivot' the data, collecting all values from each column\n      // in the batch (i.e., for each key within the elements) into an array.\n\n      return rowBatches.map(function (x) {\n        return deepZip(x, zipFn);\n      });\n    }\n    /**\n     * Concatenate this `LazyIterator` with another.\n     *\n     * @param iterator A `LazyIterator` to be concatenated onto this one.\n     * @param baseErrorHandler An optional function that can intercept `Error`s\n     *   raised during a `next()` call on the base stream.  This function can\n     *   decide whether the error should be propagated, whether the error should\n     *   be ignored, or whether the base stream should be terminated.\n     * @returns A `LazyIterator`.\n     */\n\n  }, {\n    key: \"concatenate\",\n    value: function concatenate(iterator, baseErrorHandler) {\n      return new ChainedIterator(iteratorFromItems([this, iterator]), baseErrorHandler);\n    }\n    /**\n     * Limits this stream to return at most `count` items.\n     *\n     * @param count The maximum number of items to provide from the stream. If\n     * a negative or undefined value is given, the entire stream is returned\n     *   unaltered.\n     */\n\n  }, {\n    key: \"take\",\n    value: function take(count) {\n      if (count < 0 || count == null) {\n        return this;\n      }\n\n      return new TakeIterator(this, count);\n    }\n    /**\n     * Skips the first `count` items in this stream.\n     *\n     * @param count The number of items to skip.  If a negative or undefined\n     * value is given, the entire stream is returned unaltered.\n     */\n\n  }, {\n    key: \"skip\",\n    value: function skip(count) {\n      if (count < 0 || count == null) {\n        return this;\n      }\n\n      return new SkipIterator(this, count);\n    }\n    /**\n     * Prefetch the first `bufferSize` items in this stream.\n     *\n     * Note this prefetches Promises, but makes no guarantees about when those\n     * Promises resolve.\n     *\n     * @param bufferSize: An integer specifying the number of elements to be\n     *   prefetched.\n     */\n\n  }, {\n    key: \"prefetch\",\n    value: function prefetch(bufferSize) {\n      return new PrefetchIterator(this, bufferSize);\n    } // TODO(soergel): deep sharded shuffle, where supported\n\n    /**\n     * Randomly shuffles the elements of this stream.\n     *\n     * @param bufferSize: An integer specifying the number of elements from\n     * this stream from which the new stream will sample.\n     * @param seed: (Optional.) An integer specifying the random seed that\n     * will be used to create the distribution.\n     */\n\n  }, {\n    key: \"shuffle\",\n    value: function shuffle(windowSize, seed) {\n      return new ShuffleIterator(this, windowSize, seed);\n    }\n    /**\n     * Force an iterator to execute serially: each next() call will await the\n     * prior one, so that they cannot execute concurrently.\n     */\n\n  }, {\n    key: \"serial\",\n    value: function serial() {\n      return new SerialIterator(this);\n    }\n  }]);\n\n  return LazyIterator;\n}(); // ============================================================================\n// The following private classes serve to implement the chainable methods\n// on LazyIterator.  Unfortunately they can't be placed in separate files,\n// due to resulting trouble with circular imports.\n// ============================================================================\n// Iterators that just extend LazyIterator directly\n// ============================================================================\n\nvar ArrayIterator = /*#__PURE__*/function (_LazyIterator) {\n  _inherits(ArrayIterator, _LazyIterator);\n\n  function ArrayIterator(items) {\n    var _this;\n\n    _classCallCheck(this, ArrayIterator);\n\n    _this = _possibleConstructorReturn(this, _getPrototypeOf(ArrayIterator).call(this));\n    _this.items = items;\n    _this.trav = 0;\n    return _this;\n  }\n\n  _createClass(ArrayIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"Array of \".concat(this.items.length, \" items\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee7() {\n        var item;\n        return _regeneratorRuntime.wrap(function _callee7$(_context7) {\n          while (1) {\n            switch (_context7.prev = _context7.next) {\n              case 0:\n                if (!(this.trav >= this.items.length)) {\n                  _context7.next = 2;\n                  break;\n                }\n\n                return _context7.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 2:\n                item = this.items[this.trav];\n                this.trav++;\n                return _context7.abrupt(\"return\", {\n                  value: deepClone(item),\n                  done: false\n                });\n\n              case 5:\n              case \"end\":\n                return _context7.stop();\n            }\n          }\n        }, _callee7, this);\n      }));\n\n      function next() {\n        return _next.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return ArrayIterator;\n}(LazyIterator);\n\nvar FunctionCallIterator = /*#__PURE__*/function (_LazyIterator2) {\n  _inherits(FunctionCallIterator, _LazyIterator2);\n\n  function FunctionCallIterator(nextFn) {\n    var _this2;\n\n    _classCallCheck(this, FunctionCallIterator);\n\n    _this2 = _possibleConstructorReturn(this, _getPrototypeOf(FunctionCallIterator).call(this));\n    _this2.nextFn = nextFn;\n    return _this2;\n  }\n\n  _createClass(FunctionCallIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"Function call\";\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee8() {\n        return _regeneratorRuntime.wrap(function _callee8$(_context8) {\n          while (1) {\n            switch (_context8.prev = _context8.next) {\n              case 0:\n                _context8.prev = 0;\n                return _context8.abrupt(\"return\", this.nextFn());\n\n              case 4:\n                _context8.prev = 4;\n                _context8.t0 = _context8[\"catch\"](0);\n                // Modify the error message but leave the stack trace intact\n                _context8.t0.message = \"Error thrown while iterating through a dataset: \".concat(_context8.t0.message);\n                throw _context8.t0;\n\n              case 8:\n              case \"end\":\n                return _context8.stop();\n            }\n          }\n        }, _callee8, this, [[0, 4]]);\n      }));\n\n      function next() {\n        return _next2.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return FunctionCallIterator;\n}(LazyIterator);\n\nvar SerialIterator = /*#__PURE__*/function (_LazyIterator3) {\n  _inherits(SerialIterator, _LazyIterator3);\n\n  function SerialIterator(upstream) {\n    var _this3;\n\n    _classCallCheck(this, SerialIterator);\n\n    _this3 = _possibleConstructorReturn(this, _getPrototypeOf(SerialIterator).call(this));\n    _this3.upstream = upstream;\n    _this3.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this3;\n  }\n\n  _createClass(SerialIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Serial\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee9() {\n        var _this4 = this;\n\n        return _regeneratorRuntime.wrap(function _callee9$(_context9) {\n          while (1) {\n            switch (_context9.prev = _context9.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this4.serialNext();\n                });\n                return _context9.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context9.stop();\n            }\n          }\n        }, _callee9, this);\n      }));\n\n      function next() {\n        return _next3.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee10() {\n        return _regeneratorRuntime.wrap(function _callee10$(_context10) {\n          while (1) {\n            switch (_context10.prev = _context10.next) {\n              case 0:\n                return _context10.abrupt(\"return\", this.upstream.next());\n\n              case 1:\n              case \"end\":\n                return _context10.stop();\n            }\n          }\n        }, _callee10, this);\n      }));\n\n      function serialNext() {\n        return _serialNext.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return SerialIterator;\n}(LazyIterator);\n\nvar SkipIterator = /*#__PURE__*/function (_LazyIterator4) {\n  _inherits(SkipIterator, _LazyIterator4);\n\n  function SkipIterator(upstream, maxCount) {\n    var _this5;\n\n    _classCallCheck(this, SkipIterator);\n\n    _this5 = _possibleConstructorReturn(this, _getPrototypeOf(SkipIterator).call(this));\n    _this5.upstream = upstream;\n    _this5.maxCount = maxCount; // Local state that should not be clobbered by out-of-order execution.\n\n    _this5.count = 0;\n    _this5.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this5;\n  }\n\n  _createClass(SkipIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Skip\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee11() {\n        var _this6 = this;\n\n        return _regeneratorRuntime.wrap(function _callee11$(_context11) {\n          while (1) {\n            switch (_context11.prev = _context11.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this6.serialNext();\n                });\n                return _context11.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context11.stop();\n            }\n          }\n        }, _callee11, this);\n      }));\n\n      function next() {\n        return _next4.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee12() {\n        var skipped;\n        return _regeneratorRuntime.wrap(function _callee12$(_context12) {\n          while (1) {\n            switch (_context12.prev = _context12.next) {\n              case 0:\n                if (!(this.count++ < this.maxCount)) {\n                  _context12.next = 9;\n                  break;\n                }\n\n                _context12.next = 3;\n                return this.upstream.next();\n\n              case 3:\n                skipped = _context12.sent;\n\n                if (!skipped.done) {\n                  _context12.next = 6;\n                  break;\n                }\n\n                return _context12.abrupt(\"return\", skipped);\n\n              case 6:\n                tf.dispose(skipped.value);\n                _context12.next = 0;\n                break;\n\n              case 9:\n                return _context12.abrupt(\"return\", this.upstream.next());\n\n              case 10:\n              case \"end\":\n                return _context12.stop();\n            }\n          }\n        }, _callee12, this);\n      }));\n\n      function serialNext() {\n        return _serialNext2.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return SkipIterator;\n}(LazyIterator);\n\nvar TakeIterator = /*#__PURE__*/function (_LazyIterator5) {\n  _inherits(TakeIterator, _LazyIterator5);\n\n  function TakeIterator(upstream, maxCount) {\n    var _this7;\n\n    _classCallCheck(this, TakeIterator);\n\n    _this7 = _possibleConstructorReturn(this, _getPrototypeOf(TakeIterator).call(this));\n    _this7.upstream = upstream;\n    _this7.maxCount = maxCount;\n    _this7.count = 0;\n    return _this7;\n  }\n\n  _createClass(TakeIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Take\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee13() {\n        return _regeneratorRuntime.wrap(function _callee13$(_context13) {\n          while (1) {\n            switch (_context13.prev = _context13.next) {\n              case 0:\n                if (!(this.count++ >= this.maxCount)) {\n                  _context13.next = 2;\n                  break;\n                }\n\n                return _context13.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 2:\n                return _context13.abrupt(\"return\", this.upstream.next());\n\n              case 3:\n              case \"end\":\n                return _context13.stop();\n            }\n          }\n        }, _callee13, this);\n      }));\n\n      function next() {\n        return _next5.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return TakeIterator;\n}(LazyIterator); // Note this batch just groups items into row-wise element arrays.\n// Rotating these to a column-wise representation happens only at the dataset\n// level.\n\n\nvar RowMajorBatchIterator = /*#__PURE__*/function (_LazyIterator6) {\n  _inherits(RowMajorBatchIterator, _LazyIterator6);\n\n  function RowMajorBatchIterator(upstream, batchSize) {\n    var _this8;\n\n    var enableSmallLastBatch = arguments.length > 2 && arguments[2] !== undefined ? arguments[2] : true;\n\n    _classCallCheck(this, RowMajorBatchIterator);\n\n    _this8 = _possibleConstructorReturn(this, _getPrototypeOf(RowMajorBatchIterator).call(this));\n    _this8.upstream = upstream;\n    _this8.batchSize = batchSize;\n    _this8.enableSmallLastBatch = enableSmallLastBatch;\n    _this8.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this8;\n  }\n\n  _createClass(RowMajorBatchIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> RowMajorBatch\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next6 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee14() {\n        var _this9 = this;\n\n        return _regeneratorRuntime.wrap(function _callee14$(_context14) {\n          while (1) {\n            switch (_context14.prev = _context14.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this9.serialNext();\n                });\n                return _context14.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context14.stop();\n            }\n          }\n        }, _callee14, this);\n      }));\n\n      function next() {\n        return _next6.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext3 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee15() {\n        var batch, item;\n        return _regeneratorRuntime.wrap(function _callee15$(_context15) {\n          while (1) {\n            switch (_context15.prev = _context15.next) {\n              case 0:\n                batch = [];\n\n              case 1:\n                if (!(batch.length < this.batchSize)) {\n                  _context15.next = 12;\n                  break;\n                }\n\n                _context15.next = 4;\n                return this.upstream.next();\n\n              case 4:\n                item = _context15.sent;\n\n                if (!item.done) {\n                  _context15.next = 9;\n                  break;\n                }\n\n                if (!(this.enableSmallLastBatch && batch.length > 0)) {\n                  _context15.next = 8;\n                  break;\n                }\n\n                return _context15.abrupt(\"return\", {\n                  value: batch,\n                  done: false\n                });\n\n              case 8:\n                return _context15.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 9:\n                batch.push(item.value);\n                _context15.next = 1;\n                break;\n\n              case 12:\n                return _context15.abrupt(\"return\", {\n                  value: batch,\n                  done: false\n                });\n\n              case 13:\n              case \"end\":\n                return _context15.stop();\n            }\n          }\n        }, _callee15, this);\n      }));\n\n      function serialNext() {\n        return _serialNext3.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return RowMajorBatchIterator;\n}(LazyIterator);\n\nvar FilterIterator = /*#__PURE__*/function (_LazyIterator7) {\n  _inherits(FilterIterator, _LazyIterator7);\n\n  function FilterIterator(upstream, predicate) {\n    var _this10;\n\n    _classCallCheck(this, FilterIterator);\n\n    _this10 = _possibleConstructorReturn(this, _getPrototypeOf(FilterIterator).call(this));\n    _this10.upstream = upstream;\n    _this10.predicate = predicate;\n    _this10.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this10;\n  }\n\n  _createClass(FilterIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Filter\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next7 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee16() {\n        var _this11 = this;\n\n        return _regeneratorRuntime.wrap(function _callee16$(_context16) {\n          while (1) {\n            switch (_context16.prev = _context16.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this11.serialNext();\n                });\n                return _context16.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context16.stop();\n            }\n          }\n        }, _callee16, this);\n      }));\n\n      function next() {\n        return _next7.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext4 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee17() {\n        var item;\n        return _regeneratorRuntime.wrap(function _callee17$(_context17) {\n          while (1) {\n            switch (_context17.prev = _context17.next) {\n              case 0:\n                if (!true) {\n                  _context17.next = 9;\n                  break;\n                }\n\n                _context17.next = 3;\n                return this.upstream.next();\n\n              case 3:\n                item = _context17.sent;\n\n                if (!(item.done || this.predicate(item.value))) {\n                  _context17.next = 6;\n                  break;\n                }\n\n                return _context17.abrupt(\"return\", item);\n\n              case 6:\n                tf.dispose(item.value);\n                _context17.next = 0;\n                break;\n\n              case 9:\n              case \"end\":\n                return _context17.stop();\n            }\n          }\n        }, _callee17, this);\n      }));\n\n      function serialNext() {\n        return _serialNext4.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return FilterIterator;\n}(LazyIterator);\n\nvar MapIterator = /*#__PURE__*/function (_LazyIterator8) {\n  _inherits(MapIterator, _LazyIterator8);\n\n  function MapIterator(upstream, transform) {\n    var _this12;\n\n    _classCallCheck(this, MapIterator);\n\n    _this12 = _possibleConstructorReturn(this, _getPrototypeOf(MapIterator).call(this));\n    _this12.upstream = upstream;\n    _this12.transform = transform;\n    return _this12;\n  }\n\n  _createClass(MapIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Map\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next8 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee18() {\n        var item, inputTensors, mapped, outputTensors, _iterator, _step, t;\n\n        return _regeneratorRuntime.wrap(function _callee18$(_context18) {\n          while (1) {\n            switch (_context18.prev = _context18.next) {\n              case 0:\n                _context18.next = 2;\n                return this.upstream.next();\n\n              case 2:\n                item = _context18.sent;\n\n                if (!item.done) {\n                  _context18.next = 5;\n                  break;\n                }\n\n                return _context18.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 5:\n                inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n                // That's why we have to remember the input Tensors above, and then\n                // below dispose only those that were not passed through to the output.\n                // Note too that the transform function is responsible for tidying\n                // any intermediate Tensors.  Here we are concerned only about the\n                // inputs.\n\n                mapped = this.transform(item.value);\n                outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n                // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n                _iterator = _createForOfIteratorHelper(inputTensors);\n\n                try {\n                  for (_iterator.s(); !(_step = _iterator.n()).done;) {\n                    t = _step.value;\n\n                    if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                      t.dispose();\n                    }\n                  }\n                } catch (err) {\n                  _iterator.e(err);\n                } finally {\n                  _iterator.f();\n                }\n\n                return _context18.abrupt(\"return\", {\n                  value: mapped,\n                  done: false\n                });\n\n              case 11:\n              case \"end\":\n                return _context18.stop();\n            }\n          }\n        }, _callee18, this);\n      }));\n\n      function next() {\n        return _next8.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return MapIterator;\n}(LazyIterator);\n\nvar ErrorHandlingLazyIterator = /*#__PURE__*/function (_LazyIterator9) {\n  _inherits(ErrorHandlingLazyIterator, _LazyIterator9);\n\n  function ErrorHandlingLazyIterator(upstream, handler) {\n    var _this13;\n\n    _classCallCheck(this, ErrorHandlingLazyIterator);\n\n    _this13 = _possibleConstructorReturn(this, _getPrototypeOf(ErrorHandlingLazyIterator).call(this));\n    _this13.upstream = upstream;\n    _this13.handler = handler;\n    _this13.count = 0;\n    _this13.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this13;\n  }\n\n  _createClass(ErrorHandlingLazyIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> handleErrors\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next9 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee19() {\n        var _this14 = this;\n\n        return _regeneratorRuntime.wrap(function _callee19$(_context19) {\n          while (1) {\n            switch (_context19.prev = _context19.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this14.serialNext();\n                });\n                return _context19.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context19.stop();\n            }\n          }\n        }, _callee19, this);\n      }));\n\n      function next() {\n        return _next9.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext5 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee20() {\n        return _regeneratorRuntime.wrap(function _callee20$(_context20) {\n          while (1) {\n            switch (_context20.prev = _context20.next) {\n              case 0:\n                if (!true) {\n                  _context20.next = 13;\n                  break;\n                }\n\n                _context20.prev = 1;\n                _context20.next = 4;\n                return this.upstream.next();\n\n              case 4:\n                return _context20.abrupt(\"return\", _context20.sent);\n\n              case 7:\n                _context20.prev = 7;\n                _context20.t0 = _context20[\"catch\"](1);\n\n                if (this.handler(_context20.t0)) {\n                  _context20.next = 11;\n                  break;\n                }\n\n                return _context20.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 11:\n                _context20.next = 0;\n                break;\n\n              case 13:\n              case \"end\":\n                return _context20.stop();\n            }\n          }\n        }, _callee20, this, [[1, 7]]);\n      }));\n\n      function serialNext() {\n        return _serialNext5.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return ErrorHandlingLazyIterator;\n}(LazyIterator);\n\nvar AsyncMapIterator = /*#__PURE__*/function (_LazyIterator10) {\n  _inherits(AsyncMapIterator, _LazyIterator10);\n\n  function AsyncMapIterator(upstream, transform) {\n    var _this15;\n\n    _classCallCheck(this, AsyncMapIterator);\n\n    _this15 = _possibleConstructorReturn(this, _getPrototypeOf(AsyncMapIterator).call(this));\n    _this15.upstream = upstream;\n    _this15.transform = transform;\n    return _this15;\n  }\n\n  _createClass(AsyncMapIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> AsyncMap\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next10 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee21() {\n        var item, inputTensors, mapped, outputTensors, _iterator2, _step2, t;\n\n        return _regeneratorRuntime.wrap(function _callee21$(_context21) {\n          while (1) {\n            switch (_context21.prev = _context21.next) {\n              case 0:\n                _context21.next = 2;\n                return this.upstream.next();\n\n              case 2:\n                item = _context21.sent;\n\n                if (!item.done) {\n                  _context21.next = 5;\n                  break;\n                }\n\n                return _context21.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 5:\n                inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n                // That's why we have to remember the input Tensors above, and then\n                // below dispose only those that were not passed through to the output.\n                // Note too that the transform function is responsible for tidying\n                // any intermediate Tensors.  Here we are concerned only about the\n                // inputs.\n\n                _context21.next = 8;\n                return this.transform(item.value);\n\n              case 8:\n                mapped = _context21.sent;\n                outputTensors = tf.tensor_util.getTensorsInContainer(mapped); // TODO(soergel) faster intersection\n                // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n                _iterator2 = _createForOfIteratorHelper(inputTensors);\n\n                try {\n                  for (_iterator2.s(); !(_step2 = _iterator2.n()).done;) {\n                    t = _step2.value;\n\n                    if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                      t.dispose();\n                    }\n                  }\n                } catch (err) {\n                  _iterator2.e(err);\n                } finally {\n                  _iterator2.f();\n                }\n\n                return _context21.abrupt(\"return\", {\n                  value: mapped,\n                  done: false\n                });\n\n              case 13:\n              case \"end\":\n                return _context21.stop();\n            }\n          }\n        }, _callee21, this);\n      }));\n\n      function next() {\n        return _next10.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return AsyncMapIterator;\n}(LazyIterator); // Iterators that maintain a queue of pending items\n// ============================================================================\n\n/**\n * A base class for transforming streams that operate by maintaining an\n * output queue of elements that are ready to return via next().  This is\n * commonly required when the transformation is 1-to-many:  A call to next()\n * may trigger a call to the underlying stream, which will produce many\n * mapped elements of this stream-- of which we need to return only one, so\n * we have to queue the rest.\n */\n\n\nexport var OneToManyIterator = /*#__PURE__*/function (_LazyIterator11) {\n  _inherits(OneToManyIterator, _LazyIterator11);\n\n  function OneToManyIterator() {\n    var _this16;\n\n    _classCallCheck(this, OneToManyIterator);\n\n    _this16 = _possibleConstructorReturn(this, _getPrototypeOf(OneToManyIterator).call(this));\n    _this16.outputQueue = new GrowingRingBuffer();\n    _this16.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this16;\n  }\n\n  _createClass(OneToManyIterator, [{\n    key: \"next\",\n    value: function () {\n      var _next11 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee22() {\n        var _this17 = this;\n\n        return _regeneratorRuntime.wrap(function _callee22$(_context22) {\n          while (1) {\n            switch (_context22.prev = _context22.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this17.serialNext();\n                });\n                return _context22.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context22.stop();\n            }\n          }\n        }, _callee22, this);\n      }));\n\n      function next() {\n        return _next11.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext6 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee23() {\n        return _regeneratorRuntime.wrap(function _callee23$(_context23) {\n          while (1) {\n            switch (_context23.prev = _context23.next) {\n              case 0:\n                if (!(this.outputQueue.length() === 0)) {\n                  _context23.next = 7;\n                  break;\n                }\n\n                _context23.next = 3;\n                return this.pump();\n\n              case 3:\n                if (_context23.sent) {\n                  _context23.next = 5;\n                  break;\n                }\n\n                return _context23.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 5:\n                _context23.next = 0;\n                break;\n\n              case 7:\n                return _context23.abrupt(\"return\", {\n                  value: this.outputQueue.shift(),\n                  done: false\n                });\n\n              case 8:\n              case \"end\":\n                return _context23.stop();\n            }\n          }\n        }, _callee23, this);\n      }));\n\n      function serialNext() {\n        return _serialNext6.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return OneToManyIterator;\n}(LazyIterator);\n\nvar FlatmapIterator = /*#__PURE__*/function (_OneToManyIterator) {\n  _inherits(FlatmapIterator, _OneToManyIterator);\n\n  function FlatmapIterator(upstream, transform) {\n    var _this18;\n\n    _classCallCheck(this, FlatmapIterator);\n\n    _this18 = _possibleConstructorReturn(this, _getPrototypeOf(FlatmapIterator).call(this));\n    _this18.upstream = upstream;\n    _this18.transform = transform;\n    return _this18;\n  }\n\n  _createClass(FlatmapIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Flatmap\");\n    }\n  }, {\n    key: \"pump\",\n    value: function () {\n      var _pump = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee24() {\n        var item, inputTensors, mappedArray, outputTensors, _iterator3, _step3, t;\n\n        return _regeneratorRuntime.wrap(function _callee24$(_context24) {\n          while (1) {\n            switch (_context24.prev = _context24.next) {\n              case 0:\n                _context24.next = 2;\n                return this.upstream.next();\n\n              case 2:\n                item = _context24.sent;\n\n                if (!item.done) {\n                  _context24.next = 5;\n                  break;\n                }\n\n                return _context24.abrupt(\"return\", false);\n\n              case 5:\n                inputTensors = tf.tensor_util.getTensorsInContainer(item.value); // Careful: the transform may mutate the item in place.\n                // that's why we have to remember the input Tensors above, and then\n                // below dispose only those that were not passed through to the output.\n                // Note too that the transform function is responsible for tidying any\n                // intermediate Tensors.  Here we are concerned only about the inputs.\n\n                mappedArray = this.transform(item.value);\n                outputTensors = tf.tensor_util.getTensorsInContainer(mappedArray);\n                this.outputQueue.pushAll(mappedArray); // TODO(soergel) faster intersection, and deduplicate outputTensors\n                // TODO(soergel) move to tf.disposeExcept(in, out)?\n\n                _iterator3 = _createForOfIteratorHelper(inputTensors);\n\n                try {\n                  for (_iterator3.s(); !(_step3 = _iterator3.n()).done;) {\n                    t = _step3.value;\n\n                    if (!tf.tensor_util.isTensorInList(t, outputTensors)) {\n                      t.dispose();\n                    }\n                  }\n                } catch (err) {\n                  _iterator3.e(err);\n                } finally {\n                  _iterator3.f();\n                }\n\n                return _context24.abrupt(\"return\", true);\n\n              case 12:\n              case \"end\":\n                return _context24.stop();\n            }\n          }\n        }, _callee24, this);\n      }));\n\n      function pump() {\n        return _pump.apply(this, arguments);\n      }\n\n      return pump;\n    }()\n  }]);\n\n  return FlatmapIterator;\n}(OneToManyIterator);\n/**\n * Provides a `LazyIterator` that concatenates a stream of underlying\n * streams.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n */\n\n\nexport var ChainedIterator = /*#__PURE__*/function (_LazyIterator12) {\n  _inherits(ChainedIterator, _LazyIterator12);\n\n  function ChainedIterator(iterators, baseErrorHandler) {\n    var _this19;\n\n    _classCallCheck(this, ChainedIterator);\n\n    _this19 = _possibleConstructorReturn(this, _getPrototypeOf(ChainedIterator).call(this));\n    _this19.baseErrorHandler = baseErrorHandler; // Strict Promise execution order:\n    // a next() call may not even begin until the previous one completes.\n\n    _this19.lastRead = null; // Local state that should not be clobbered by out-of-order execution.\n\n    _this19.iterator = null;\n    _this19.moreIterators = iterators;\n    return _this19;\n  }\n\n  _createClass(ChainedIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      var upstreamSummaries = 'TODO: fill in upstream of chained summaries';\n      return \"\".concat(upstreamSummaries, \" -> Chained\");\n    }\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next12 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee25() {\n        return _regeneratorRuntime.wrap(function _callee25$(_context25) {\n          while (1) {\n            switch (_context25.prev = _context25.next) {\n              case 0:\n                this.lastRead = this.readFromChain(this.lastRead);\n                return _context25.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context25.stop();\n            }\n          }\n        }, _callee25, this);\n      }));\n\n      function next() {\n        return _next12.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"readFromChain\",\n    value: function () {\n      var _readFromChain = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee26(lastRead) {\n        var iteratorResult, itemResult;\n        return _regeneratorRuntime.wrap(function _callee26$(_context26) {\n          while (1) {\n            switch (_context26.prev = _context26.next) {\n              case 0:\n                _context26.next = 2;\n                return lastRead;\n\n              case 2:\n                if (!(this.iterator == null)) {\n                  _context26.next = 10;\n                  break;\n                }\n\n                _context26.next = 5;\n                return this.moreIterators.next();\n\n              case 5:\n                iteratorResult = _context26.sent;\n\n                if (!iteratorResult.done) {\n                  _context26.next = 8;\n                  break;\n                }\n\n                return _context26.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 8:\n                this.iterator = iteratorResult.value;\n\n                if (this.baseErrorHandler != null) {\n                  this.iterator = this.iterator.handleErrors(this.baseErrorHandler);\n                }\n\n              case 10:\n                _context26.next = 12;\n                return this.iterator.next();\n\n              case 12:\n                itemResult = _context26.sent;\n\n                if (!itemResult.done) {\n                  _context26.next = 16;\n                  break;\n                }\n\n                this.iterator = null;\n                return _context26.abrupt(\"return\", this.readFromChain(lastRead));\n\n              case 16:\n                return _context26.abrupt(\"return\", itemResult);\n\n              case 17:\n              case \"end\":\n                return _context26.stop();\n            }\n          }\n        }, _callee26, this);\n      }));\n\n      function readFromChain(_x4) {\n        return _readFromChain.apply(this, arguments);\n      }\n\n      return readFromChain;\n    }()\n  }]);\n\n  return ChainedIterator;\n}(LazyIterator);\nexport var ZipMismatchMode;\n\n(function (ZipMismatchMode) {\n  ZipMismatchMode[ZipMismatchMode[\"FAIL\"] = 0] = \"FAIL\";\n  ZipMismatchMode[ZipMismatchMode[\"SHORTEST\"] = 1] = \"SHORTEST\";\n  ZipMismatchMode[ZipMismatchMode[\"LONGEST\"] = 2] = \"LONGEST\"; // use nulls for exhausted streams; use up the longest stream.\n})(ZipMismatchMode || (ZipMismatchMode = {}));\n/**\n * Provides a `LazyIterator` that zips together an array, dict, or nested\n * structure of `LazyIterator`s (and perhaps additional constants).\n *\n * The underlying streams must provide elements in a consistent order such\n * that they correspond.\n *\n * Typically, the underlying streams should have the same number of\n * elements. If they do not, the behavior is determined by the\n * `mismatchMode` argument.\n *\n * The nested structure of the `iterators` argument determines the\n * structure of elements in the resulting iterator.\n *\n * Doing this in a concurrency-safe way requires some trickery.  In\n * particular, we want this stream to return the elements from the\n * underlying streams in the correct order according to when next() was\n * called, even if the resulting Promises resolve in a different order.\n *\n * @param iterators: An array or object containing LazyIterators at the\n * leaves.\n * @param mismatchMode: Determines what to do when one underlying iterator\n * is exhausted before the others.  `ZipMismatchMode.FAIL` (the default)\n * causes an error to be thrown in this case.  `ZipMismatchMode.SHORTEST`\n * causes the zipped iterator to terminate with the furst underlying\n * streams, so elements remaining on the longer streams are ignored.\n * `ZipMismatchMode.LONGEST` causes the zipped stream to continue, filling\n * in nulls for the exhausted streams, until all streams are exhausted.\n */\n\n\nvar ZipIterator = /*#__PURE__*/function (_LazyIterator13) {\n  _inherits(ZipIterator, _LazyIterator13);\n\n  function ZipIterator(iterators) {\n    var _this20;\n\n    var mismatchMode = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : ZipMismatchMode.FAIL;\n\n    _classCallCheck(this, ZipIterator);\n\n    _this20 = _possibleConstructorReturn(this, _getPrototypeOf(ZipIterator).call(this));\n    _this20.iterators = iterators;\n    _this20.mismatchMode = mismatchMode;\n    _this20.count = 0;\n    _this20.currentPromise = null;\n    return _this20;\n  }\n\n  _createClass(ZipIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      var upstreamSummaries = 'TODO: fill in upstream of zip summaries';\n      return \"{\".concat(upstreamSummaries, \"} -> Zip\");\n    }\n  }, {\n    key: \"nextState\",\n    value: function () {\n      var _nextState = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee27(afterState) {\n        var numIterators, iteratorsDone, getNext, mapped;\n        return _regeneratorRuntime.wrap(function _callee27$(_context27) {\n          while (1) {\n            switch (_context27.prev = _context27.next) {\n              case 0:\n                getNext = function _getNext(container) {\n                  if (container instanceof LazyIterator) {\n                    var result = container.next();\n                    return {\n                      value: result.then(function (x) {\n                        numIterators++;\n\n                        if (x.done) {\n                          iteratorsDone++;\n                        }\n\n                        return x.value;\n                      }),\n                      recurse: false\n                    };\n                  } else {\n                    return {\n                      value: null,\n                      recurse: true\n                    };\n                  }\n                };\n\n                _context27.next = 3;\n                return afterState;\n\n              case 3:\n                // Collect underlying iterator \"done\" signals as a side effect in\n                // getNext()\n                numIterators = 0;\n                iteratorsDone = 0;\n                _context27.next = 7;\n                return deepMapAndAwaitAll(this.iterators, getNext);\n\n              case 7:\n                mapped = _context27.sent;\n\n                if (!(numIterators === iteratorsDone)) {\n                  _context27.next = 10;\n                  break;\n                }\n\n                return _context27.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 10:\n                if (!(iteratorsDone > 0)) {\n                  _context27.next = 16;\n                  break;\n                }\n\n                _context27.t0 = this.mismatchMode;\n                _context27.next = _context27.t0 === ZipMismatchMode.FAIL ? 14 : _context27.t0 === ZipMismatchMode.SHORTEST ? 15 : _context27.t0 === ZipMismatchMode.LONGEST ? 16 : 16;\n                break;\n\n              case 14:\n                throw new Error('Zipped streams should have the same length. ' + \"Mismatched at element \".concat(this.count, \".\"));\n\n              case 15:\n                return _context27.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 16:\n                this.count++;\n                return _context27.abrupt(\"return\", {\n                  value: mapped,\n                  done: false\n                });\n\n              case 18:\n              case \"end\":\n                return _context27.stop();\n            }\n          }\n        }, _callee27, this);\n      }));\n\n      function nextState(_x5) {\n        return _nextState.apply(this, arguments);\n      }\n\n      return nextState;\n    }()\n  }, {\n    key: \"next\",\n    value: function () {\n      var _next13 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee28() {\n        return _regeneratorRuntime.wrap(function _callee28$(_context28) {\n          while (1) {\n            switch (_context28.prev = _context28.next) {\n              case 0:\n                this.currentPromise = this.nextState(this.currentPromise);\n                return _context28.abrupt(\"return\", this.currentPromise);\n\n              case 2:\n              case \"end\":\n                return _context28.stop();\n            }\n          }\n        }, _callee28, this);\n      }));\n\n      function next() {\n        return _next13.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }]);\n\n  return ZipIterator;\n}(LazyIterator); // Iterators that maintain a ring buffer of pending promises\n// ============================================================================\n\n/**\n * A stream that prefetches a given number of items from an upstream source,\n * returning them in FIFO order.\n *\n * Note this prefetches Promises, but makes no guarantees about when those\n * Promises resolve.\n */\n\n\nexport var PrefetchIterator = /*#__PURE__*/function (_LazyIterator14) {\n  _inherits(PrefetchIterator, _LazyIterator14);\n\n  function PrefetchIterator(upstream, bufferSize) {\n    var _this21;\n\n    _classCallCheck(this, PrefetchIterator);\n\n    _this21 = _possibleConstructorReturn(this, _getPrototypeOf(PrefetchIterator).call(this));\n    _this21.upstream = upstream;\n    _this21.bufferSize = bufferSize;\n    _this21.buffer = new RingBuffer(bufferSize);\n    return _this21;\n  }\n\n  _createClass(PrefetchIterator, [{\n    key: \"summary\",\n    value: function summary() {\n      return \"\".concat(this.upstream.summary(), \" -> Prefetch\");\n    }\n    /**\n     * Refill the prefetch buffer.  Returns only after the buffer is full, or\n     * the upstream source is exhausted.\n     */\n\n  }, {\n    key: \"refill\",\n    value: function refill() {\n      while (!this.buffer.isFull()) {\n        var v = this.upstream.next();\n        this.buffer.push(v);\n      }\n    }\n  }, {\n    key: \"next\",\n    value: function next() {\n      this.refill(); // This shift will never throw an error because the buffer is always\n      // full after a refill. If the stream is exhausted, the buffer will be\n      // full of Promises that will resolve to the end-of-stream signal.\n\n      return this.buffer.shift();\n    }\n  }]);\n\n  return PrefetchIterator;\n}(LazyIterator);\n/**\n * A stream that performs a sliding-window random shuffle on an upstream\n * source. This is like a `PrefetchIterator` except that the items are\n * returned in randomized order.  Mixing naturally improves as the buffer\n * size increases.\n */\n\nexport var ShuffleIterator = /*#__PURE__*/function (_PrefetchIterator) {\n  _inherits(ShuffleIterator, _PrefetchIterator);\n\n  function ShuffleIterator(upstream, windowSize, seed) {\n    var _this22;\n\n    _classCallCheck(this, ShuffleIterator);\n\n    _this22 = _possibleConstructorReturn(this, _getPrototypeOf(ShuffleIterator).call(this, upstream, windowSize));\n    _this22.upstream = upstream;\n    _this22.windowSize = windowSize; // Local state that should not be clobbered by out-of-order execution.\n\n    _this22.upstreamExhausted = false;\n    _this22.random = seedrandom.alea(seed || tf.util.now().toString());\n    _this22.lastRead = Promise.resolve({\n      value: null,\n      done: false\n    });\n    return _this22;\n  }\n\n  _createClass(ShuffleIterator, [{\n    key: \"next\",\n    value: function () {\n      var _next14 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee29() {\n        var _this23 = this;\n\n        return _regeneratorRuntime.wrap(function _callee29$(_context29) {\n          while (1) {\n            switch (_context29.prev = _context29.next) {\n              case 0:\n                // This sets this.lastRead to a new Promise right away, as opposed to\n                // saying `await this.lastRead; this.lastRead = this.serialNext();` which\n                // would not work because this.nextRead would be updated only after the\n                // promise resolves.\n                this.lastRead = this.lastRead.then(function () {\n                  return _this23.serialNext();\n                });\n                return _context29.abrupt(\"return\", this.lastRead);\n\n              case 2:\n              case \"end\":\n                return _context29.stop();\n            }\n          }\n        }, _callee29, this);\n      }));\n\n      function next() {\n        return _next14.apply(this, arguments);\n      }\n\n      return next;\n    }()\n  }, {\n    key: \"randomInt\",\n    value: function randomInt(max) {\n      return Math.floor(this.random() * max);\n    }\n  }, {\n    key: \"chooseIndex\",\n    value: function chooseIndex() {\n      return this.randomInt(this.buffer.length());\n    }\n  }, {\n    key: \"serialNext\",\n    value: function () {\n      var _serialNext7 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee30() {\n        var chosenIndex, result;\n        return _regeneratorRuntime.wrap(function _callee30$(_context30) {\n          while (1) {\n            switch (_context30.prev = _context30.next) {\n              case 0:\n                // TODO(soergel): consider performance\n                if (!this.upstreamExhausted) {\n                  this.refill();\n                }\n\n              case 1:\n                if (this.buffer.isEmpty()) {\n                  _context30.next = 14;\n                  break;\n                }\n\n                chosenIndex = this.chooseIndex();\n                _context30.next = 5;\n                return this.buffer.shuffleExcise(chosenIndex);\n\n              case 5:\n                result = _context30.sent;\n\n                if (!result.done) {\n                  _context30.next = 10;\n                  break;\n                }\n\n                this.upstreamExhausted = true;\n                _context30.next = 12;\n                break;\n\n              case 10:\n                this.refill();\n                return _context30.abrupt(\"return\", result);\n\n              case 12:\n                _context30.next = 1;\n                break;\n\n              case 14:\n                return _context30.abrupt(\"return\", {\n                  value: null,\n                  done: true\n                });\n\n              case 15:\n              case \"end\":\n                return _context30.stop();\n            }\n          }\n        }, _callee30, this);\n      }));\n\n      function serialNext() {\n        return _serialNext7.apply(this, arguments);\n      }\n\n      return serialNext;\n    }()\n  }]);\n\n  return ShuffleIterator;\n}(PrefetchIterator);","map":null,"metadata":{},"sourceType":"module"}