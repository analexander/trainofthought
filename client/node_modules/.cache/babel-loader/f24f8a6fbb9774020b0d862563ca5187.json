{"ast":null,"code":"import _slicedToArray from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/slicedToArray\";\n\n/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { BatchMatMul, buffer, util } from '@tensorflow/tfjs-core';\nimport { assertNotComplex } from '../cpu_util';\nimport { reshape } from './Reshape';\nexport function batchMatMul(args) {\n  var inputs = args.inputs,\n      backend = args.backend,\n      attrs = args.attrs;\n  var a = inputs.a,\n      b = inputs.b;\n  var transposeA = attrs.transposeA,\n      transposeB = attrs.transposeB;\n  assertNotComplex([a, b], 'matMul');\n  var aRank = a.shape.length;\n  var bRank = b.shape.length;\n  var innerShapeA = transposeA ? a.shape[aRank - 2] : a.shape[aRank - 1];\n  var innerShapeB = transposeB ? b.shape[bRank - 1] : b.shape[bRank - 2];\n  var outerShapeA = transposeA ? a.shape[aRank - 1] : a.shape[aRank - 2];\n  var outerShapeB = transposeB ? b.shape[bRank - 2] : b.shape[bRank - 1];\n  var outerDimsA = a.shape.slice(0, -2);\n  var outerDimsB = b.shape.slice(0, -2);\n  var batchDimA = util.sizeFromShape(outerDimsA);\n  var batchDimB = util.sizeFromShape(outerDimsB);\n  var batchDimsCompatible = batchDimA === batchDimB || batchDimA === 1 || batchDimB === 1;\n  util.assert(aRank >= 2 && bRank >= 2 && batchDimsCompatible, function () {\n    return \"Error in matMul: the input batch dimensions must either be the \" + \"same or at least one input batch dimension must be 1. Got input \" + \"batch dimensions of (\".concat(outerDimsA, \") and (\").concat(outerDimsB, \").\");\n  });\n  var outShapeOuterDims = batchDimA > batchDimB ? a.shape.slice(0, -2) : b.shape.slice(0, -2);\n  var outShape = outShapeOuterDims.concat([outerShapeA, outerShapeB]);\n  util.assert(innerShapeA === innerShapeB, function () {\n    return \"Error in matMul: inner shapes (\".concat(innerShapeA, \") and (\") + \"\".concat(innerShapeB, \") of Tensors with shapes \").concat(a.shape, \" and \") + \"\".concat(b.shape, \" and transposeA=\").concat(transposeA) + \" and transposeB=\".concat(transposeB, \" must match.\");\n  });\n  var a3dShape = transposeA ? [batchDimA, innerShapeA, outerShapeA] : [batchDimA, outerShapeA, innerShapeA];\n  var b3dShape = transposeB ? [batchDimB, outerShapeB, innerShapeB] : [batchDimB, innerShapeB, outerShapeB]; // The rest of the implementation is designed to operate on rank-3 tensors\n\n  var a3d = reshape({\n    inputs: {\n      x: a\n    },\n    backend: backend,\n    attrs: {\n      shape: a3dShape\n    }\n  });\n  var b3d = reshape({\n    inputs: {\n      x: b\n    },\n    backend: backend,\n    attrs: {\n      shape: b3dShape\n    }\n  });\n  var sharedDim = transposeA ? a3d.shape[1] : a3d.shape[2];\n  var leftDim = transposeA ? a3d.shape[2] : a3d.shape[1];\n  var rightDim = transposeB ? b3d.shape[1] : b3d.shape[2];\n  var batchDim = Math.max(batchDimA, batchDimB);\n  var a3dValues = backend.data.get(a3d.dataId).values;\n  var b3dValues = backend.data.get(b3d.dataId).values;\n  var a3dStrides = util.computeStrides(a3d.shape);\n  var b3dStrides = util.computeStrides(b3d.shape);\n\n  var _ref = transposeA ? [a3dStrides[0], 1, a3dStrides[1]] : [a3dStrides[0], a3dStrides[1], 1],\n      _ref2 = _slicedToArray(_ref, 3),\n      aBatch = _ref2[0],\n      aOuterStep = _ref2[1],\n      aInnerStep = _ref2[2];\n\n  var _ref3 = transposeB ? [1, b3dStrides[1], b3dStrides[0]] : [b3dStrides[1], 1, b3dStrides[0]],\n      _ref4 = _slicedToArray(_ref3, 3),\n      bInnerStep = _ref4[0],\n      bOuterStep = _ref4[1],\n      bBatch = _ref4[2];\n\n  var size = leftDim * rightDim;\n  var result = buffer([batchDim, leftDim, rightDim], a3d.dtype);\n  var resVals = result.values;\n  var blockSize = backend.blockSize;\n\n  for (var bi = 0; bi < batchDim; bi++) {\n    for (var i0 = 0; i0 < leftDim; i0 += blockSize) {\n      for (var j0 = 0; j0 < rightDim; j0 += blockSize) {\n        for (var k0 = 0; k0 < sharedDim; k0 += blockSize) {\n          // for when blockSize doesn't evenly divide the input\n          var iBlock = Math.min(i0 + blockSize, leftDim);\n          var jBlock = Math.min(j0 + blockSize, rightDim);\n          var kBlock = Math.min(k0 + blockSize, sharedDim);\n\n          for (var i = i0; i < iBlock; i++) {\n            for (var j = j0; j < jBlock; j++) {\n              var sum = 0.0;\n\n              for (var k = k0; k < kBlock; k++) {\n                var batchOffsetA = Math.min(bi, batchDimA - 1) * aBatch;\n                var batchOffsetB = Math.min(bi, batchDimB - 1) * bBatch;\n                var aVal = a3dValues[batchOffsetA + i * aOuterStep + k * aInnerStep];\n                var bVal = b3dValues[k * bInnerStep + j * bOuterStep + batchOffsetB];\n                sum += aVal * bVal;\n              }\n\n              resVals[bi * size + (i * rightDim + j)] += sum;\n            }\n          }\n        }\n      }\n    }\n  }\n\n  backend.disposeIntermediateTensorInfo(a3d);\n  backend.disposeIntermediateTensorInfo(b3d); // set correct shape on output.\n\n  return backend.makeTensorInfo(outShape, result.dtype, result.values);\n}\nexport var batchMatMulConfig = {\n  kernelName: BatchMatMul,\n  backendName: 'cpu',\n  kernelFunc: batchMatMul\n};","map":null,"metadata":{},"sourceType":"module"}