{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\n\n/**\n * @license\n * Copyright 2018 Google LLC\n *\n * Use of this source code is governed by an MIT-style\n * license that can be found in the LICENSE file or at\n * https://opensource.org/licenses/MIT.\n * =============================================================================\n */\n\n/**\n * Interfaces and methods for training models using tf.Tensor objects.\n */\nimport * as tfc from '@tensorflow/tfjs-core';\nimport { Tensor, tensor1d, util } from '@tensorflow/tfjs-core';\nimport { expandDims, gather, sliceAlongFirstAxis } from '../backend/tfjs_backend';\nimport { configureCallbacks, standardizeCallbacks } from '../base_callbacks';\nimport { NotImplementedError, ValueError } from '../errors';\nimport { disposeTensorsInLogs } from '../logs';\nimport { range } from '../utils/math_utils';\nexport function checkBatchSize(batchSize) {\n  tfc.util.assert(batchSize > 0 && Number.isInteger(batchSize), function () {\n    return \"batchSize is required to be a positive integer, but got \".concat(batchSize);\n  });\n}\n/**\n * Slice a Tensor or an Array of Tensors, by start and stop indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArraysByIndices()` together.\n *\n * @param arrays: the input.\n * @param start: the starting index (inclusive).\n * @param stop: the stopping index (exclusive).\n * @returns The result of the slicing. If `arrays` is an `Array` of\n *   `tf.Tensor`s, the slicing will be applied to all elements of the `Array`\n *   in the same way.\n */\n\nexport function sliceArrays(arrays, start, stop) {\n  if (arrays == null) {\n    return [null];\n  } else if (Array.isArray(arrays)) {\n    return arrays.map(function (array) {\n      return sliceAlongFirstAxis(array, start, stop - start);\n    });\n  } else {\n    // Tensor.\n    return sliceAlongFirstAxis(arrays, start, stop - start);\n  }\n}\n/**\n * Slice a Tensor or an Array of Tensors, by random-order indices.\n *\n * Porting Note: The `_slice_arrays` function in PyKeras is covered by this\n *   function and `sliceArrays()` together.\n *\n * @param arrays The input `tf.Tensor` or `Array` of `tf.Tensor`s to slice.\n *   If an `Array` of `tf.Tensor`s, all `tf.Tensor`s will be sliced in the\n *   same fashion.\n * @param indices The indices to use for slicing along the first (batch)\n *   dimension.\n * @returns Result(s) of the slicing.\n */\n\nexport function sliceArraysByIndices(arrays, indices) {\n  return tfc.tidy(function () {\n    if (arrays == null) {\n      return null;\n    } else if (Array.isArray(arrays)) {\n      return arrays.map(function (array) {\n        return sliceArraysByIndices(array, indices);\n      });\n    } else {\n      // TODO(cais): indices should be a pre-constructed Tensor1D to avoid\n      //   tensor1d() calls.\n      return gather(arrays, indices.dtype === 'int32' ? indices : indices.toInt());\n    }\n  });\n}\n/**\n * Returns a list of batch indices (tuples of indices).\n * @param size: Integer, total size of the data to slice into batches.\n * @param batchSize: Integer, batch size.\n * @returns An Array of [batchStart, batchEnd] tuples. batchStart is\n *   inclusive; batchEnd is exclusive. I.e., each batch consists of indices x\n *   that satisfy batchStart <= x < batchEnd.\n */\n\nexport function makeBatches(size, batchSize) {\n  var output = [];\n  var batchStart = 0;\n  var batchEnd = null;\n\n  while (batchStart < size) {\n    batchEnd = batchStart + batchSize;\n\n    if (batchEnd >= size) {\n      batchEnd = size;\n    }\n\n    output.push([batchStart, batchEnd]);\n    batchStart = batchEnd;\n  }\n\n  return output;\n}\n/**\n * Abstract fit function for `f(ins)`.\n * @param f A Function returning a list of tensors. For training, this\n *   function is expected to perform the updates to the variables.\n * @param ins List of tensors to be fed to `f`.\n * @param outLabels List of strings, display names of the outputs of `f`.\n * @param batchSize Integer batch size or `== null` if unknown. Default : 32.\n * @param epochs Number of times to iterate over the data. Default : 1.\n * @param verbose Verbosity mode: 0, 1, or 2. Default: 1.\n * @param callbacks List of callbacks to be called during training.\n * @param valF Function to call for validation.\n * @param valIns List of tensors to be fed to `valF`.\n * @param shuffle Whether to shuffle the data at the beginning of every\n * epoch. Default : true.\n * @param callbackMetrics List of strings, the display names of the metrics\n *   passed to the callbacks. They should be the concatenation of the\n *   display names of the outputs of `f` and the list of display names\n *   of the outputs of `valF`.\n * @param initialEpoch Epoch at which to start training (useful for\n *   resuming a previous training run). Default : 0.\n * @param stepsPerEpoch Total number of steps (batches on samples) before\n *   declaring one epoch finished and starting the next epoch. Ignored with\n *   the default value of `undefined` or `null`.\n * @param validationSteps Number of steps to run validation for (only if\n *   doing validation from data tensors). Not applicable for tfjs-layers.\n * @returns A `History` object.\n */\n\nfunction fitLoop(_x, _x2, _x3, _x4, _x5, _x6, _x7, _x8, _x9, _x10, _x11, _x12, _x13, _x14, _x15) {\n  return _fitLoop.apply(this, arguments);\n}\n\nfunction _fitLoop() {\n  _fitLoop = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n  // tslint:disable-next-line:no-any\n  model, f, ins, outLabels, batchSize, epochs, verbose, callbacks, valF, valIns, shuffle, callbackMetrics, initialEpoch, stepsPerEpoch, validationSteps) {\n    var doValidation, numTrainSamples, indexArray, _configureCallbacks, callbackList, history, _loop, epoch, _ret;\n\n    return _regeneratorRuntime.wrap(function _callee2$(_context4) {\n      while (1) {\n        switch (_context4.prev = _context4.next) {\n          case 0:\n            if (batchSize == null) {\n              batchSize = 32;\n            }\n\n            if (epochs == null) {\n              epochs = 1;\n            }\n\n            if (shuffle == null) {\n              shuffle = true;\n            }\n\n            if (initialEpoch == null) {\n              initialEpoch = 0;\n            } // TODO(cais): Change const to let below when implementing validation.\n\n\n            doValidation = false;\n\n            if (valF != null && valIns != null) {\n              doValidation = true; // TODO(cais): verbose message.\n            }\n\n            if (!(validationSteps != null)) {\n              _context4.next = 10;\n              break;\n            }\n\n            doValidation = true;\n\n            if (!(stepsPerEpoch == null)) {\n              _context4.next = 10;\n              break;\n            }\n\n            throw new ValueError('Can only use `validationSteps` when doing step-wise training, ' + 'i.e., `stepsPerEpoch` must be set.');\n\n          case 10:\n            numTrainSamples = model.checkNumSamples(ins, batchSize, stepsPerEpoch, 'steps_per_epoch');\n\n            if (numTrainSamples != null) {\n              indexArray = range(0, numTrainSamples);\n            }\n\n            if (verbose == null) {\n              verbose = 1;\n            }\n\n            _configureCallbacks = configureCallbacks(callbacks, verbose, epochs, initialEpoch, numTrainSamples, stepsPerEpoch, batchSize, doValidation, callbackMetrics), callbackList = _configureCallbacks.callbackList, history = _configureCallbacks.history;\n            callbackList.setModel(model);\n            model.history = history;\n            _context4.next = 18;\n            return callbackList.onTrainBegin();\n\n          case 18:\n            model.stopTraining_ = false; // TODO(cais): Take care of callbacks.validation_data as in PyKeras.\n            // TODO(cais): Pre-convert feeds for performance as in PyKeras.\n\n            _loop = /*#__PURE__*/_regeneratorRuntime.mark(function _loop(epoch) {\n              var epochLogs;\n              return _regeneratorRuntime.wrap(function _loop$(_context3) {\n                while (1) {\n                  switch (_context3.prev = _context3.next) {\n                    case 0:\n                      _context3.next = 2;\n                      return callbackList.onEpochBegin(epoch);\n\n                    case 2:\n                      epochLogs = {};\n\n                      if (!(stepsPerEpoch != null)) {\n                        _context3.next = 7;\n                        break;\n                      }\n\n                      throw new NotImplementedError('stepsPerEpoch mode is not implemented yet.');\n\n                    case 7:\n                      return _context3.delegateYield( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n                        var epochIndexArray1D, batches, _loop2, batchIndex, _ret2;\n\n                        return _regeneratorRuntime.wrap(function _callee$(_context2) {\n                          while (1) {\n                            switch (_context2.prev = _context2.next) {\n                              case 0:\n                                if (!(shuffle === 'batch')) {\n                                  _context2.next = 4;\n                                  break;\n                                }\n\n                                throw new NotImplementedError('batch shuffling is not implemneted yet');\n\n                              case 4:\n                                if (shuffle) {\n                                  util.shuffle(indexArray);\n                                }\n\n                              case 5:\n                                // Convert the potentially shuffled indices to Tensor1D, to avoid the\n                                // cost of repeated creation of Array1Ds later on.\n                                epochIndexArray1D = tensor1d(indexArray);\n                                batches = makeBatches(numTrainSamples, batchSize);\n                                _loop2 = /*#__PURE__*/_regeneratorRuntime.mark(function _loop2(batchIndex) {\n                                  var batchLogs;\n                                  return _regeneratorRuntime.wrap(function _loop2$(_context) {\n                                    while (1) {\n                                      switch (_context.prev = _context.next) {\n                                        case 0:\n                                          batchLogs = {};\n                                          _context.next = 3;\n                                          return callbackList.onBatchBegin(batchIndex, batchLogs);\n\n                                        case 3:\n                                          tfc.tidy(function () {\n                                            var batchStart = batches[batchIndex][0];\n                                            var batchEnd = batches[batchIndex][1];\n                                            var batchIds = sliceAlongFirstAxis(epochIndexArray1D, batchStart, batchEnd - batchStart);\n                                            batchLogs['batch'] = batchIndex;\n                                            batchLogs['size'] = batchEnd - batchStart; // TODO(cais): In ins, train flag can be a number, instead of an\n                                            //   Tensor? Do we need to handle this in tfjs-layers?\n\n                                            var insBatch = sliceArraysByIndices(ins, batchIds);\n                                            var outs = f(insBatch);\n\n                                            for (var i = 0; i < outLabels.length; ++i) {\n                                              var label = outLabels[i];\n                                              var out = outs[i];\n                                              batchLogs[label] = out;\n                                              tfc.keep(out); // TODO(cais): Use scope() to avoid ownership.\n                                            }\n\n                                            if (batchIndex === batches.length - 1) {\n                                              // Last batch.\n                                              if (doValidation) {\n                                                var valOuts = model.testLoop(valF, valIns, batchSize); // Porting Notes: In tfjs-layers, valOuts is always an Array.\n\n                                                for (var _i = 0; _i < outLabels.length; ++_i) {\n                                                  var _label = outLabels[_i];\n                                                  var _out = valOuts[_i];\n                                                  tfc.keep(_out); // TODO(cais): Use scope() to avoid ownership.\n\n                                                  epochLogs['val_' + _label] = _out;\n                                                }\n                                              }\n                                            }\n                                          });\n                                          _context.next = 6;\n                                          return callbackList.onBatchEnd(batchIndex, batchLogs);\n\n                                        case 6:\n                                          disposeTensorsInLogs(batchLogs);\n\n                                          if (!model.stopTraining_) {\n                                            _context.next = 9;\n                                            break;\n                                          }\n\n                                          return _context.abrupt(\"return\", \"break\");\n\n                                        case 9:\n                                        case \"end\":\n                                          return _context.stop();\n                                      }\n                                    }\n                                  }, _loop2);\n                                });\n                                batchIndex = 0;\n\n                              case 9:\n                                if (!(batchIndex < batches.length)) {\n                                  _context2.next = 17;\n                                  break;\n                                }\n\n                                return _context2.delegateYield(_loop2(batchIndex), \"t0\", 11);\n\n                              case 11:\n                                _ret2 = _context2.t0;\n\n                                if (!(_ret2 === \"break\")) {\n                                  _context2.next = 14;\n                                  break;\n                                }\n\n                                return _context2.abrupt(\"break\", 17);\n\n                              case 14:\n                                ++batchIndex;\n                                _context2.next = 9;\n                                break;\n\n                              case 17:\n                                epochIndexArray1D.dispose();\n\n                              case 18:\n                              case \"end\":\n                                return _context2.stop();\n                            }\n                          }\n                        }, _callee);\n                      })(), \"t0\", 8);\n\n                    case 8:\n                      _context3.next = 10;\n                      return callbackList.onEpochEnd(epoch, epochLogs);\n\n                    case 10:\n                      if (!model.stopTraining_) {\n                        _context3.next = 12;\n                        break;\n                      }\n\n                      return _context3.abrupt(\"return\", \"break\");\n\n                    case 12:\n                    case \"end\":\n                      return _context3.stop();\n                  }\n                }\n              }, _loop);\n            });\n            epoch = initialEpoch;\n\n          case 21:\n            if (!(epoch < epochs)) {\n              _context4.next = 29;\n              break;\n            }\n\n            return _context4.delegateYield(_loop(epoch), \"t0\", 23);\n\n          case 23:\n            _ret = _context4.t0;\n\n            if (!(_ret === \"break\")) {\n              _context4.next = 26;\n              break;\n            }\n\n            return _context4.abrupt(\"break\", 29);\n\n          case 26:\n            ++epoch;\n            _context4.next = 21;\n            break;\n\n          case 29:\n            _context4.next = 31;\n            return callbackList.onTrainEnd();\n\n          case 31:\n            _context4.next = 33;\n            return model.history.syncData();\n\n          case 33:\n            return _context4.abrupt(\"return\", model.history);\n\n          case 34:\n          case \"end\":\n            return _context4.stop();\n        }\n      }\n    }, _callee2);\n  }));\n  return _fitLoop.apply(this, arguments);\n}\n\nexport function fitTensors(_x16, _x17, _x18) {\n  return _fitTensors.apply(this, arguments);\n}\n/**\n * Ensure tensors all have a rank of at least 2.\n *\n * If a tensor has a rank of 1, it is dimension-expanded to rank 2.\n * If any tensor has a rank of 0 (i.e., is a scalar), an error will be thrown.\n */\n\nfunction _fitTensors() {\n  _fitTensors = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee3( // Type `model` as `any` here to avoid circular dependency w/ training.ts.\n  // tslint:disable-next-line:no-any\n  model, x, y) {\n    var args,\n        inputs,\n        targets,\n        inputValX,\n        inputValY,\n        valX,\n        valY,\n        sampleWeights,\n        batchSize,\n        checkBatchAxis,\n        standardizedOuts,\n        doValidation,\n        valIns,\n        _checkBatchAxis,\n        valStandardized,\n        splitAt,\n        originalBatchSize,\n        ins,\n        trainFunction,\n        outLabels,\n        valFunction,\n        callbackMetrics,\n        callbacks,\n        out,\n        _args5 = arguments;\n\n    return _regeneratorRuntime.wrap(function _callee3$(_context5) {\n      while (1) {\n        switch (_context5.prev = _context5.next) {\n          case 0:\n            args = _args5.length > 3 && _args5[3] !== undefined ? _args5[3] : {};\n\n            if (!model.isTraining) {\n              _context5.next = 3;\n              break;\n            }\n\n            throw new Error('Cannot start training because another fit() call is ongoing.');\n\n          case 3:\n            model.isTraining = true;\n            _context5.prev = 4;\n            batchSize = args.batchSize == null ? 32 : args.batchSize;\n            checkBatchSize(batchSize); // Validate user data.\n            // TODO(cais): Support sampleWeight.\n\n            checkBatchAxis = false;\n            _context5.next = 10;\n            return model.standardizeUserData(x, y, args.sampleWeight, args.classWeight, checkBatchAxis, batchSize);\n\n          case 10:\n            standardizedOuts = _context5.sent;\n            inputs = standardizedOuts[0];\n            targets = standardizedOuts[1];\n            sampleWeights = standardizedOuts[2]; // Prepare validation data.\n\n            doValidation = false;\n\n            if (!(args.validationData != null && args.validationData.length > 0)) {\n              _context5.next = 36;\n              break;\n            }\n\n            doValidation = true;\n\n            if (!(args.validationData.length === 2)) {\n              _context5.next = 22;\n              break;\n            }\n\n            // config.validationData consists of valX and valY.\n            inputValX = args.validationData[0];\n            inputValY = args.validationData[1];\n            _context5.next = 27;\n            break;\n\n          case 22:\n            if (!(args.validationData.length === 3)) {\n              _context5.next = 26;\n              break;\n            }\n\n            throw new NotImplementedError('validationData including sample weights is not supported yet.');\n\n          case 26:\n            throw new ValueError(\"When passing validation data, it must contain 2 (valX, valY) \" + \"or 3 (valX, valY, valSampleWeight) items; \" + \"\".concat(args.validationData, \" is invalid.\"));\n\n          case 27:\n            _checkBatchAxis = true;\n            _context5.next = 30;\n            return model.standardizeUserData(inputValX, inputValY, null,\n            /** Unused sample weights. */\n            null,\n            /** Unused class weights. */\n            _checkBatchAxis, batchSize);\n\n          case 30:\n            valStandardized = _context5.sent;\n            valX = valStandardized[0];\n            valY = valStandardized[1];\n            valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n\n            _context5.next = 37;\n            break;\n\n          case 36:\n            if (args.validationSplit != null && args.validationSplit > 0 && args.validationSplit < 1) {\n              doValidation = true; // Porting Note: In tfjs-layers, inputs[0] is always a Tensor.\n\n              splitAt = Math.floor(inputs[0].shape[0] * (1 - args.validationSplit));\n              originalBatchSize = inputs[0].shape[0];\n              valX = sliceArrays(inputs, splitAt, originalBatchSize);\n              inputs = sliceArrays(inputs, 0, splitAt);\n              valY = sliceArrays(targets, splitAt, originalBatchSize);\n              targets = sliceArrays(targets, 0, splitAt); // TODO(cais): Once sampleWeights becomes available, slice it to get\n              //   valSampleWeights.\n\n              valIns = valX.concat(valY); // TODO(cais): Add useLearningPhase data properly.\n            } else if (args.validationSteps != null) {\n              doValidation = true; // TODO(cais): Add useLearningPhase.\n            }\n\n          case 37:\n            ins = inputs.concat(targets).concat(sampleWeights);\n            model.checkTrainableWeightsConsistency(); // TODO(cais): Handle use_learning_phase and learning_phase?\n            // Porting Note: Here we see a key deviation of tfjs-layers from\n            // Keras.\n            //  Due to the imperative nature of tfjs-layers' backend (tfjs-core),\n            //  we do not construct symbolic computation graphs to embody the\n            //  training process. Instead, we define a function that performs the\n            //  training action. In PyKeras, the data (inputs and targets) are fed\n            //  through graph placeholders. In tfjs-layers, the data are fed as\n            //  function arguments. Since the function are defined below in the\n            //  scope, we don't have equivalents of PyKeras's\n            //  `_make_train_funciton`.\n\n            trainFunction = model.makeTrainFunction();\n            outLabels = model.getDedupedMetricsNames();\n\n            if (doValidation) {\n              model.makeTestFunction();\n              valFunction = model.testFunction;\n              callbackMetrics = outLabels.slice().concat(outLabels.map(function (n) {\n                return 'val_' + n;\n              }));\n            } else {\n              valFunction = null;\n              valIns = [];\n              callbackMetrics = outLabels.slice();\n            }\n\n            callbacks = standardizeCallbacks(args.callbacks, args.yieldEvery);\n            _context5.next = 45;\n            return fitLoop(model, trainFunction, ins, outLabels, batchSize, args.epochs, args.verbose, callbacks, valFunction, valIns, args.shuffle, callbackMetrics, args.initialEpoch, null, null);\n\n          case 45:\n            out = _context5.sent;\n            return _context5.abrupt(\"return\", out);\n\n          case 47:\n            _context5.prev = 47;\n            model.isTraining = false; // Memory clean up.\n\n            disposeNewTensors(inputs, x);\n            disposeNewTensors(targets, y);\n            disposeNewTensors(valX, inputValX);\n            disposeNewTensors(valY, inputValY);\n\n            if (sampleWeights != null) {\n              tfc.dispose(sampleWeights);\n            }\n\n            return _context5.finish(47);\n\n          case 55:\n          case \"end\":\n            return _context5.stop();\n        }\n      }\n    }, _callee3, null, [[4,, 47, 55]]);\n  }));\n  return _fitTensors.apply(this, arguments);\n}\n\nexport function ensureTensorsRank2OrHigher(tensors) {\n  var outs = [];\n\n  if (tensors instanceof Tensor) {\n    tensors = [tensors];\n  } // Make Tensors at least 2D.\n\n\n  for (var i = 0; i < tensors.length; ++i) {\n    var tensor = tensors[i];\n\n    if (tensor.rank === 1) {\n      outs.push(expandDims(tensor, 1));\n    } else if (tensor.rank === 0) {\n      throw new Error('Expected tensor to be at least 1D, but received a 0D tensor ' + '(scalar).');\n    } else {\n      outs.push(tensor);\n    }\n  }\n\n  return outs;\n}\n/**\n * Compare a set of tensors with a reference (old) set, discard the ones\n * in the new set that are not present in the reference set.\n *\n * This method is used for memory clenaup during calls such as\n * LayersModel.fit().\n *\n * @param tensors New set which may contain Tensors not present in\n *   `refTensors`.\n * @param refTensors Reference Tensor set.\n */\n// TODO(cais, kangyizhang): Deduplicate with tfjs-data.\n\nexport function disposeNewTensors(tensors, refTensors) {\n  if (tensors == null) {\n    return;\n  }\n\n  var oldTensorIds = [];\n\n  if (refTensors instanceof Tensor) {\n    oldTensorIds.push(refTensors.id);\n  } else if (Array.isArray(refTensors)) {\n    refTensors.forEach(function (t) {\n      return oldTensorIds.push(t.id);\n    });\n  } else if (refTensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (var name in refTensors) {\n      var oldTensor = refTensors[name];\n      oldTensorIds.push(oldTensor.id);\n    }\n  }\n\n  var tensorsToDispose = [];\n\n  if (tensors instanceof Tensor) {\n    if (oldTensorIds.indexOf(tensors.id) === -1) {\n      tensorsToDispose.push(tensors);\n    }\n  } else if (Array.isArray(tensors)) {\n    tensors.forEach(function (t) {\n      if (oldTensorIds.indexOf(t.id) === -1) {\n        tensorsToDispose.push(t);\n      }\n    });\n  } else if (tensors != null) {\n    // `oldTensors` is a map from string name to Tensor.\n    for (var _name in tensors) {\n      var tensor = tensors[_name];\n\n      if (oldTensorIds.indexOf(tensor.id) === -1) {\n        tensorsToDispose.push(tensor);\n      }\n    }\n  }\n\n  tensorsToDispose.forEach(function (t) {\n    if (!t.isDisposed) {\n      t.dispose();\n    }\n  });\n}","map":null,"metadata":{},"sourceType":"module"}