{"ast":null,"code":"import _regeneratorRuntime from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/regenerator\";\nimport _asyncToGenerator from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/asyncToGenerator\";\nimport _classCallCheck from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/classCallCheck\";\nimport _createClass from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/createClass\";\nimport _possibleConstructorReturn from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/possibleConstructorReturn\";\nimport _getPrototypeOf from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/getPrototypeOf\";\nimport _inherits from \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/node_modules/babel-preset-react-app/node_modules/@babel/runtime/helpers/esm/inherits\";\nvar _jsxFileName = \"/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/facerec/VideoStream.js\";\nimport React, { Component } from \"react\";\nimport \"./styles.css\";\nimport \"./face_expression_model-weights_manifest.json\";\nimport \"./tiny_face_detector_model-weights_manifest.json\";\nimport Video from \"./Video\";\nimport * as canvas from 'canvas';\nimport * as faceapi from 'face-api.js';\nimport { fetchJson } from \"face-api.js\";\n\nvar VideoStream = /*#__PURE__*/function (_Component) {\n  _inherits(VideoStream, _Component);\n\n  function VideoStream() {\n    var _getPrototypeOf2;\n\n    var _this;\n\n    _classCallCheck(this, VideoStream);\n\n    for (var _len = arguments.length, args = new Array(_len), _key = 0; _key < _len; _key++) {\n      args[_key] = arguments[_key];\n    }\n\n    _this = _possibleConstructorReturn(this, (_getPrototypeOf2 = _getPrototypeOf(VideoStream)).call.apply(_getPrototypeOf2, [this].concat(args)));\n    _this.renderVideo = /*#__PURE__*/_asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee2() {\n      var canvasElement, videoElement, constraints, stream, onPlay;\n      return _regeneratorRuntime.wrap(function _callee2$(_context2) {\n        while (1) {\n          switch (_context2.prev = _context2.next) {\n            case 0:\n              _context2.next = 2;\n              return faceapi.nets.tinyFaceDetector.load('/');\n\n            case 2:\n              _context2.next = 4;\n              return faceapi.loadFaceExpressionModel('/');\n\n            case 4:\n              // get canvas and video elements\n              canvasElement = document.getElementById(\"overlay\");\n              videoElement = document.querySelector(\"video\"); // get Webcam video stream\n\n              constraints = {\n                audio: false,\n                video: {}\n              };\n              _context2.next = 9;\n              return navigator.mediaDevices.getUserMedia(constraints);\n\n            case 9:\n              stream = _context2.sent;\n\n              // what to do when the video stream is available\n              // AKA facial recogition \n              onPlay = /*#__PURE__*/function () {\n                var _ref2 = _asyncToGenerator( /*#__PURE__*/_regeneratorRuntime.mark(function _callee() {\n                  var options, result, dims, resizedResult, minConfidence;\n                  return _regeneratorRuntime.wrap(function _callee$(_context) {\n                    while (1) {\n                      switch (_context.prev = _context.next) {\n                        case 0:\n                          fetchJson(\"./face_expression_model-weights_manifest.json\");\n                          fetchJson(\"./tiny_face_detector_model-weights_manifest.json\");\n                          options = new faceapi.TinyFaceDetectorOptions({\n                            inputSize: 512,\n                            scoreThreshold: 0.5\n                          });\n                          _context.next = 5;\n                          return faceapi.detectSingleFace(videoElement, options).withFaceExpressions();\n\n                        case 5:\n                          result = _context.sent;\n\n                          if (result) {\n                            dims = faceapi.matchDimensions(canvasElement, videoElement, true);\n                            resizedResult = faceapi.resizeResults(result, dims);\n                            minConfidence = 0.05;\n                            faceapi.draw.drawDetections(canvasElement, resizedResult);\n                            faceapi.draw.drawFaceExpressions(canvasElement, resizedResult, minConfidence);\n                          }\n\n                          setTimeout(function () {\n                            return onPlay();\n                          });\n\n                        case 8:\n                        case \"end\":\n                          return _context.stop();\n                      }\n                    }\n                  }, _callee);\n                }));\n\n                return function onPlay() {\n                  return _ref2.apply(this, arguments);\n                };\n              }();\n\n              videoElement.srcObject = stream;\n\n              videoElement.onloadedmetadata = function () {\n                videoElement.play();\n              };\n\n              videoElement.onplay = onPlay;\n\n            case 14:\n            case \"end\":\n              return _context2.stop();\n          }\n        }\n      }, _callee2);\n    }));\n    return _this;\n  }\n\n  _createClass(VideoStream, [{\n    key: \"componentDidMount\",\n    value: function componentDidMount() {\n      this.renderVideo();\n    }\n  }, {\n    key: \"render\",\n    value: function render() {\n      return /*#__PURE__*/React.createElement(\"div\", {\n        style: {\n          position: \"relative\"\n        },\n        __self: this,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 64,\n          columnNumber: 17\n        }\n      }, /*#__PURE__*/React.createElement(\"video\", {\n        onLoadedMetadata: function onLoadedMetadata() {\n          return \"onPlay\";\n        },\n        id: \"inputVideo\",\n        className: \"video-circle\",\n        width: \"500\",\n        height: \"500\",\n        autoPlay: true,\n        muted: true,\n        playsInline: true,\n        __self: this,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 65,\n          columnNumber: 21\n        }\n      }), /*#__PURE__*/React.createElement(\"canvas\", {\n        id: \"overlay\",\n        __self: this,\n        __source: {\n          fileName: _jsxFileName,\n          lineNumber: 66,\n          columnNumber: 21\n        }\n      }));\n    }\n  }]);\n\n  return VideoStream;\n}(Component);\n\nexport default VideoStream;","map":{"version":3,"sources":["/Users/angeldiscopanda/Trilogy-2020/Projects/trainofthought/client/src/component/facerec/VideoStream.js"],"names":["React","Component","Video","canvas","faceapi","fetchJson","VideoStream","renderVideo","nets","tinyFaceDetector","load","loadFaceExpressionModel","canvasElement","document","getElementById","videoElement","querySelector","constraints","audio","video","navigator","mediaDevices","getUserMedia","stream","onPlay","options","TinyFaceDetectorOptions","inputSize","scoreThreshold","detectSingleFace","withFaceExpressions","result","dims","matchDimensions","resizedResult","resizeResults","minConfidence","draw","drawDetections","drawFaceExpressions","setTimeout","srcObject","onloadedmetadata","play","onplay","position"],"mappings":";;;;;;;;AAAA,OAAOA,KAAP,IAAgBC,SAAhB,QAAiC,OAAjC;AACA,OAAO,cAAP;AACA,OAAO,+CAAP;AACA,OAAO,kDAAP;AACA,OAAOC,KAAP,MAAkB,SAAlB;AACA,OAAO,KAAKC,MAAZ,MAAwB,QAAxB;AACA,OAAO,KAAKC,OAAZ,MAAyB,aAAzB;AACA,SAASC,SAAT,QAA0B,aAA1B;;IAGMC,W;;;;;;;;;;;;;;;UAMFC,W,yEAAc;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,qBAKJH,OAAO,CAACI,IAAR,CAAaC,gBAAb,CAA8BC,IAA9B,CAAmC,GAAnC,CALI;;AAAA;AAAA;AAAA,qBAOJN,OAAO,CAACO,uBAAR,CAAgC,GAAhC,CAPI;;AAAA;AASV;AACMC,cAAAA,aAVI,GAUYC,QAAQ,CAACC,cAAT,CAAwB,SAAxB,CAVZ;AAWJC,cAAAA,YAXI,GAWWF,QAAQ,CAACG,aAAT,CAAuB,OAAvB,CAXX,EAaV;;AACMC,cAAAA,WAdI,GAcU;AAAEC,gBAAAA,KAAK,EAAE,KAAT;AAAgBC,gBAAAA,KAAK,EAAE;AAAvB,eAdV;AAAA;AAAA,qBAeWC,SAAS,CAACC,YAAV,CAAuBC,YAAvB,CAAoCL,WAApC,CAfX;;AAAA;AAeJM,cAAAA,MAfI;;AAiBV;AACA;AACMC,cAAAA,MAnBI;AAAA,qFAmBK;AAAA;AAAA;AAAA;AAAA;AAAA;AACXnB,0BAAAA,SAAS,CAAE,+CAAF,CAAT;AACAA,0BAAAA,SAAS,CAAC,kDAAD,CAAT;AAEMoB,0BAAAA,OAJK,GAIK,IAAIrB,OAAO,CAACsB,uBAAZ,CAAoC;AAAEC,4BAAAA,SAAS,EAAE,GAAb;AAAkBC,4BAAAA,cAAc,EAAE;AAAlC,2BAApC,CAJL;AAAA;AAAA,iCAKUxB,OAAO,CAACyB,gBAAR,CAAyBd,YAAzB,EAAuCU,OAAvC,EAAgDK,mBAAhD,EALV;;AAAA;AAKLC,0BAAAA,MALK;;AAOX,8BAAIA,MAAJ,EAAY;AACFC,4BAAAA,IADE,GACK5B,OAAO,CAAC6B,eAAR,CAAwBrB,aAAxB,EAAuCG,YAAvC,EAAqD,IAArD,CADL;AAEFmB,4BAAAA,aAFE,GAEc9B,OAAO,CAAC+B,aAAR,CAAsBJ,MAAtB,EAA8BC,IAA9B,CAFd;AAGFI,4BAAAA,aAHE,GAGc,IAHd;AAIRhC,4BAAAA,OAAO,CAACiC,IAAR,CAAaC,cAAb,CAA4B1B,aAA5B,EAA2CsB,aAA3C;AACA9B,4BAAAA,OAAO,CAACiC,IAAR,CAAaE,mBAAb,CAAiC3B,aAAjC,EAAgDsB,aAAhD,EAA+DE,aAA/D;AACH;;AAEDI,0BAAAA,UAAU,CAAC;AAAA,mCAAMhB,MAAM,EAAZ;AAAA,2BAAD,CAAV;;AAfW;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,iBAnBL;;AAAA,gCAmBJA,MAnBI;AAAA;AAAA;AAAA;;AAqCVT,cAAAA,YAAY,CAAC0B,SAAb,GAAyBlB,MAAzB;;AACAR,cAAAA,YAAY,CAAC2B,gBAAb,GAAgC,YAAM;AAClC3B,gBAAAA,YAAY,CAAC4B,IAAb;AACH,eAFD;;AAGA5B,cAAAA,YAAY,CAAC6B,MAAb,GAAsBpB,MAAtB;;AAzCU;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,K;;;;;;wCAJM;AAChB,WAAKjB,WAAL;AACH;;;6BA+CY;AACL,0BACI;AAAK,QAAA,KAAK,EAAE;AAAEsC,UAAAA,QAAQ,EAAE;AAAZ,SAAZ;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,sBACI;AAAO,QAAA,gBAAgB,EAAE;AAAA,iBAAM,QAAN;AAAA,SAAzB;AAAyC,QAAA,EAAE,EAAC,YAA5C;AAAyD,QAAA,SAAS,EAAC,cAAnE;AAAkF,QAAA,KAAK,EAAC,KAAxF;AAA8F,QAAA,MAAM,EAAC,KAArG;AAA2G,QAAA,QAAQ,MAAnH;AAAoH,QAAA,KAAK,MAAzH;AAA0H,QAAA,WAAW,MAArI;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QADJ,eAEI;AAAQ,QAAA,EAAE,EAAC,SAAX;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA,QAFJ,CADJ;AAMH;;;;EA1DiB5C,S;;AA6D1B,eAAeK,WAAf","sourcesContent":["import React, { Component } from \"react\"\nimport \"./styles.css\"\nimport \"./face_expression_model-weights_manifest.json\"\nimport \"./tiny_face_detector_model-weights_manifest.json\"\nimport Video from \"./Video\"\nimport * as canvas from 'canvas';\nimport * as faceapi from 'face-api.js';\nimport { fetchJson } from \"face-api.js\"\n\n\nclass VideoStream extends Component {\n\n    componentDidMount() {\n        this.renderVideo();\n    }\n\n    renderVideo = async () => {\n        \n\n\n        // load the face detection model\n        await faceapi.nets.tinyFaceDetector.load('/');\n        // load the face expression detection model\n        await faceapi.loadFaceExpressionModel('/');\n\n        // get canvas and video elements\n        const canvasElement = document.getElementById(\"overlay\");\n        const videoElement = document.querySelector(\"video\");\n\n        // get Webcam video stream\n        const constraints = { audio: false, video: {} };\n        const stream = await navigator.mediaDevices.getUserMedia(constraints);\n\n        // what to do when the video stream is available\n        // AKA facial recogition \n        const onPlay = async () => {\n            fetchJson( \"./face_expression_model-weights_manifest.json\")\n            fetchJson(\"./tiny_face_detector_model-weights_manifest.json\")\n\n            const options = new faceapi.TinyFaceDetectorOptions({ inputSize: 512, scoreThreshold: 0.5 });\n            const result = await faceapi.detectSingleFace(videoElement, options).withFaceExpressions();\n\n            if (result) {\n                const dims = faceapi.matchDimensions(canvasElement, videoElement, true);\n                const resizedResult = faceapi.resizeResults(result, dims);\n                const minConfidence = 0.05;\n                faceapi.draw.drawDetections(canvasElement, resizedResult);\n                faceapi.draw.drawFaceExpressions(canvasElement, resizedResult, minConfidence);\n            }\n\n            setTimeout(() => onPlay());\n        }\n\n        videoElement.srcObject = stream;\n        videoElement.onloadedmetadata = () => {\n            videoElement.play();\n        };\n        videoElement.onplay = onPlay;\n\n    }\n\n        render() {\n            return (\n                <div style={{ position: \"relative\" }}>\n                    <video onLoadedMetadata={() => \"onPlay\"} id=\"inputVideo\" className=\"video-circle\" width=\"500\" height=\"500\" autoPlay muted playsInline></video>\n                    <canvas id=\"overlay\" />\n                </div>\n            )\n        }\n    }\n\nexport default VideoStream"]},"metadata":{},"sourceType":"module"}