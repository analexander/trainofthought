{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google Inc. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { ENGINE } from '../engine';\nimport { LogSoftmax } from '../kernel_names';\nimport { convertToTensor } from '../tensor_util_env';\nimport { cast } from './cast';\nimport { exp } from './exp';\nimport { log } from './log';\nimport { max } from './max';\nimport { op } from './operation';\nimport { sub } from './sub';\nimport { sum } from './sum';\n/**\n * Computes the log softmax.\n *\n * ```js\n * const a = tf.tensor1d([1, 2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * ```js\n * const a = tf.tensor2d([2, 4, 6, 1, 2, 3], [2, 3]);\n *\n * a.logSoftmax().print();  // or tf.logSoftmax(a)\n * ```\n *\n * @param logits The logits array.\n * @param axis The dimension softmax would be performed on. Defaults to `-1`\n *     which indicates the last dimension.\n *\n * @doc {heading: 'Operations', subheading: 'Normalization'}\n */\n\nfunction logSoftmax_(logits) {\n  var axis = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : -1;\n  var $logits = convertToTensor(logits, 'logits', 'logSoftmax');\n\n  if (axis === -1) {\n    axis = $logits.rank - 1;\n  }\n\n  if (axis !== $logits.rank - 1) {\n    throw Error('Log Softmax along a non-last dimension is not yet supported. ' + \"Logits was rank \".concat($logits.rank, \" and axis was \").concat(axis));\n  }\n\n  var forward = function forward(backend, save) {\n    var keepDims = true;\n    var xMax = max(logits, axis, true);\n    var shifted = sub(logits, xMax);\n    var value = sub(cast(shifted, 'float32'), log(sum(exp(shifted), axis, keepDims)));\n    save([value]);\n    return value;\n  };\n\n  var inputs = {\n    logits: $logits\n  };\n  var attrs = {\n    axis: axis\n  };\n  return ENGINE.runKernelFunc(forward, inputs, null\n  /* grad */\n  , LogSoftmax, attrs);\n}\n\nexport var logSoftmax = op({\n  logSoftmax_: logSoftmax_\n});","map":null,"metadata":{},"sourceType":"module"}