{"ast":null,"code":"\"use strict\";\n/**\n * @license\n * Copyright 2019 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the \"License\");\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an \"AS IS\" BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\n\nvar __awaiter = this && this.__awaiter || function (thisArg, _arguments, P, generator) {\n  return new (P || (P = Promise))(function (resolve, reject) {\n    function fulfilled(value) {\n      try {\n        step(generator.next(value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function rejected(value) {\n      try {\n        step(generator[\"throw\"](value));\n      } catch (e) {\n        reject(e);\n      }\n    }\n\n    function step(result) {\n      result.done ? resolve(result.value) : new P(function (resolve) {\n        resolve(result.value);\n      }).then(fulfilled, rejected);\n    }\n\n    step((generator = generator.apply(thisArg, _arguments || [])).next());\n  });\n};\n\nvar __generator = this && this.__generator || function (thisArg, body) {\n  var _ = {\n    label: 0,\n    sent: function sent() {\n      if (t[0] & 1) throw t[1];\n      return t[1];\n    },\n    trys: [],\n    ops: []\n  },\n      f,\n      y,\n      t,\n      g;\n  return g = {\n    next: verb(0),\n    \"throw\": verb(1),\n    \"return\": verb(2)\n  }, typeof Symbol === \"function\" && (g[Symbol.iterator] = function () {\n    return this;\n  }), g;\n\n  function verb(n) {\n    return function (v) {\n      return step([n, v]);\n    };\n  }\n\n  function step(op) {\n    if (f) throw new TypeError(\"Generator is already executing.\");\n\n    while (_) {\n      try {\n        if (f = 1, y && (t = op[0] & 2 ? y[\"return\"] : op[0] ? y[\"throw\"] || ((t = y[\"return\"]) && t.call(y), 0) : y.next) && !(t = t.call(y, op[1])).done) return t;\n        if (y = 0, t) op = [op[0] & 2, t.value];\n\n        switch (op[0]) {\n          case 0:\n          case 1:\n            t = op;\n            break;\n\n          case 4:\n            _.label++;\n            return {\n              value: op[1],\n              done: false\n            };\n\n          case 5:\n            _.label++;\n            y = op[1];\n            op = [0];\n            continue;\n\n          case 7:\n            op = _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n\n          default:\n            if (!(t = _.trys, t = t.length > 0 && t[t.length - 1]) && (op[0] === 6 || op[0] === 2)) {\n              _ = 0;\n              continue;\n            }\n\n            if (op[0] === 3 && (!t || op[1] > t[0] && op[1] < t[3])) {\n              _.label = op[1];\n              break;\n            }\n\n            if (op[0] === 6 && _.label < t[1]) {\n              _.label = t[1];\n              t = op;\n              break;\n            }\n\n            if (t && _.label < t[2]) {\n              _.label = t[2];\n\n              _.ops.push(op);\n\n              break;\n            }\n\n            if (t[2]) _.ops.pop();\n\n            _.trys.pop();\n\n            continue;\n        }\n\n        op = body.call(thisArg, _);\n      } catch (e) {\n        op = [6, e];\n        y = 0;\n      } finally {\n        f = t = 0;\n      }\n    }\n\n    if (op[0] & 5) throw op[1];\n    return {\n      value: op[0] ? op[1] : void 0,\n      done: true\n    };\n  }\n};\n\nObject.defineProperty(exports, \"__esModule\", {\n  value: true\n});\n\nvar tfjs_1 = require(\"@tensorflow/tfjs\");\n\nvar fs = require(\"fs\");\n\nvar util_1 = require(\"util\");\n\nvar nodejs_kernel_backend_1 = require(\"./nodejs_kernel_backend\");\n\nvar readFile = util_1.promisify(fs.readFile); // tslint:disable-next-line:no-require-imports\n\nvar messages = require('./proto/api_pb');\n\nvar SAVED_MODEL_FILE_NAME = '/saved_model.pb';\nvar SAVED_MODEL_INIT_OP_KEY = '__saved_model_init_op'; // This map is used to keep track of loaded SavedModel metagraph mapping\n// information. The map key is TFSavedModel id in JavaScript, value is\n// an object of path to the SavedModel, metagraph tags, and loaded Session ID in\n// the c++ bindings. When user loads a SavedModel signature, it will go through\n// entries in this map to find if the corresponding SavedModel session has\n// already been loaded in C++ addon and will reuse it if existing.\n\nvar loadedSavedModelPathMap = new Map(); // The ID of loaded TFSavedModel. This ID is used to keep track of loaded\n// TFSavedModel, so the loaded session in c++ bindings for the corresponding\n// TFSavedModel can be properly reused/disposed.\n\nvar nextTFSavedModelId = 0;\n/**\n * Get a key in an object by its value. This is used to get protobuf enum value\n * from index.\n *\n * @param object\n * @param value\n */\n// tslint:disable-next-line:no-any\n\nfunction getEnumKeyFromValue(object, value) {\n  return Object.keys(object).find(function (key) {\n    return object[key] === value;\n  });\n}\n\nexports.getEnumKeyFromValue = getEnumKeyFromValue;\n/**\n * Read SavedModel proto message from path.\n *\n * @param path Path to SavedModel folder.\n */\n\nfunction readSavedModelProto(path) {\n  return __awaiter(this, void 0, void 0, function () {\n    var modelFile, array;\n    return __generator(this, function (_a) {\n      switch (_a.label) {\n        case 0:\n          // Load the SavedModel pb file and deserialize it into message.\n          try {\n            fs.accessSync(path + SAVED_MODEL_FILE_NAME, fs.constants.R_OK);\n          } catch (error) {\n            throw new Error('There is no saved_model.pb file in the directory: ' + path);\n          }\n\n          return [4\n          /*yield*/\n          , readFile(path + SAVED_MODEL_FILE_NAME)];\n\n        case 1:\n          modelFile = _a.sent();\n          array = new Uint8Array(modelFile);\n          return [2\n          /*return*/\n          , messages.SavedModel.deserializeBinary(array)];\n      }\n    });\n  });\n}\n\nexports.readSavedModelProto = readSavedModelProto;\n/**\n * Inspect the MetaGraphs of the SavedModel from the provided path. This\n * function will return an array of `MetaGraphInfo` objects.\n *\n * @param path Path to SavedModel folder.\n *\n * @doc {heading: 'Models', subheading: 'SavedModel', namespace: 'node'}\n */\n\nfunction getMetaGraphsFromSavedModel(path) {\n  return __awaiter(this, void 0, void 0, function () {\n    var result, modelMessage, metaGraphList, i, metaGraph, tags, signatureDef, signatureDefMap, signatureDefKeys, key, signatureDefEntry, inputsMapMessage, inputsMapKeys, inputs, inputsMapKey, inputTensor, inputTensorInfo, dtype, outputsMapMessage, outputsMapKeys, outputs, outputsMapKey, outputTensor, outputTensorInfo, dtype;\n    return __generator(this, function (_a) {\n      switch (_a.label) {\n        case 0:\n          result = [];\n          return [4\n          /*yield*/\n          , readSavedModelProto(path)];\n\n        case 1:\n          modelMessage = _a.sent();\n          metaGraphList = modelMessage.getMetaGraphsList();\n\n          for (i = 0; i < metaGraphList.length; i++) {\n            metaGraph = {};\n            tags = metaGraphList[i].getMetaInfoDef().getTagsList();\n            metaGraph.tags = tags;\n            signatureDef = {};\n            signatureDefMap = metaGraphList[i].getSignatureDefMap();\n            signatureDefKeys = signatureDefMap.keys(); // Go through all signatureDefs\n\n            while (true) {\n              key = signatureDefKeys.next();\n\n              if (key.done) {\n                break;\n              } // Skip TensorFlow internal Signature '__saved_model_init_op'.\n\n\n              if (key.value === SAVED_MODEL_INIT_OP_KEY) {\n                continue;\n              }\n\n              signatureDefEntry = signatureDefMap.get(key.value);\n              inputsMapMessage = signatureDefEntry.getInputsMap();\n              inputsMapKeys = inputsMapMessage.keys();\n              inputs = {};\n\n              while (true) {\n                inputsMapKey = inputsMapKeys.next();\n\n                if (inputsMapKey.done) {\n                  break;\n                }\n\n                inputTensor = inputsMapMessage.get(inputsMapKey.value);\n                inputTensorInfo = {};\n                dtype = getEnumKeyFromValue(messages.DataType, inputTensor.getDtype());\n                inputTensorInfo.dtype = mapTFDtypeToJSDtype(dtype);\n                inputTensorInfo.tfDtype = dtype;\n                inputTensorInfo.name = inputTensor.getName();\n                inputTensorInfo.shape = inputTensor.getTensorShape().getDimList();\n                inputs[inputsMapKey.value] = inputTensorInfo;\n              }\n\n              outputsMapMessage = signatureDefEntry.getOutputsMap();\n              outputsMapKeys = outputsMapMessage.keys();\n              outputs = {};\n\n              while (true) {\n                outputsMapKey = outputsMapKeys.next();\n\n                if (outputsMapKey.done) {\n                  break;\n                }\n\n                outputTensor = outputsMapMessage.get(outputsMapKey.value);\n                outputTensorInfo = {};\n                dtype = getEnumKeyFromValue(messages.DataType, outputTensor.getDtype());\n                outputTensorInfo.dtype = mapTFDtypeToJSDtype(dtype);\n                outputTensorInfo.tfDtype = dtype;\n                outputTensorInfo.name = outputTensor.getName();\n                outputTensorInfo.shape = outputTensor.getTensorShape().getDimList();\n                outputs[outputsMapKey.value] = outputTensorInfo;\n              }\n\n              signatureDef[key.value] = {\n                inputs: inputs,\n                outputs: outputs\n              };\n            }\n\n            metaGraph.signatureDefs = signatureDef;\n            result.push(metaGraph);\n          }\n\n          return [2\n          /*return*/\n          , result];\n      }\n    });\n  });\n}\n\nexports.getMetaGraphsFromSavedModel = getMetaGraphsFromSavedModel;\n/**\n * Get SignatureDefEntry from SavedModel metagraphs info. The SignatureDefEntry\n * will be used when executing a SavedModel signature.\n *\n * @param savedModelInfo The MetaGraphInfo array loaded through\n *     getMetaGraphsFromSavedModel().\n * @param tags The tags of the MetaGraph to get input/output node names from.\n * @param signature The signature to get input/output node names from.\n */\n\nfunction getSignatureDefEntryFromMetaGraphInfo(savedModelInfo, tags, signature) {\n  for (var i = 0; i < savedModelInfo.length; i++) {\n    var metaGraphInfo = savedModelInfo[i];\n\n    if (stringArraysHaveSameElements(tags, metaGraphInfo.tags)) {\n      if (metaGraphInfo.signatureDefs[signature] == null) {\n        throw new Error('The SavedModel does not have signature: ' + signature);\n      }\n\n      return metaGraphInfo.signatureDefs[signature];\n    }\n  }\n\n  throw new Error(\"The SavedModel does not have tags: \" + tags);\n}\n\nexports.getSignatureDefEntryFromMetaGraphInfo = getSignatureDefEntryFromMetaGraphInfo;\n/**\n * A `tf.TFSavedModel` is a signature loaded from a SavedModel\n * metagraph, and allows inference execution.\n *\n * @doc {heading: 'Models', subheading: 'SavedModel', namespace: 'node'}\n */\n\nvar TFSavedModel =\n/** @class */\nfunction () {\n  function TFSavedModel(sessionId, jsid, signature, backend) {\n    this.sessionId = sessionId;\n    this.jsid = jsid;\n    this.signature = signature;\n    this.backend = backend;\n    this.disposed = false;\n  }\n\n  Object.defineProperty(TFSavedModel.prototype, \"inputs\", {\n    /**\n     * Return the array of input tensor info.\n     *\n     * @doc {heading: 'Models', subheading: 'SavedModel'}\n     */\n    get: function get() {\n      var entries = this.signature.inputs;\n      var results = Object.keys(entries).map(function (key) {\n        return entries[key];\n      });\n      results.forEach(function (info) {\n        info.name = info.name.replace(/:0$/, '');\n      });\n      return results;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  Object.defineProperty(TFSavedModel.prototype, \"outputs\", {\n    /**\n     * Return the array of output tensor info.\n     *\n     * @doc {heading: 'Models', subheading: 'SavedModel'}\n     */\n    get: function get() {\n      var entries = this.signature.outputs;\n      var results = Object.keys(entries).map(function (key) {\n        return entries[key];\n      });\n      results.forEach(function (info) {\n        info.name = info.name.replace(/:0$/, '');\n      });\n      return results;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  /**\n   * Delete the SavedModel from nodeBackend and delete corresponding session in\n   * the C++ backend if the session is only used by this TFSavedModel.\n   *\n   * @doc {heading: 'Models', subheading: 'SavedModel'}\n   */\n\n  TFSavedModel.prototype.dispose = function () {\n    if (!this.disposed) {\n      this.disposed = true;\n      loadedSavedModelPathMap.delete(this.jsid);\n\n      for (var _i = 0, _a = Array.from(loadedSavedModelPathMap.keys()); _i < _a.length; _i++) {\n        var id = _a[_i];\n        var value = loadedSavedModelPathMap.get(id);\n\n        if (value.sessionId === this.sessionId) {\n          return;\n        }\n      }\n\n      this.backend.deleteSavedModel(this.sessionId);\n    } else {\n      throw new Error('This SavedModel has already been deleted.');\n    }\n  };\n\n  Object.defineProperty(TFSavedModel.prototype, \"outputNodeNames\", {\n    get: function get() {\n      var _this = this;\n\n      if (this.outputNodeNames_ != null) {\n        return this.outputNodeNames_;\n      }\n\n      this.outputNodeNames_ = Object.keys(this.signature.outputs).reduce(function (names, key) {\n        names[key] = _this.signature.outputs[key].name;\n        return names;\n      }, {});\n      return this.outputNodeNames_;\n    },\n    enumerable: true,\n    configurable: true\n  });\n  /**\n   * Execute the inference for the input tensors.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a Tensor. For models with multiple inputs, inputs\n   * params should be in either Tensor[] if the input order is fixed, or\n   * otherwise NamedTensorMap format. The keys in the NamedTensorMap are the\n   * name of input tensors in SavedModel signatureDef. It can be found through\n   * `tf.node.getMetaGraphsFromSavedModel()`.\n   *\n   * For batch inference execution, the tensors for each input need to be\n   * concatenated together. For example with mobilenet, the required input shape\n   * is [1, 244, 244, 3], which represents the [batch, height, width, channel].\n   * If we are provide a batched data of 100 images, the input tensor should be\n   * in the shape of [100, 244, 244, 3].\n   *\n   * @param config Prediction configuration for specifying the batch size.\n   *\n   * @returns Inference result tensors. The output would be single Tensor if\n   * model has single output node, otherwise Tensor[] or NamedTensorMap[] will\n   * be returned for model with multiple outputs.\n   *\n   * @doc {heading: 'Models', subheading: 'SavedModel'}\n   */\n\n  TFSavedModel.prototype.predict = function (inputs, config) {\n    var _this = this;\n\n    if (this.disposed) {\n      throw new Error('The TFSavedModel has already been deleted!');\n    } else {\n      var inputTensors = [];\n\n      if (inputs instanceof tfjs_1.Tensor) {\n        inputTensors.push(inputs);\n        var result = this.backend.runSavedModel(this.sessionId, inputTensors, Object.values(this.signature.inputs), Object.values(this.outputNodeNames));\n        return result.length > 1 ? result : result[0];\n      } else if (Array.isArray(inputs)) {\n        inputTensors = inputs;\n        return this.backend.runSavedModel(this.sessionId, inputTensors, Object.values(this.signature.inputs), Object.values(this.outputNodeNames));\n      } else {\n        var inputTensorNames = Object.keys(this.signature.inputs);\n        var providedInputNames = Object.keys(inputs);\n\n        if (!stringArraysHaveSameElements(inputTensorNames, providedInputNames)) {\n          throw new Error(\"The model signatureDef input names are \" + inputTensorNames.join() + \", however the provided input names are \" + providedInputNames.join() + \".\");\n        }\n\n        var inputNodeNamesArray = [];\n\n        for (var i = 0; i < inputTensorNames.length; i++) {\n          inputTensors.push(inputs[inputTensorNames[i]]);\n          inputNodeNamesArray.push(this.signature.inputs[inputTensorNames[i]]);\n        }\n\n        var outputTensorNames = Object.keys(this.outputNodeNames);\n        var outputNodeNamesArray = [];\n\n        for (var i = 0; i < outputTensorNames.length; i++) {\n          outputNodeNamesArray.push(this.outputNodeNames[outputTensorNames[i]]);\n        }\n\n        var outputTensors_1 = this.backend.runSavedModel(this.sessionId, inputTensors, inputNodeNamesArray, outputNodeNamesArray);\n        tfjs_1.util.assert(outputTensors_1.length === outputNodeNamesArray.length, function () {\n          return 'Output tensors do not match output node names, ' + (\"receive \" + outputTensors_1.length + \") output tensors but \") + (\"there are \" + _this.outputNodeNames.length + \" output nodes.\");\n        });\n        var outputMap = {};\n\n        for (var i = 0; i < outputTensorNames.length; i++) {\n          outputMap[outputTensorNames[i]] = outputTensors_1[i];\n        }\n\n        return outputMap;\n      }\n    }\n  };\n  /**\n   * Execute the inference for the input tensors and return activation\n   * values for specified output node names without batching.\n   *\n   * @param input The input tensors, when there is single input for the model,\n   * inputs param should be a Tensor. For models with multiple inputs, inputs\n   * params should be in either Tensor[] if the input order is fixed, or\n   * otherwise NamedTensorMap format.\n   *\n   * @param outputs string|string[]. List of output node names to retrieve\n   * activation from.\n   *\n   * @returns Activation values for the output nodes result tensors. The return\n   * type matches specified parameter outputs type. The output would be single\n   * Tensor if single output is specified, otherwise Tensor[] for multiple\n   * outputs.\n   *\n   * @doc {heading: 'Models', subheading: 'SavedModel'}\n   */\n\n\n  TFSavedModel.prototype.execute = function (inputs, outputs) {\n    throw new Error('execute() of TFSavedModel is not supported yet.');\n  };\n\n  return TFSavedModel;\n}();\n\nexports.TFSavedModel = TFSavedModel;\n/**\n * Load a TensorFlow SavedModel from disk. TensorFlow SavedModel is different\n * from TensorFlow.js model format. A SavedModel is a directory containing\n * serialized signatures and the states needed to run them. The directory has a\n * saved_model.pb (or saved_model.pbtxt) file storing the actual TensorFlow\n * program, or model, and a set of named signatures, each identifying a\n * function. The directory also has a variables directory contains a standard\n * training checkpoint. The directory may also has a assets directory contains\n * files used by the TensorFlow graph, for example text files used to initialize\n * vocabulary tables. These are supported datatypes: float32, int32, complex64,\n * string.For more information, see this guide:\n * https://www.tensorflow.org/guide/saved_model.\n *\n * @param path The path to the SavedModel.\n * @param tags The tags of the MetaGraph to load. The available tags of a\n *     SavedModel can be retrieved through tf.node.getMetaGraphsFromSavedModel()\n *     API. Defaults to ['serve'].\n * @param signature The name of the SignatureDef to load. The available\n *     SignatureDefs of a SavedModel can be retrieved through\n *     tf.node.getMetaGraphsFromSavedModel() API. Defaults to 'serving_default'.\n *\n * @doc {heading: 'Models', subheading: 'SavedModel', namespace: 'node'}\n */\n\nfunction loadSavedModel(path, tags, signature) {\n  if (tags === void 0) {\n    tags = ['serve'];\n  }\n\n  if (signature === void 0) {\n    signature = 'serving_default';\n  }\n\n  return __awaiter(this, void 0, void 0, function () {\n    var backend, savedModelInfo, signatureDefEntry, sessionId, _i, _a, id_1, modelInfo, tagsString, id, savedModel;\n\n    return __generator(this, function (_b) {\n      switch (_b.label) {\n        case 0:\n          nodejs_kernel_backend_1.ensureTensorflowBackend();\n          backend = nodejs_kernel_backend_1.nodeBackend();\n          return [4\n          /*yield*/\n          , getMetaGraphsFromSavedModel(path)];\n\n        case 1:\n          savedModelInfo = _b.sent();\n          signatureDefEntry = getSignatureDefEntryFromMetaGraphInfo(savedModelInfo, tags, signature);\n\n          for (_i = 0, _a = Array.from(loadedSavedModelPathMap.keys()); _i < _a.length; _i++) {\n            id_1 = _a[_i];\n            modelInfo = loadedSavedModelPathMap.get(id_1);\n\n            if (modelInfo.path === path && stringArraysHaveSameElements(modelInfo.tags, tags)) {\n              sessionId = modelInfo.sessionId;\n            }\n          }\n\n          if (sessionId == null) {\n            tagsString = tags.join(',');\n            sessionId = backend.loadSavedModelMetaGraph(path, tagsString);\n          }\n\n          id = nextTFSavedModelId++;\n          savedModel = new TFSavedModel(sessionId, id, signatureDefEntry, backend);\n          loadedSavedModelPathMap.set(id, {\n            path: path,\n            tags: tags,\n            sessionId: sessionId\n          });\n          return [2\n          /*return*/\n          , savedModel];\n      }\n    });\n  });\n}\n\nexports.loadSavedModel = loadSavedModel;\n/**\n * Compare if two unsorted arrays of string have the same elements.\n * @param arrayA\n * @param arrayB\n */\n\nfunction stringArraysHaveSameElements(arrayA, arrayB) {\n  if (arrayA.length === arrayB.length && arrayA.sort().join() === arrayB.sort().join()) {\n    return true;\n  }\n\n  return false;\n}\n\nfunction mapTFDtypeToJSDtype(tfDtype) {\n  switch (tfDtype) {\n    case 'DT_FLOAT':\n      return 'float32';\n\n    case 'DT_INT64':\n    case 'DT_INT32':\n    case 'DT_UINT8':\n      return 'int32';\n\n    case 'DT_BOOL':\n      return 'bool';\n\n    case 'DT_COMPLEX64':\n      return 'complex64';\n\n    case 'DT_STRING':\n      return 'string';\n\n    default:\n      throw new Error('Unsupported tensor DataType: ' + tfDtype + ', try to modify the model in python to convert the datatype');\n  }\n}\n\nfunction getNumOfSavedModels() {\n  nodejs_kernel_backend_1.ensureTensorflowBackend();\n  var backend = nodejs_kernel_backend_1.nodeBackend();\n  return backend.getNumOfSavedModels();\n}\n\nexports.getNumOfSavedModels = getNumOfSavedModels;","map":null,"metadata":{},"sourceType":"script"}