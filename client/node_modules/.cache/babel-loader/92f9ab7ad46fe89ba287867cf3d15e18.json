{"ast":null,"code":"/**\n * @license\n * Copyright 2020 Google LLC. All Rights Reserved.\n * Licensed under the Apache License, Version 2.0 (the License);\n * you may not use this file except in compliance with the License.\n * You may obtain a copy of the License at\n *\n * http://www.apache.org/licenses/LICENSE-2.0\n *\n * Unless required by applicable law or agreed to in writing, software\n * distributed under the License is distributed on an AS IS BASIS,\n * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n * See the License for the specific language governing permissions and\n * limitations under the License.\n * =============================================================================\n */\nimport { Softplus } from '@tensorflow/tfjs-core';\nimport { unaryKernelFunc } from '../utils/unary_utils'; // mirrors the implementation of tf.nn.softplus: https://goo.gl/vkcvwX\n// epsilon is the difference between 1.0 and the next representable float.\n// For a single precision 32 bit float this should be 2^-23, see:\n// https://math.byu.edu/~schow/work/IEEEFloatingPoint.htm\n\nvar epsilon = 1.1920928955078125e-7;\nvar threshold = Math.log(epsilon) + 2.0;\nexport var softplus = unaryKernelFunc(Softplus, function (xi) {\n  // Value above which exp(x) may overflow, but softplus(x) == x\n  // is within machine epsilon.\n  var tooLarge = xi > -threshold; // Value below which exp(x) may underflow, but softplus(x) == exp(x)\n  // is within machine epsilon.\n\n  var tooSmall = xi < threshold;\n  var expX = Math.exp(xi);\n  var result;\n\n  if (tooSmall) {\n    result = expX;\n  } else if (tooLarge) {\n    result = xi;\n  } else {\n    result = Math.log(1.0 + expX);\n  }\n\n  return result;\n});\nexport var softplusConfig = {\n  kernelName: Softplus,\n  backendName: 'cpu',\n  kernelFunc: softplus\n};","map":null,"metadata":{},"sourceType":"module"}